{
  "hash": "97aaf3e2e34beea2f5f0c5e6f9916d84",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Convertir el análisis exploratorio en acción\"\n---\n\nEl análisis exploratorio de datos es un paso crucial en el flujo de trabajo de la ciencia de datos, ¡por no esl el final! Ahora es el momento de aprender técnicas y consideraciones que puedes utilizar para avanzar con éxito en tus proyectos una vez que hayas terminado de explorar.\n\n## Consideraciones para datos categóricos\n\n-   Por qué ejecutar EDA?\n    -   Detectar patrones y relaciones.\n    -   Generar preguntas o hipótesis.\n    -   Preparar datos para modelos de machine learning.\n-   Representatividad de los datos\n    -   La muestra debe representar la población.\n    -   Por ejemplo:\n        -   Educación versus ingresos en USA\n            -   No se pueden usar datos de Francia\n-   Clases Categóricas\n    -   Clases = etiquetas\n    -   Ejemplo, actitudes de las personas hacia el matrimonio.\n        -   Estado civil\n            -   Soltero\n            -   Casado\n            -   Divorciado\n-   Desbalance de Clases\n\n![](images/paste-66.png)\n\n-   Frecuencia de Clases\n\n::: {#4aa4cb3f .cell execution_count=1}\n``` {.python .cell-code}\nprint(planes('Destination').value_counts())\n```\n:::\n\n\n![](images/paste-67.png)\n\n-   Frecuencia relativa de clases\n\n    -   40% de los vuelos internos de la India van hacia Delhi.\n\n::: {#3b75aef7 .cell execution_count=2}\n``` {.python .cell-code}\nplanes['Destination'].value_counts(normalize=True)\n```\n:::\n\n\n![](images/paste-68.png)\n\nEs nuestra muestra representativa de la población? (Vuelos internos de India)\n\n-   Tabulación Cruzada\n\n    -   Es otro método para observar la frecuencia de clase, que permite examinar la frecuencia de combinaciones de clases\n\n    ![](images/paste-69.png)\n\n::: {#07162030 .cell execution_count=3}\n``` {.python .cell-code}\npd.crosstab(planes['Source'], planes['Destination'])\n```\n:::\n\n\n![](images/paste-70.png)\n\n-   Extendiendo la tabulación cruzada\n\n| Source   | Destination | Median Price (IDR) |\n|----------|-------------|--------------------|\n| Banglore | Delhi       | 4232.21            |\n| Banglore | New Delhi   | 12114.56           |\n| Chennai  | Kolkata     | 3859.76            |\n| Delhi    | Cochin      | 9987.63            |\n| Kolkata  | Banglore    | 9654.21            |\n| Mumbai   | Hyderabad   | 3431.97            |\n\n-   Agregación de valores con pd.crosstab()\n\n::: {#22c65dee .cell execution_count=4}\n``` {.python .cell-code}\npd.crosstab(planes['Source'], planes['Destination'],\n           values=planes['Price'], aggfunc='median')\n```\n:::\n\n\n![](images/paste-71.png)\n\nLos resultados muestran valores de la mediana para todas las rutas posibles en el conjunto de datos.\n\n-   Comparando la muestra con la población\n\n| Source   | Desitnation | Median Price (IDR) | Median Price (dataset) |\n|----------|-------------|--------------------|------------------------|\n| Banglore | Delhi       | 4232.21            | 4823.0                 |\n| Banglore | New Delhi   | 12114.56           | 10976.50               |\n| Chennai  | Kolkata     | 3859.76            | 3850.0                 |\n| Delhi    | Cochin      | 9987.63            | 10260.0                |\n| Kolkata  | Banglore    | 9654.21            | 9345.0                 |\n| Mumbai   | Hyderabad   | 3431.97            | 3342.0                 |\n\n### Comprobación del desequilibrio de clases\n\nLa [Encuesta Kaggle 2022](https://www.kaggle.com/kaggle-survey-2022) recoge la información sobre la formación de los científicos de datos, sus tecnologías y técnicas preferidas. Se considera una visión precisa de lo que está ocurriendo en la ciencia de datos, basada en el volumen y el perfil de los que responden.\n\nUna vez examinados los títulos de los puestos y categorizados para alinearlos con nuestro `salaries` DataFrame\\`, puedes ver la siguiente proporción de categorías laborales en la encuesta Kaggle:\n\n| Categoría laboral   | Frecuencia relativa |\n|---------------------|---------------------|\n| Ciencia de datos    | 0,281236            |\n| Análisis de datos   | 0,224231            |\n| Otros               | 0,214609            |\n| Dirección           | 0,121300            |\n| Machine Learning    | 0,083248            |\n| Ingeniería de datos | 0,075375            |\n\nPensando en los resultados de la encuesta Kaggle como población, tu tarea consiste en averiguar si el DataFrame `salaries` es representativo comparando la frecuencia relativa de las categorías laborales.\n\n::: {#25211648 .cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\nruta = './data/salaries.csv'\nsalaries = pd.read_csv(ruta)\nsalaries.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Working_Year</th>\n      <th>Designation</th>\n      <th>Experience</th>\n      <th>Employment_Status</th>\n      <th>Salary_In_Rupees</th>\n      <th>Employee_Location</th>\n      <th>Company_Location</th>\n      <th>Company_Size</th>\n      <th>Remote_Working_Ratio</th>\n      <th>Salary_USD</th>\n      <th>Job_Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>Machine Learning Scientist</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>20688070.0</td>\n      <td>JP</td>\n      <td>JP</td>\n      <td>S</td>\n      <td>0.0</td>\n      <td>248256.840</td>\n      <td>Machine Learning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020</td>\n      <td>Big Data Engineer</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>8674985.0</td>\n      <td>GB</td>\n      <td>GB</td>\n      <td>M</td>\n      <td>50.0</td>\n      <td>104099.820</td>\n      <td>Data Engineering</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>Product Data Analyst</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>1591390.0</td>\n      <td>HN</td>\n      <td>HN</td>\n      <td>S</td>\n      <td>0.0</td>\n      <td>19096.680</td>\n      <td>Data Analytics</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020</td>\n      <td>Machine Learning Engineer</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>11935425.0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>L</td>\n      <td>50.0</td>\n      <td>143225.100</td>\n      <td>Machine Learning</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020</td>\n      <td>Data Analyst</td>\n      <td>EN</td>\n      <td>FT</td>\n      <td>5729004.0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>L</td>\n      <td>100.0</td>\n      <td>68748.048</td>\n      <td>Data Analytics</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Instrucciones\n\n-   Imprime la frecuencia relativa de la columna `Job_Category` de `salaries` DataFrame\n\n::: callout-note\nPara exportar el dataset en formato CSV dentro de DataCamp y luego copiarlo:\n\n``` python\nprint(salaries.to_csv(index=False))\n```\n:::\n\n::: {#b202eba3 .cell execution_count=6}\n``` {.python .cell-code}\n# Print the relative frequency of Job_Category\nprint(salaries['Job_Category'].value_counts(normalize=True))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nJob_Category\nData Science        0.277641\nData Engineering    0.272727\nData Analytics      0.226044\nMachine Learning    0.120393\nOther               0.068796\nManagerial          0.034398\nName: proportion, dtype: float64\n```\n:::\n:::\n\n\nParece que Data Science es la clase más popular y tiene una representación similar. Aún así, las otras categorías tienen frecuencias relativas bastante diferentes, lo cual pordría no ser sorprendente dado que el público objetivo son científico de datos. Dada la diferencia en las frecuencias relativas, ¿puedes confiar en que el DataFrame `salaries` representa con precisión los roles gerenciales?\n\n### Tabulación cruzada\n\nLa tabulación cruzada puede ayudar a identificar cómo se combinan las observaciones.\n\nUtilizando el conjunto de datos `salaries`, que se ha importado como un DataFrame `pandas`, realizarás una tabulación cruzada de múltiples variables, incluyendo el uso de la agregación, para ver la relación entre 'Company_Size' y otras variables.\n\n#### Instrucciones\n\n1.  Realiza una tabulación cruzada, estableciendo `Company_Size` como índice, y las columnas a las clases en `Experience`.\n\n::: {#58ad9a39 .cell execution_count=7}\n``` {.python .cell-code}\n# Cross-tabulate Company_Size and Experience\nprint(pd.crosstab(salaries['Company_Size'], salaries['Experience']))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExperience    EN  EX  MI   SE\nCompany_Size                 \nL             24   7  49   44\nM             25   9  58  136\nS             18   1  21   15\n```\n:::\n:::\n\n\n2.  Cruza 'Job_Category' y las clases de 'Company_Size' como nombres de columna.\n\n::: {#6748da28 .cell execution_count=8}\n``` {.python .cell-code}\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size']))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompany_Size       L   M   S\nJob_Category                \nData Analytics    23  61   8\nData Engineering  28  72  11\nData Science      38  59  16\nMachine Learning  17  19  13\nManagerial         5   8   1\nOther             13   9   6\n```\n:::\n:::\n\n\n3.  Actualiza `pd.crosstab()` para que devuelva los valores medios de `Salary_USD`.\n\n::: {#ba6d4824 .cell execution_count=9}\n``` {.python .cell-code}\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size'], values= salaries['Salary_USD'], aggfunc='mean'))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCompany_Size                  L              M             S\nJob_Category                                                \nData Analytics    112851.749217   95912.685246  53741.877000\nData Engineering  118939.035000  121287.060500  86927.136000\nData Science       96489.520105  116044.455864  62241.749250\nMachine Learning  140779.491529  100794.236842  78812.586462\nManagerial        190551.448800  150713.628000  31484.700000\nOther              92873.911385   89750.578667  69871.248000\n```\n:::\n:::\n\n\nÉsta es una función útil para examinar la combinación de frecuencias, así como para encontrar estadísticas agregadas. ¡Parece que el salario medio más alto es para roles de datos gerenciales en grandes empresas!\n\n## Generar nuevas Características\n\n-   Correlación\n\n::: {#5fc8b6a4 .cell execution_count=10}\n``` {.python .cell-code}\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n```\n:::\n\n\n![](images/paste-72.png)\n\n-   Viendo el tipo de datos\n\n::: {#125de9d6 .cell execution_count=11}\n``` {.python .cell-code}\nprint(planes.dtypes)\n```\n:::\n\n\n![](images/paste-73.png)\n\n-   Total Stops\n\n::: {#986acafc .cell execution_count=12}\n``` {.python .cell-code}\nprint(planes['Total_Stops'].value_counts())\n```\n:::\n\n\n![](images/paste-74.png)\n\nSe observa que es necesario eliminar algunos caracteres.\n\n-   Limpiando Total Stops\n\n::: {#7273f4a8 .cell execution_count=13}\n``` {.python .cell-code}\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stops', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stop', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace('non-stop', '0')\nplanes['Total_Stops'] = planes['Total_Stops'].astype(int)\n```\n:::\n\n\n-   Correlación\n\n::: {#81a8ca88 .cell execution_count=14}\n``` {.python .cell-code}\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n```\n:::\n\n\n![](images/paste-75.png)\n\n-   Fechas\n\n::: {#b866edee .cell execution_count=15}\n``` {.python .cell-code}\nprint(planes.dtypes)\n```\n:::\n\n\n![](images/paste-76.png)\n\n-   Extrayendo el mes y el día de la semana\n\n::: {#d20955e2 .cell execution_count=16}\n``` {.python .cell-code}\nplanes['month'] = planes['Date_of_Journey'].dt.month\nplanes['weekday'] = planes['Date_of_Journey'].dt.weekday\nprint(planes[['month', 'weekday', 'Date_of_Journey']].head())\n```\n:::\n\n\n![](images/paste-77.png)\n\n-   Tiempos de salidas y llegadas\n\n::: {#11476d37 .cell execution_count=17}\n``` {.python .cell-code}\nplanes['Dep_Hour'] = planes['Dep_Time'].dt.hour\nplanes['Arrival_Hour'] = planes['Arrival_Time'].dt.hour\n```\n:::\n\n\n-   Correlación\n\n![](images/paste-78.png)\n\nNo hay correlaciones, pero no lo sabríamos si no se hubieran generado nuevas características.\n\n-   Creando características\n\n::: {#73169006 .cell execution_count=18}\n``` {.python .cell-code}\nprint(planes['Price'].describe())\n```\n:::\n\n\n![](images/paste-79.png)\n\n| Rango             | Tipo de tiquete |\n|-------------------|-----------------|\n| \\<= 5228          | Economy         |\n| \\> 5528 \\<= 8355  | Premium Economy |\n| \\> 8355 \\<= 12373 | Business Class  |\n| \\> 12373          | First Class     |\n\n-   Estadística descriptiva\n\n::: {#4e1b3b1c .cell execution_count=19}\n``` {.python .cell-code}\ntwenty_fifth = planes['Price'].quantile(0.25)\nmedian = planes['Price'].median()\nseventy_fifth = planes['Price'].quantile(0.75)\nmaximum = planes['Price'].max()\n```\n:::\n\n\n-   Etiquetas y bins\n\n::: {#ec235b2e .cell execution_count=20}\n``` {.python .cell-code}\nlabels = ['Economy', 'Premium Economy', 'Business Class', 'First Class']\nbins = [0, twenty_fifth, median, seventy_fifth, maximum]\n```\n:::\n\n\n-   pd.cut()\n\n![](images/paste-80.png)\n\n::: {#c1fbd932 .cell execution_count=21}\n``` {.python .cell-code}\nplanes['Price_Category'] = pd.cut(planes['Price'], labels=labels, bins=bins)\n```\n:::\n\n\n-   Categoría de precios\n\n::: {#1d1a7596 .cell execution_count=22}\n``` {.python .cell-code}\nprint(planes[['Price', 'Price_Category']].head())\n```\n:::\n\n\n![](images/paste-81.png)\n\n-   Categoría de precio por aerolínea\n\n::: {#d8536395 .cell execution_count=23}\n``` {.python .cell-code}\nsns.countplot(data=planes, x='Airline', hue='Price_Category')\nplt.show()\n```\n:::\n\n\n![](images/paste-82.png)\n\n### Extraer características para la correlación\n\nEn este ejercicio trabajarás con una versión del conjunto de datos `salaries` que contiene una nueva columna llamada \"\\`date_of_response\".\n\nEl conjunto de datos se ha leído comjo un DataFrame de pandas, con \"`date_of_response`\" como tipo de datos `datetime`.\n\nTu tarea consiste en extraer los atributos fecha-hora de esta columna y, a continuación, crear un mapa de calor para visualizar los coeficientes de correlación entre las variables.\n\n::: {.callout-important collapse=\"true\"}\nPara realizar el ejercicio fue necesario bajar el DataFrame de Datacamp teniendo en cuenta la nueva columna, y cambiando el tipo de formato de la columna `date_of_response` usando los comandos:\n\n::: {#ddfdfcc2 .cell execution_count=24}\n``` {.python .cell-code}\nprint(salaries.to_csv(index=false))\n```\n:::\n\n\n:::\n\n::: {#54743d78 .cell execution_count=25}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nruta = './data/salaries_2.csv'\nsalaries = pd.read_csv(ruta)\n\n# Cambia el tipo de datos de date_of_response\nsalaries['date_of_response'] = pd.to_datetime(salaries['date_of_response'])\nsalaries.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Designation</th>\n      <th>date_of_response</th>\n      <th>Experience</th>\n      <th>Employment_Status</th>\n      <th>Salary_In_Rupees</th>\n      <th>Employee_Location</th>\n      <th>Company_Location</th>\n      <th>Company_Size</th>\n      <th>Remote_Working_Ratio</th>\n      <th>Salary_USD</th>\n      <th>Job_Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Machine Learning Scientist</td>\n      <td>2020-01-07</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>20688070.0</td>\n      <td>JP</td>\n      <td>JP</td>\n      <td>S</td>\n      <td>0.0</td>\n      <td>248256.840</td>\n      <td>Machine Learning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Big Data Engineer</td>\n      <td>2020-09-19</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>8674985.0</td>\n      <td>GB</td>\n      <td>GB</td>\n      <td>M</td>\n      <td>50.0</td>\n      <td>104099.820</td>\n      <td>Data Engineering</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Product Data Analyst</td>\n      <td>2020-11-21</td>\n      <td>MI</td>\n      <td>FT</td>\n      <td>1591390.0</td>\n      <td>HN</td>\n      <td>HN</td>\n      <td>S</td>\n      <td>0.0</td>\n      <td>19096.680</td>\n      <td>Data Analytics</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Machine Learning Engineer</td>\n      <td>2020-11-29</td>\n      <td>SE</td>\n      <td>FT</td>\n      <td>11935425.0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>L</td>\n      <td>50.0</td>\n      <td>143225.100</td>\n      <td>Machine Learning</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Analyst</td>\n      <td>2020-09-07</td>\n      <td>EN</td>\n      <td>FT</td>\n      <td>5729004.0</td>\n      <td>US</td>\n      <td>US</td>\n      <td>L</td>\n      <td>100.0</td>\n      <td>68748.048</td>\n      <td>Data Analytics</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n#### Instrucciones\n\n-   Extrae el mes de \"`date_of_response`\", almacenándolo como una columna llamada \"`month`\".\n\n-   Crea la columna \"`weekday`\", que contiene el día de la semana en que los participantes completaron la encuesta.\n\n-   Traza un mapa de calor, incluyendo las puntuaciones del coeficiente de correlación de Pearson.\n\n::: {#2afa25fe .cell execution_count=26}\n``` {.python .cell-code}\n# Get the month of the response\nsalaries['month'] = salaries['date_of_response'].dt.month\n\n# Extract the weekday of the response\nsalaries['weekday'] = salaries['date_of_response'].dt.weekday\n\n# Create a heatmap\nsns.heatmap(salaries.corr(numeric_only=True), annot=True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04_Convertir_analisis_exploratorio_en_accion_files/figure-html/cell-27-output-1.png){}\n:::\n:::\n\n\n¡Fantástica creación de características! Parece que no hay relaciones significativas entre nuestras variables numéricas, así que veamos si convertir los datos numéricos en clases ofrece información adicional.\n\n### Cálculo de los percentiles salariales\n\nTu tarea consiste en convertir la columna \"`Salary_USD`\" en categorías basadas en sus percentiles . Primero tienes que encontrar los percentiles y almacenarlos como variables.\n\n#### Instrucciones\n\n-   Halla el percentil 25 de \"`Salary_USD`\"\n\n-   Guarda la mediana de \"`Salary_USD`\" como `salaries_median`.\n\n-   Obtén el percentil 75 de los salaries\n\n::: {#4ac99140 .cell execution_count=27}\n``` {.python .cell-code}\n# Find the 25th percentile \ntwenty_fifth = salaries['Salary_USD'].quantile(0.25)\n\n# Save the median\nsalaries_median = salaries['Salary_USD'].median()\n\n# Gather the 75th percentile\nseventy_fifth = salaries['Salary_USD'].quantile(0.75)\n\nprint(twenty_fifth, salaries_median, seventy_fifth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n60880.691999999995 97488.552 143225.1\n```\n:::\n:::\n\n\n¡Parece que el rango intercuartil está entre 60881 y 143225 dólares! ¡Ahora usemos estas variables para agregar una columna categórica de salario en el DataFrame\n\n### Categorizar los salarios\n\n¡Ahora es el momento de crear una nueva categoría! Utilizarás las variables `twenty_fifth`, `salaries_median` y `seventy_fifth`, que creaste en el ejercicio anterior, para dividir los salarios en diferentes etiquetas.\n\nEl resultado será una nueva columna llamada \"`salary_level`\", que incorporarás a una visualización para analizar el salario de los encuestados y en empresas de distintos tamaños.\n\n#### Instrucciones\n\n1.  Crea `salaries_labels`, una lista que contenga \"`entry`\", \"`mid`\", \"`senior`\" y \"`exec`\".\n\n::: {#7ca6cd24 .cell execution_count=28}\n``` {.python .cell-code}\n# Create salary labels\nsalary_labels = ['entry', 'mid', 'senior', 'exec']\n```\n:::\n\n\n2.  Termina `salary_ranges`, añadiendo el percentil 25, la mediana, el percentil 75 y el valor más grande de \"`Salary_USD`\"\n\n::: {#fe7461db .cell execution_count=29}\n``` {.python .cell-code}\n# Create the salary ranges list\nsalary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries['Salary_USD'].max()]\n```\n:::\n\n\n3.  Divide \"`Salary_USD`\" en función de las etiquetas y rangos que hayas creado.\n\n::: {#2ffbed0b .cell execution_count=30}\n``` {.python .cell-code}\n# Create salary_level\nsalaries['salary_level'] = pd.cut(salaries['Salary_USD'], bins=salary_ranges, labels=salary_labels)\n```\n:::\n\n\n4.  Utiliza `sns.countplot()` para visualizar el reconteo de \"`Company_Size`\", factrorizando las etiquetas de nivel salarial.\n\n::: {#37cd7d95 .cell execution_count=31}\n``` {.python .cell-code}\n# Plot the count of salary levels at companies of different sizes\nsns.countplot(data=salaries, x='Company_Size', hue='salary_level')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04_Convertir_analisis_exploratorio_en_accion_files/figure-html/cell-32-output-1.png){}\n:::\n:::\n\n\nAl usar `pd.cut()` para dividir los datos numéricos en categorías, se puede ver que una gran proporción de trabajadores en empresas pequeñas reciben salarios de nivel de \"entrada\", mientras que más personal en empresas medianas son recompensados con salarios de nivel \"senior\". ¡Ahora vamos a ver cómo generar hipótesis a medida que se llega al final de la fase de EDA!\n\n## Generar hipótesis\n\nGenerar hipótesis es una tarea fundamental para los científicos de datos.\n\nAl realizar EDA, la pregunta que debemos hacernos es ¿Cómo sabemos que lo que estamos observando es verdadero?\n\nPor ejemplo:\n\n-   Si recopilamos nuevos datos sobre vuelos de un período de tiempo diferente ¿observaríamos los mismos resultados?\n\n-   Detectar relaciones, diferencias y patrones:\n\n    -   Usamos **Prueba de hipótesis**\n\n-   La prueba de hipótesis requiere previo a la recolección de datos:\n\n    -   Generar una hipótesis o pregunta.\n    -   Una decisión en la se pueda usar una prueba estadística\n\n-   Data snooping\n\n    -   Los análisis de datos excesivos, la generación de múltiples hipótesis y la ejecución de múltiples pruebas estadísticas\n\n-   Generación de Hipótesis\n\n    -   Se realiza usando análisis exploratorio de datos\n\n-   Próximos pasos\n\n    -   Diseñar nuestro experimento.\n    -   Envuelve pasos como:\n        -   Elegir una muestra\n        -   Calcular cuántos puntos de datos necesitamos\n        -   Decidir que prueba estadística ejecutar.\n\n### Comparar salarios\n\n¡El análisis exploratorio de datos es un paso crucial en la generación de hipótesis!\n\nSe te ha ocurrido una idea que te gustaría investigar: ¿los profesionales de los datos cobran más en Estados Unidos que en Gran Bretaña?\n\nTendrás que subconjuntar los datos en \"`Employee_Location`\" y elaborar un gráfico que muestre el salario medio entre los dos grupos.\n\n#### Instrucciones\n\n-   Filtra `salaries` donde \"`Employee_Location`\" es \"`US`\" o \"`GB`\", guardando como `usa_and_gb`.\n\n-   Utiliza `usa_and_gb` para crear un gráfico de barras que visualice \"`Salary_USD`\" frete a \"`Employee_Location`\".\n\n::: {#a0b75c4b .cell execution_count=32}\n``` {.python .cell-code}\n# Filter for employees in the US or GB\nusa_and_gb = salaries[salaries['Employee_Location'].isin(['US', 'GB'])]\n\n# Create a barplot of salaries by location\nsns.barplot(data=usa_and_gb, x='Employee_Location', y='Salary_USD')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04_Convertir_analisis_exploratorio_en_accion_files/figure-html/cell-33-output-1.png){}\n:::\n:::\n\n\nAl subconfigurar los datos, pudiste comparar directamente los salarios entre EE.UU. y Gran Bretaña. La visualización sugiere que has generado una hipótesis que vale la pena investigar formalmente para determinar si existe una diferencia real o no.\n\n### Elegir una hipótesis\n\nHas visto cómo las visualizaciones pueden utilizarse para generar hipótesis, ¡lo que las convierte en una parte crucial del análisis exploratorio de datos!\n\nEn este ejercicio, generarás un diagrama de barras para inspeccionar cómo difieren los salarios según el tamaño de la empresa y la situación laboral.\n\nComo referencia, hay cuatro valores:\n\n| Valor | Significado       |\n|-------|-------------------|\n| `CT`  | Contratista       |\n| `FL`  | Autónomo          |\n| `PT`  | A tiempo parcial  |\n| `FT`  | A tiempo completo |\n\n#### Instrucciones\n\n1. Elabora un diagrama de barras comparando \"`Salary_USD`\" por \"`Company_Size`\", factorizando \"`Employment_Status`\".\n\n::: {#ee166eaf .cell execution_count=33}\n``` {.python .cell-code}\n# Create a bar plot  of salary versus company size, factoring in employment status\nsns.barplot(data=salaries, x='Company_Size', y='Salary_USD', hue='Employment_Status')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04_Convertir_analisis_exploratorio_en_accion_files/figure-html/cell-34-output-1.png){}\n:::\n:::\n\n\n2. **Pregunta**\n¿ Cuál es una hipótesis razonable que se puede generar a partir de esta trama?\n\n**Respuestas Posibles**\n\n- [ ] Por término medio, las pequeñas empresas pagan menos a los empleados a tiempo parcial que las grandes empresas.\n- [ ] Los autónomos ganan más en las empresas medianas que en las pequeñas o grandes.\n- [X] Por término medio, las grandes empresas pagan más a los contratistas que las medianas.\n- [ ] No se puede generar ninguna hipótesis a partir de este gráfico.\n\nLos contratistas parecen se mejor pagados por las grandes empresas en promedio según los datos, ¡así que esta es una hipótesis razonable!\n\n",
    "supporting": [
      "04_Convertir_analisis_exploratorio_en_accion_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}
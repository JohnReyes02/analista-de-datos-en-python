[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anal铆sta de Datos en Python",
    "section": "",
    "text": "Bienvenida",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.html#descripci贸n-del-programa",
    "href": "index.html#descripci贸n-del-programa",
    "title": "Anal铆sta de Datos en Python",
    "section": "Descripci贸n del programa",
    "text": "Descripci贸n del programa\nDesarrolla tus habilidades de an谩nlisis de datos en Python. Adquiere las habilidades de analista de datos para manipular, analizar y visualizar datos. No necesitas experiencia en programac贸n.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/index.html",
    "href": "03_Manipulacion_de_datos_con_pandas/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\n Nivel: Principiante\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nPandas es la biblioteca de Python m谩s popular del mundo, utilizada para todo, desde la manipulaci贸n de datos hasta el an谩lisis de datos. En este curso, aprender谩s a manipular los DataFrames, mientras extraes, filtras y transformas conjuntos de datos del mundo real para su an谩lisis. Utilizando pandas explorar谩s todos los conceptos b谩sicos de la ciencia de datos. Utilizando datos del mundo real, como cifras de ventas de Walmart y series temporales de temperatura global, aprender谩s a importar, limpiar, calcular estad铆sticas y crear visualizaciones, 隆utilizando pandas para aumentar la potencia de Python!",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/index.html#m贸dulos-del-curso",
    "href": "03_Manipulacion_de_datos_con_pandas/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nTransformaci贸n de DataFrames\nAgregar DataFrames\nSegmentar e indexar DataFrames\nCrear y visualizar DataFrames",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/01_Transformacion_de_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/01_Transformacion_de_dataframes.html",
    "title": "Transformaci贸n de DataFrames",
    "section": "",
    "text": "Vamos a tratar los fundamentos de pandas. Aprende a inspeccionar los DataFrames y a realizar manipulaciones b谩sicas, como ordenar filas, hacer subconjuntos y a帽adir nuevas columnas.",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "<span class='chapter-number'>10</span> <span class='chapter-title'>Transformaci贸n de DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/02_Agregar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/02_Agregar_dataframes.html",
    "title": "Agregar DataFrames",
    "section": "",
    "text": "En este cap铆tulo, calcular谩s estad铆sticas sumarias en columnas del DataFrame y dominar谩s las estad铆sticas sumarias agrupadas y las tablas din谩micas.",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "<span class='chapter-number'>2</span> <span class='chapter-title'>Agregar DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/03_Segmentar_e_indexar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/03_Segmentar_e_indexar_dataframes.html",
    "title": "Segmentar e indexar DataFrames",
    "section": "",
    "text": "Los 铆ndices son nombres de filas y columnas sobrecargados. Aprende c贸mo pueden combinarse con la segmentaci贸n para obtener un potente subconjunto del DataFrame.",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "<span class='chapter-number'>12</span> <span class='chapter-title'>Segmentar e indexar DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/04_Crear_y_visualizar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/04_Crear_y_visualizar_dataframes.html",
    "title": "Crear y visualizar DataFrames",
    "section": "",
    "text": "Aprende a visualizar el contenido de tus DataFrames, a tratar los valores de datos que faltan y a importar y exportar datos a archivos CSV.",
    "crumbs": [
      "Manipulaci贸n de Datos con Pandas",
      "<span class='chapter-number'>13</span> <span class='chapter-title'>Crear y visualizar DataFrames</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html",
    "title": "Conceptos B谩sicos de la fusi贸n de datos",
    "section": "",
    "text": "Uni贸n interna\nAprende a fusionar datos dispares mediante uniones internas. Combinando informaci贸n de m煤ltiples fuentes, descubrir谩s perspectivas convincentes que antes pod铆an estar ocultas. Tambi茅n aprender谩s c贸mo la relaci贸n entre esas fuentes, de uno a uno o de uno a muchos, puede afectar a tu resultado.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>5</span> <span class='chapter-title'>Conceptos B谩sicos de la fusi贸n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#uni贸n-interna",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#uni贸n-interna",
    "title": "Conceptos B谩sicos de la fusi贸n de datos",
    "section": "",
    "text": "Qu茅 columna elegiremos para fusionar?\nChicago proporciona una lista de propietarios de taxis y veh铆culos con licencia para operar en la ciudad, por seguridad p煤blica. Tu objetivo es unir dos tablas. Una tabla se llama taxi_owners y contiene informaci贸n sobre los propietarios de las empresas de taxis, mientras que la otra se 铮llama taxi_vehe incluye informaci贸n sobre cada veh铆cul铮o de taxi.\n\nimport pandas as pd\n\n\ntaxi_owners = pd.read_pickle('./data/taxi_owners.p')\ntaxi_owners.head()\n\n\n\n\n\n\n\n\nrid\nvid\nowner\naddress\nzip\n\n\n\n\n0\nT6285\n6285\nAGEAN TAXI LLC\n4536 N. ELSTON AVE.\n60630\n\n\n1\nT4862\n4862\nMANGIB CORP.\n5717 N. WASHTENAW AVE.\n60659\n\n\n2\nT1495\n1495\nFUNRIDE, INC.\n3351 W. ADDISON ST.\n60618\n\n\n3\nT4231\n4231\nALQUSH CORP.\n6611 N. CAMPBELL AVE.\n60645\n\n\n4\nT5971\n5971\nEUNIFFORD INC.\n3351 W. ADDISON ST.\n60618\n\n\n\n\n\n\n\n\ntaxi_veh = pd.read_pickle('./data/taxi_vehicles.p')\ntaxi_veh.head()\n\n\n\n\n\n\n\n\nvid\nmake\nmodel\nyear\nfuel_type\nowner\n\n\n\n\n0\n2767\nTOYOTA\nCAMRY\n2013\nHYBRID\nSEYED M. BADRI\n\n\n1\n1411\nTOYOTA\nRAV4\n2017\nHYBRID\nDESZY CORP.\n\n\n2\n6500\nNISSAN\nSENTRA\n2019\nGASOLINE\nAGAPH CAB CORP\n\n\n3\n2746\nTOYOTA\nCAMRY\n2013\nHYBRID\nMIDWEST CAB CO, INC\n\n\n4\n5922\nTOYOTA\nCAMRY\n2013\nHYBRID\nSUMETTI CAB CO\n\n\n\n\n\n\n\n\nInstrucciones:\nElige una columna que utilizar铆as para fusionar las dos tablas utilizando el m茅todo .merge().\nRespuestas posibles\n\non=rid\non=vid\non=year\non=zip\n\n\n\n\nTu primera uni贸n interna\nTe han encargado que averig眉es cu谩les son los tipos de combustibles m谩s utlizados en los taxis de Chicago. Para completar el an谩lisis, tienes que fusionar las tablas taxi_owners y taxi_veh en la columna vid. A continuaci贸n, puedes utilizar la tabla combinada junto con el m茅todo .values_counts() para encontrar el fuel_type m谩s com煤n.\n\nInstrucciones:\n\nFusiona taxi_owners con taxi_veh en la columna vid y guarda el resultado en taxi_own_veh.\n\n\n# Merge the taxi_owners and taxi_veh tables\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\ntaxi_own_veh.head()\n\n# Print the column names of taxi_own_veh\nprint(taxi_own_veh.columns)\n\nIndex(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n       'fuel_type', 'owner_y'],\n      dtype='object')\n\n\n\nEstablece los sufijos izquierdo y derecho de la tabla para las columnas solapadas de la fusi贸n en _own y _veh, respectivamente.\n\n\n# Merge the taxi_owners and taxi_veh tables setting a suffix\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\ntaxi_own_veh.head()\n\n# Print the column names of taxi_own_veh\nprint(taxi_own_veh.columns)\n\nIndex(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n       'fuel_type', 'owner_veh'],\n      dtype='object')\n\n\n\nSelecciona la columna fuel_type de taxi_own_veh e imprime value_counts() para encontrar los fuel_type m谩s utilizados.\n\n\n# Merge the taxi_owners and taxi_veh tables setting a suffix\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n\n# Print the value_counts to find the most popular fuel_type\nprint(taxi_own_veh['fuel_type'].value_counts())\n\nfuel_type\nHYBRID                    2792\nGASOLINE                   611\nFLEX FUEL                   89\nCOMPRESSED NATURAL GAS      27\nName: count, dtype: int64\n\n\n\n\n\nUniones internas y n煤mero de filas devueltas\nTodas las fusiones que has estudiado hasta ahora se llaman uniones internas. Es necesario comprender que las uniones internas solo devuelven las filas con valores coincidentes en ambas tablas. Explorar谩s esto m谩s a fondo revisando la fusi贸n entre las tablas wards y census, y compar谩ndola despu茅s con fusiones de copias de estas tablas ligeramente alteradas, denominadas wards_altered y census_altered. La primera fila de la columna wards se ha modificado en las tablas alteradas. Examinar谩s c贸mo afecta esto a la fusi贸n entre ellos.\n\nwards = pd.read_pickle('./data/ward.p')\nwards.head()\n\n\n\n\n\n\n\n\nward\nalderman\naddress\nzip\n\n\n\n\n0\n1\nProco \"Joe\" Moreno\n2058 NORTH WESTERN AVENUE\n60647\n\n\n1\n2\nBrian Hopkins\n1400 NORTH ASHLAND AVENUE\n60622\n\n\n2\n3\nPat Dowell\n5046 SOUTH STATE STREET\n60609\n\n\n3\n4\nWilliam D. Burns\n435 EAST 35TH STREET, 1ST FLOOR\n60616\n\n\n4\n5\nLeslie A. Hairston\n2325 EAST 71ST STREET\n60649\n\n\n\n\n\n\n\n\ncensus = pd.read_pickle('./data/census.p')\ncensus.head()\n\n\n\n\n\n\n\n\nward\npop_2000\npop_2010\nchange\naddress\nzip\n\n\n\n\n0\n1\n52951\n56149\n6%\n2765 WEST SAINT MARY STREET\n60647\n\n\n1\n2\n54361\n55805\n3%\nWM WASTE MANAGEMENT 1500\n60622\n\n\n2\n3\n40385\n53039\n31%\n17 EAST 38TH STREET\n60653\n\n\n3\n4\n51953\n54589\n5%\n31ST ST HARBOR BUILDING LAKEFRONT TRAIL\n60653\n\n\n4\n5\n55302\n51455\n-7%\nJACKSON PARK LAGOON SOUTH CORNELL DRIVE\n60637\n\n\n\n\n\n\n\n\nwards_altered = wards.copy()\nwards_altered.loc[0, 'ward'] = 61\nwards_altered.head()\n\n\n\n\n\n\n\n\nward\nalderman\naddress\nzip\n\n\n\n\n0\n61\nProco \"Joe\" Moreno\n2058 NORTH WESTERN AVENUE\n60647\n\n\n1\n2\nBrian Hopkins\n1400 NORTH ASHLAND AVENUE\n60622\n\n\n2\n3\nPat Dowell\n5046 SOUTH STATE STREET\n60609\n\n\n3\n4\nWilliam D. Burns\n435 EAST 35TH STREET, 1ST FLOOR\n60616\n\n\n4\n5\nLeslie A. Hairston\n2325 EAST 71ST STREET\n60649\n\n\n\n\n\n\n\n\ncensus_altered = census.copy()\ncensus_altered.loc[0, 'ward'] = None\ncensus_altered.head()\n\n\n\n\n\n\n\n\nward\npop_2000\npop_2010\nchange\naddress\nzip\n\n\n\n\n0\nNone\n52951\n56149\n6%\n2765 WEST SAINT MARY STREET\n60647\n\n\n1\n2\n54361\n55805\n3%\nWM WASTE MANAGEMENT 1500\n60622\n\n\n2\n3\n40385\n53039\n31%\n17 EAST 38TH STREET\n60653\n\n\n3\n4\n51953\n54589\n5%\n31ST ST HARBOR BUILDING LAKEFRONT TRAIL\n60653\n\n\n4\n5\n55302\n51455\n-7%\nJACKSON PARK LAGOON SOUTH CORNELL DRIVE\n60637\n\n\n\n\n\n\n\n\nInstrucciones:\n\nFusiona wards y census en la columna ward y guarda el resultado en ward_census.\n\n\n# Merge the wards and census tables on the ward column\nward_census = wards.merge(census, on='ward')\n\n# Print the shape of wards_census\nprint(f'ward_census table shape: {ward_census.shape}')\n\nward_census table shape: (50, 9)\n\n\n\nFusiona las tablas merge_altered y census en la columna ward y observa la diferencia en las filas devueltas.\n\n\n# Print the first few rows of the wards_altered table to view the change\nprint(wards_altered[['ward']].head())\n\n# Merge the wards_altered and census tables on the ward column\nwards_altered_census =  wards_altered.merge(census, on='ward')\n\n# Print the shape of wards_altered_census\nprint(f'wards_altered_census table shape: {wards_altered_census.shape}')\n\n  ward\n0   61\n1    2\n2    3\n3    4\n4    5\nwards_altered_census table shape: (49, 9)\n\n\n\nFusiona las tablas wards y census_altered en la columna ward y observa la diferencia en las filas devueltas.\n\n\n# Print the first few rows of the wards_altered table to view the change\nprint(census_altered[['ward']].head())\n\n# Merge the wards_altered and census tables on the ward column\nwards_altered_census =  wards.merge(census_altered, on='ward')\n\n# Print the shape of wards_altered_census\nprint(f'wards_altered_census table shape: {wards_altered_census.shape}')\n\n   ward\n0  None\n1     2\n2     3\n3     4\n4     5\nwards_altered_census table shape: (49, 9)\n\n\nEn el paso 1, el .merge() devolvi贸 una tabla con el mismo n煤mero de filas que la tabla original wards. Sin embargo, en los pasos 2 y 3, al usar las tablas alteradas con la primera fila alterada de la columna ward, el n煤mero de filas devueltas fue menor. No hab铆a un valor coincidente en la columna ward de la otra tabla. Recuerda que .merge() solo devuelve filas donde los valores coinciden en ambas tablas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>5</span> <span class='chapter-title'>Conceptos B谩sicos de la fusi贸n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#relaciones-de-uno-a-muchos",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#relaciones-de-uno-a-muchos",
    "title": "Conceptos B谩sicos de la fusi贸n de datos",
    "section": "Relaciones de uno a muchos",
    "text": "Relaciones de uno a muchos\nEn una relaci贸n de uno a muchos cada fila de la tabla izquierda esta relacionada con una o varias filas de la tabla derecha.\nA continuaci贸n se muestran algunos ejemplos de relaci贸n uno a uno y relaci贸n uno a muchos:\n\n\n\n\n\n\n\nUno a uno\nUno a muchos\n\n\n\n\nLa relaci贸n entre products y inventory\nLa relaci贸n entre products y orders\n\n\nLa relaci贸n entre customery cust_tax_info\nLa relaci贸n entre customersy orders\n\n\n\n\nFusi贸n de uno a muchos\nUna empresa puede tener uno o varios propietarios. En este ejercicio, seguir谩s adquiriendo experiencia con las uniones de uno a muchos fusionando una tabla de propietarios de empresas, llamada biz_owners, con la tabla licenses. Recuerda de la lecci贸n de video que, con una relaci贸n de uno a muchos, una fila de la tabla izquierda puede repetirse si est谩 relacionada con varias filas de la tabla de la derecha. En esta lecci贸n, profundizar谩s en este tema averiguando cu谩l es el t铆tulo de propietario de empresa m谩s habitual (por ejemplo, secretario, CEO, o vicepresidente).\n\nlicenses = pd.read_pickle('./data/licenses.p')\nlicenses.head()\n\n\n\n\n\n\n\n\naccount\nward\naid\nbusiness\naddress\nzip\n\n\n\n\n0\n307071\n3\n743\nREGGIE'S BAR & GRILL\n2105 S STATE ST\n60616\n\n\n1\n10\n10\n829\nHONEYBEERS\n13200 S HOUSTON AVE\n60633\n\n\n2\n10002\n14\n775\nCELINA DELI\n5089 S ARCHER AVE\n60632\n\n\n3\n10005\n12\nNaN\nKRAFT FOODS NORTH AMERICA\n2005 W 43RD ST\n60609\n\n\n4\n10044\n44\n638\nNEYBOUR'S TAVERN & GRILLE\n3651 N SOUTHPORT AVE\n60613\n\n\n\n\n\n\n\n\nbiz_owners = pd.read_pickle('./data/business_owners.p')\nbiz_owners.head()\n\n\n\n\n\n\n\n\naccount\nfirst_name\nlast_name\ntitle\n\n\n\n\n0\n10\nPEARL\nSHERMAN\nPRESIDENT\n\n\n1\n10\nPEARL\nSHERMAN\nSECRETARY\n\n\n2\n10002\nWALTER\nMROZEK\nPARTNER\n\n\n3\n10002\nCELINA\nBYRDAK\nPARTNER\n\n\n4\n10005\nIRENE\nROSENFELD\nPRESIDENT\n\n\n\n\n\n\n\n\nInstrucciones:",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>5</span> <span class='chapter-title'>Conceptos B谩sicos de la fusi贸n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html",
    "href": "04_Unir_datos_con_pandas/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\n Nivel: Intermedio\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nSer capaz de combinar y trabajar con m煤ltiples conjuntos de datos es una habilidad esencial para cualquier aspirante a cient铆fico de datos. pandas es una piedra angular crucial del ecosistema de ciencia de datos de Python, y Stack Overflow registra 5 millones de visitas a preguntas sobre pandas. Aprende a manejar m煤ltiples DataFrames combin谩ndolos, organiz谩ndolos, uni茅ndolos y remodel谩ndolos mediante pandas. Trabajar谩s con conjuntos de datos del Banco Mundial y de la ciudad de Chicago. Terminar谩s el curso con un s贸lido conjunto de habilidades para unir datos en pandas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html#m贸dulos-del-curso",
    "href": "04_Unir_datos_con_pandas/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nConceptos b谩sicos de la fusi贸n de datos\nFusionar tablas con distintos tipos de uni贸n\nFusi贸n y concatenaci贸n avanzadas\nFusionar datos ordenados y series temporales",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html#datasets",
    "href": "04_Unir_datos_con_pandas/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/02_Fusionar_tablas_distintos_tipos.html",
    "href": "04_Unir_datos_con_pandas/02_Fusionar_tablas_distintos_tipos.html",
    "title": "Fusionar tablas con distintos tipos de uni贸n",
    "section": "",
    "text": "Lleva tu conocimiento de las uniones al siguiente nivel. En este cap铆tulo, trabajar谩s con datos de pel铆culas de TMDb mientras aprendes sobre las uniones izquierda, derecha y externa. Tambi茅n descubrir谩s c贸mo fusionar una tabla consigo misma y c贸mo fusionar en un 铆ndice DataFrame.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>6</span> <span class='chapter-title'>Fusionar tablas con distintos tipos de uni贸n</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/03_Fusion_y_concatenacion_avanzadas.html",
    "href": "04_Unir_datos_con_pandas/03_Fusion_y_concatenacion_avanzadas.html",
    "title": "Fusi贸n y concatenaci贸n avanzadas",
    "section": "",
    "text": "En este cap铆tulo, aprovechar谩s potentes t茅cnicas de filtrado, incluidas las semiuniones y las antiuniones. Tambi茅n aprender谩s a pegar DataFrames combin谩ndolos verticalmente y a utilizar la funci贸n pandas.concat para crear nuevos conjuntos de datos. Por 煤ltimo, como los datos rara vez est谩n limpios, tambi茅n aprender谩s a validar tus estructuras de datos reci茅n combinadas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>7</span> <span class='chapter-title'>Fusi贸n y concatenaci贸n avanzadas</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/04_Fusionar_datos_ordenados_y_series_temporales.html",
    "href": "04_Unir_datos_con_pandas/04_Fusionar_datos_ordenados_y_series_temporales.html",
    "title": "Fusionar datos ordenados y series temporales",
    "section": "",
    "text": "En este cap铆tulo final, dar谩s un paso adelante y aprender谩s a aplicar los m茅todos especializados de pandas para fusionar series temporales y datos ordenados con datos financieros y econ贸micos del mundo real de la ciudad de Chicago. Tambi茅n aprender谩s a consultar las tablas resultantes utilizando un formato tipo SQL, y a desagrupar los datos utilizando el m茅todo de fusi贸n.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>8</span> <span class='chapter-title'>Fusionar datos ordenados y series temporales</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\n Nivel: Intermedio\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nLa estad铆stica es el estudio de c贸mo recopilar, analizar y extraer conclusiones a partir de los datos. Es una herramienta enormemente valiosa que puedes utilizar para enfocar el futuro e inferir la respuesta a montones de preguntas. Por ejemplo, 驴cu谩l es la probabilidad de que alguien compre tu producto, cu谩ntas llamadas recibir谩 tu equipo de asistencia y cu谩ntas tallas de vaqueros deber铆as fabricar para que le queden bien al 95 % de la poblaci贸n? En este curso, descubrir谩s c贸mo responder a preguntas como estas a medida que aumentas tus competencias estad铆sticas y aprendes a calcular medias, utilizar diagramas de dispersi贸n para mostrar la relaci贸n entre valores num茅ricos y calcular la correlaci贸n. Tambi茅n abordar谩s la probabilidad, columna vertebral del razonamiento estad铆stico, y aprender谩s a utilizar Python para realizar un estudio bien dise帽ado que te permita extraer tus propias conclusiones a partir de los datos.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html#m贸dulos-del-curso",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nS铆ntesis estad铆stica\nN煤meros aleatorios y probabilidad\nM谩s distribuciones y el teorema del l铆mite central\nCorrelaci贸n y dise帽o de experimentos",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html#datasets",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\namir_deals.csv\nfood_consumption.csv\nworld_happiness_add_sugar.csv\nworld_happiness.csv",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html",
    "title": "Mas distribuciones y el teorema del l铆mite central",
    "section": "",
    "text": "La distribuci贸n normal",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>11</span> <span class='chapter-title'>Mas distribuciones y el teorema del l铆mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci贸n-normal",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci贸n-normal",
    "title": "Mas distribuciones y el teorema del l铆mite central",
    "section": "",
    "text": "Distribuci贸n de las ventas de Amir\n\n\nProbabilidades de la distribuci贸n normal\n\n\nSimulaci贸n de ventas en nuevas condiciones de mercado\n\n\nQu茅 mercado es el mejor?",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>11</span> <span class='chapter-title'>Mas distribuciones y el teorema del l铆mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#teorema-del-l铆mite-central",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#teorema-del-l铆mite-central",
    "title": "Mas distribuciones y el teorema del l铆mite central",
    "section": "Teorema del l铆mite central",
    "text": "Teorema del l铆mite central\n\nVisualizar distribuciones muestrales\n\n\nCTL en acci贸n\n\n\nLa media de las medias",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>11</span> <span class='chapter-title'>Mas distribuciones y el teorema del l铆mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci贸n-de-poisson",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci贸n-de-poisson",
    "title": "Mas distribuciones y el teorema del l铆mite central",
    "section": "La distribuci贸n de Poisson",
    "text": "La distribuci贸n de Poisson\n\nProceso de Poisson\n\nProcesos que parecen ocurrir a un ritmo determinado, pero completamente aleatorio.\nEjemplos:\n\nEl n煤mero de animales adoptados de un refugio por semana.\nEl n煤mero de personas que llegan a un restaurante cada hora.\nEl n煤mero de terremotos al a帽o en California.\n\nLa unidad de tiempo, como, horas, semanas o a帽os es irrelevante siempre que sean coherentes.\n\nDistrubici贸n de Poisson\n\nLa probabilidad de que ocurra un n煤mero determinado de sucesos en un periodo de tiempo.\nEjemplos\n\nProbabilidad de &gt;= 5 animales adoptados en una semana.\nProbabilidad de que 12 personas lleguen a un restaurante en una hora.\nProbabilidad &lt; 20 terremotos en California en un a帽o.\n\n\nLambda (\\(\\lambda\\))\n\n\\(\\lambda\\): N煤mero de eventos promedio por intervalo de tiempo.\n\nN煤mero promedio de adopciones por semana = 8.\n\n\n\nLambda es el pico de la distribuci贸n\n\nCTL contin煤a aplicando\n\n\n\nIdentificar lambda\nAhora que has aprendido sobre la distribuci贸n de Poisson, sabes que su forma se describe mediante un valor llamado lambda. En este ejercicio emparejar谩s histogramas con valores lambda.\n\n\n\n\n\n\n\n\nlambda = 1\nlambda = 4\nlambda = 8\n\n\n\n\n\n\n\n\n\n\nLa distribuci贸n de Poisson es una familia de distribuciones, igual que las distribuciones uniforme, binomial o normal.\n\n\nSeguimiento de las respuestas de los clientes potenciales\nTu empresa utiliza un software de ventas para hacer un seguimiento de los nuevos clientes potenciales. Los organiza en una cola para que cualquiera pueda hacer el seguimiento de uno cuando tenga un poco de tiempo libre. Dado que el n煤mero de respuestas de clientes potenciales es un resultado contable a lo largo de un periodo de tiempo, esta situaci贸n corresponde a una distribuci贸n de Poisson. De media, Amir responde a 4 clientes potenciales cada d铆a. En este ejercicio, calcular谩s las probabilidades de que Amir responda a distintos n煤meros de clientes potenciales.\n\nInstrucciones:\n\nImporta poisson de scipy.stats y calcula la problabilidad de que Amir responda a 5 clientes potenciales en un d铆a, dado que responde a una media de 4.\n\n\n# Import poisson from scipy.stats\nfrom scipy.stats import poisson\n\n# Probability of 5 responses\nprob_5 = poisson.pmf(5, 4) # (deseado, media)\nprint(prob_5)\n\n0.1562934518505317\n\n\n\nEl compa帽ero de trabajo de Amir responde a una media de 5.5 clientes potenciales al d铆a. Cu谩l es la probabilidad a que responda a 5 clientes potenciales en un d铆a?\n\n\n# Probability of 5 responses\nprob_coworker = poisson.pmf(5, 5.5)  # (deseado, media)\nprint(prob_coworker)\n\n0.17140068409793663\n\n\n\nCu谩l es la probabilidad de que Amir responda a 2 o menos clientes potenciales en en un d铆a?\n\n\n# Probability of 2 or fewer responses\nprob_2_or_less = poisson.cdf(2, 4) # &lt;= cdf(deseado, media)\nprint(prob_2_or_less)\n\n0.2381033055535443\n\n\n\nCu谩l es la probabilidad de que Amir responda a m谩s de 10 clientes potenciales en 1 d铆a?\n\n\n# Probability of &gt; 10 responses\nprob_over_10 = 1 - poisson.cdf(10, 4)\nprint(prob_over_10)\n\n0.0028397661205137315\n\n\nTener en cuenta que si se proporciona poisson.pmf o poisson.cdf con un n煤mero no entero , arroja un error ya que la distribuci贸n de Poisson solo se aplica a enteros.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>11</span> <span class='chapter-title'>Mas distribuciones y el teorema del l铆mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#m谩s-distribuciones-de-probabilidad",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#m谩s-distribuciones-de-probabilidad",
    "title": "Mas distribuciones y el teorema del l铆mite central",
    "section": "M谩s distribuciones de probabilidad",
    "text": "M谩s distribuciones de probabilidad\n\nDistribuci贸n exponencial\n\nProbabilidad en que transcurra cierto tiempo entre eventos de Poisson.\nEjemplos\n\nProbabilidad &gt; 1 d铆a entre adopciones.\nProbabilidad &lt; 10 minutos entre llegadas a restaurantes.\nProbabilidad de 6 a 8 meses entre terremotos.\n\nTambi茅n usa lambda \\(\\lambda\\)\nContinua (tiempo)\nValor esperado de la distribuci贸n exponencial\n\nMide la frecuencia en terminos de tiempo entre sucesos.\n\n\nDistribuci贸n T (estudiante)\n\nForma similar a la distribuci贸n normal.\n\n\nGrados de libertad (DoF)\n\nTiene un par谩metro de grados de libertad (df) que afecta el grosor de las colas de la distribuci贸n.\n\n\nBajo df = Colas m谩s gruesas y mayor desviaci贸n estandar.\nAlto df = Similar a la distribuci贸n normal.\n\n\nDistribuci贸n Log-normal\n\nLas variables que siguen una distribuci贸n log-normal tiene un logaritmo que se distribuye normalmente. Da lugar a distribuciones sesgadas.\nEjemplos\n\nDuraci贸n de las partidas de ajedrez.\nLa presi贸n arterial en adultos.\nN煤mero de hospitalizaciones en el brote de SARS en el 2003.\n\n\n\n\nArrastrar y colocar distribuciones\nLlegados a este punto, has aprendido sobre tantas distribuciones de probabilidad diferentes que puede ser dif铆cil recordar cu谩l es cu谩l. En este ejercicio, practicar谩s la distinci贸n entre distribuciones y la identificaci贸n de la distribuci贸n que mejor se ajusta a distintas situaciones.\n\n\n\n\n\n\n\n\nPoisson\nExponencial\nBinomial\n\n\n\n\nN煤mero de clientes que entran a una tienda cada hora.\nTiempo que transcurre hasta que alguien paga su pr茅stamo.\nN煤mero de personas de un grupo de 30 que aprueban el examen de conducir.\n\n\nN煤mero de productos vendidos cada semana.\nTiempo que transcurre hasta que el siguiente cliente realiza su compra.\n\n\n\n\n\n\nTiempo de modelado entre clientes potenciales\nPara evaluar mejor el rendimiento de Amir, quieres saber cu谩nto tarda en responder a un cliente potencial despu茅s de abrirlo. De media, responde a 1 solicitud cada 2,5 horas. En este ejercicio, calcular谩s las probabilidades de que pasen diferentes cantidades de tiempo entre que Amir recibe un cliente potencial y env铆a una respuesta.\n\nInstrucciones:\n\nImporta expon desde scipy.stats. Cu谩l es la probabilidad de que Amir tarde menos de una hora en responder a un cliente potencial.\n\n\n# Import expon from scipy.stats\nfrom scipy.stats import expon\n\n# Print probability response takes &lt; 1 hour\nprint(expon.cdf(1, scale=2.5))\n\n0.3296799539643607\n\n\n\nCu谩l es la probabilidad de que Amir tarde m谩s de 4 horas en responder a un cliente potencial?\n\n\n# Print probability response takes &gt; 4\nprint(1 - expon.cdf(4, scale=2.5))\n\n0.20189651799465536\n\n\n\nCu谩l es la probabilidad de que Amir tarde 3-4 horas en responder a un cliente potencial?\n\n\n# Print probability response takes 3-4 hours\nprint(expon.cdf(4, scale=2.5) - expon.cdf(3, scale=2.5))\n\n0.09929769391754684\n\n\nHay solo alrededor de un 20% de probabilidad de que Amir tarde m谩s de 4 horas en responder, as铆 que es bastante r谩pido en sus respuestas.\n\n\n\nLa disttibuci贸n t\nQu茅 afirmaci贸n no es cierta respecto a la distrubuci贸n t?\n\nLa distribuci贸n t tiene colas m谩s gruesas que la distribuci贸n normal.\nUna distribuci贸n t con altos grados de libertad se parece a la distribuci贸n normal.\nEl n煤mero de grados de libertad afecta a la varianza de la distribuci贸n.\nLa distribuci贸n t est谩 sesgada.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>11</span> <span class='chapter-title'>Mas distribuciones y el teorema del l铆mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html",
    "title": "12 Correlaci贸n y dise帽o de experimentos",
    "section": "",
    "text": "12.1 Correlaci贸n\nEn este cap铆tulo, aprender谩s a cuantificar la fuerza de una relaci贸n lineal entre dos variables, y explorar谩s c贸mo las variables de confusi贸n pueden afectar a la relaci贸n entre otras dos variables. Tambi茅n ver谩s c贸mo el dise帽o de un estudio puede influir en sus resultados, cambiar la forma en que deben analizarse los datos y afectar potencialmente a la fiabilidad de tus conclusiones.\nimport seaborn as sns\nsns.scatterplot(x='sleep_total', y='sleep_rem', data=msleep)\nplt.show()\nimport seaborn as sns\nsns.lmplot(x='sleep_total', y='sleep_rem', data=msleep, ci=None)\nplt.show()\nmsleep['sleep_total'].corr(msleep['sleep_rem'])\nmsleep['sleep_rem'].corr(msleep['sleep_total'])",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>12</span> <span class='chapter-title'>Correlaci贸n y dise帽o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#correlaci贸n",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#correlaci贸n",
    "title": "12 Correlaci贸n y dise帽o de experimentos",
    "section": "",
    "text": "Realci贸n entre dos variables\n\n\nx = variable explicativa o independiente.\ny = variable de respuesta o dependiente.\n\nCoeficiente de correlaci贸n\n\nCuantifica la relaci贸n lineal entre dos variables.\nEs un m煤mero entre -1 y 1.\nLa magnitud corresponde a la fuerza de la relaci贸n.\nSigno (+ o -) corresponde a la direcci贸n de la relaci贸n.\n\nMagnitud = Fuerza de la relaci贸n\n\n\n\n\n\n\n\n\n\n0.99 (Muy fuerte relaci贸n)\n\n0.75 (Fuerte relaci贸n ) | 0.56 (moderada relaci贸n) | |  |  |\n\n\n0.21 (d茅bil relaci贸n)\n\n0.04 (sin relaci贸n)\n\n\nConocer el valor de x no nos dice nada acerca de y.\n\n\n\n\n\nSigno = Direcci贸n\n\n\n\n\n\n\n\n0.75: Como x incrementa y incrementa\n-0.75: Como x incrementa y decrece\n\n\n\n\n\n\n\n\n\nVisualizaci贸n de relaciones\n\n\n\n\nA帽adir una linea de tendencia\n\n\n\n\nCalcular el coeficiente de correlaci贸n entre dos series\n\n\n\n\nMuchas formas de calcular la correlaci贸n\n\nLa usada en el curso: Correlaci贸n producto momento de Pearson (\\(r\\))\n\nEs la m谩s com煤n\n\\(\\bar{x} = \\text{media de } x \\\\\\)\n\\(\\sigma_x = \\text{desviaci贸n estandar de } x\\)\n\\[\\begin{align*}\n    r &= \\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})(y_i - \\bar{y})}{\\sigma_x \\times \\sigma_y}\n\\end{align*}\\]\n\nVariaciones en esta f贸rmula:\n\nKendalls tau\nSpearmans rho\n\n\n\n\n12.1.1 Adivina la correlaci贸n\n驴Cu谩l de las siguientes afirmaciones NOT es verdadera sobre la correlaci贸n?\n\nSi la correlaci贸n entre x y y tiene una magnitud elevada, los puntos de datos se agrupar谩n estrechamente alrededor de una l铆nea.\nLa correlaci贸n puede escribirse como r.\nSi x e y est谩n correlacionados negativamente, los valores de y disminuyen a medida que aumentan los de x.\nLa correlaci贸n no puede ser 0.\n\n\n\n12.1.2 Relaciones entre variables\nEn este cap铆tulo, trabajar谩s con un conjunto de datos world_happiness que contiene los resultados de 2019 World Happiness Report. El informe punt煤a a diferentes pa铆ses en funci贸n de lo felices que son sus habitantes. Tambi茅n clasifica a cada pa铆s en funci贸n de diversos aspectos sociales, como el apoyo social, la libertad, la corrupci贸n y otros. El conjunto de datos tambi茅n incluye el GDP per c谩pita y la esperanza de vida de cada pa铆s.\nEn este ejercicio, examinar谩s la relaci贸n entre la esperanza de vida de un pa铆s (life_exp) y la puntuaci贸n de felicidad (happiness_score) tanto visual como cuantitativamente. seaborn como sns, matplotlib.pyplot como plt y pandas como pd est谩n cargados y world_happiness est谩 disponible.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nworld_happiness = pd.read_csv('./data/world_happiness.csv')\nprint(world_happiness.head())\n\n   Unnamed: 0      country  social_support  freedom  corruption  generosity  \\\n0           1      Finland             2.0      5.0         4.0        47.0   \n1           2      Denmark             4.0      6.0         3.0        22.0   \n2           3       Norway             3.0      3.0         8.0        11.0   \n3           4      Iceland             1.0      7.0        45.0         3.0   \n4           5  Netherlands            15.0     19.0        12.0         7.0   \n\n   gdp_per_cap  life_exp  happiness_score  \n0        42400      81.8              155  \n1        48300      81.0              154  \n2        66300      82.6              153  \n3        47900      83.0              152  \n4        50500      81.8              151  \n\n\n\n12.1.2.1 Instrucciones:\n\n\n\n\nCrea un diagrama de dispersi贸n de happiness_score frente a life_exp (sin l铆nea de tendencia) utilizando seaborn.\nMuestra el gr谩fico.\n\n\n# Create a scatterplot of happiness_score vs. life_exp ando show\nsns.scatterplot(x='life_exp', y='happiness_score', data=world_happiness)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nCrea un diagrama de dispersi贸n de happiness_score frente a life_exp con una l铆nea de tendencia lineal utilizando seaborn, estableciendo ci en None.\nMuestra el gr谩fico.\n\n\n# Create scatterplot of happiness_score vs life_exp with trendline\nsns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPregunta\nSeg煤n el diagrama de dispersi贸n, cu谩l es la correlaci贸n m谩s probable entre life_exp y happiness_score?\nRespuestras posibles\n\n0.3\n-0.3\n0.8\n-0.8\n\n\nCalcula la correlaci贸n entre life_exp y happiness_score. Gu谩rdala como cor.\n\n\n# Correlation between life_exp and happiness_score\ncor =  world_happiness['life_exp'].corr(world_happiness['happiness_score'])\n\nprint(cor)\n\n0.7802249053272065\n\n\nLos diagramas de dispersi贸n con l铆neas de tendencia son una excelente manera de verificar que una relaci贸n estre dos variables es realmente lineal.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>12</span> <span class='chapter-title'>Correlaci贸n y dise帽o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#advertencias-sobre-la-correlaci贸n",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#advertencias-sobre-la-correlaci贸n",
    "title": "12 Correlaci贸n y dise帽o de experimentos",
    "section": "12.2 Advertencias sobre la correlaci贸n",
    "text": "12.2 Advertencias sobre la correlaci贸n\n\nRelaciones no lineales\n\nSiempre que sea posible visualizar los datos.\n\nTransformaci贸n logaritmica\n\nEs posible usarla cuando hayan datos muy sesgados.\n\nOtras transformaciones\n\nTransformaci贸n logar铆tmica (log(x))\nTransformaci贸n ra铆z cuadrada (sqrt(x))\nTransformaci贸n rec铆proca (1 / x)\nCombinations de esteas, por ejemplo:\n\nlog(x) y log(y)\nsqrt(x) y 1 / y\n\n\nPor qu茅 usar una transformaci贸n?\n\nCiertos m茅todos estad铆sticos se basan en que las variables tengan una relaci贸n lineal.\n\nCoeficiente de correlaci贸n\nRegresi贸n lineal.\n\n\nLa correlaci贸n no implica causalidad.\nSi x est谩 correlacionada con y no significa que x cause y.\nConfusi贸n\nEste fen贸meno puede dar lugar a correlaciones espurias.\n\n\n12.2.1 Qu茅 no puede medir la correlaci贸n?\nAunque el coeficiente de correlaci贸n es una forma c贸moda de cuantificar la fuerza de una relaci贸n entre dos variables, dista mucho de ser perfecto. En este ejercicio, explorar谩s una de las advertencias sobre el coeficiente de correlaci贸n examinando la relaci贸n entre el GDP per c谩pita de un pa铆s (gdp_per_cap) y la puntuaci贸n de felicidad.\n\n\n12.2.2 Instrucciones:\n\n\n\n\nCrea un diagrama de dispersi贸n seaborn (sin l铆nea de tendencia) que muestre la relaci贸n entre gdp_per_cap (en el eje X) y life_exp (en el eje Y).\nMuestra el gr谩fico.\n\n\n# Scatterplot of gdp_per_cap and life_exp\nsns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCalcula la correlaci贸n entre gdp_per_cap y life_exp y gu谩rdala como cor.\n\n\n# Correlation between gdp_per_cap and life_exp\ncor = world_happiness['gdp_per_cap'].corr(world_happiness['life_exp'])\n\nprint(cor)\n\n0.7019547642148015\n\n\n\n\n\nPregunta\nLa correlaci贸n entre GDP per c谩pita y esperanza de vida es de 0.7. Por qu茅 la correlaci贸n no es la mejor forma de medir la relaci贸n entre estas dos variables?\nRespuestas posibles\n\nLa correlaci贸n mide c贸mo afecta una variable a otra.\nLa correlaci贸n solo mide las correlaciones lineales.\nLa correlaci贸n no puede medir adecuadamente las relaciones entre variables num茅ricas.\n\nEl coeficiente de correlaci贸n no puede dar cuenta de ninguna relaci贸n que no sea lineal, independientemente de su fuerza.\n\n\n12.2.3 Transformaci贸n de variables\nCuando las variables tienen distribuciones sesgadas, a menudo requieren una transformaci贸n para formar una relaci贸n lineal con otra variable, de modo que pueda calcularse la correlaci贸n. En este ejercicio realizar谩s una transformaci贸n.\n\n12.2.3.1 Instrucciones:\n\nCrea un diagrama de dispersi贸n de happiness_score frente a gdp_per_cap y calcula la correlaci贸n entre ambos.\n\n\n# Scatterplot of happiness_score vs. gdp_per_cap\nsns.scatterplot(x='gdp_per_cap', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Calculate correlation\ncor = world_happiness['happiness_score'].corr(world_happiness['gdp_per_cap'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.7279733012222978\n\n\n\nA帽ade una nueva columna a world_happiness llamada log_gdp_per_cap que contenga el logaritmo de gdp_per_cap. Crea un diagrama de dispersi贸n seaborn de happiness_score frente a log_gdp_per_cap y happiness_score. Calcula la correlaci贸n enre log_gdp_per_cap y happiness_score.\n\n\n# Create log_gdp_per_cap column\nworld_happiness['log_gdp_per_cap'] = np.log(world_happiness['gdp_per_cap'])\n\n# Scatterplot of happiness_score vs. log_gdp_per_cap\nsns.scatterplot(x='log_gdp_per_cap', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Calculate correlation\ncor = world_happiness['log_gdp_per_cap'].corr(world_happiness['happiness_score'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.8043146004918288\n\n\nLa relaci贸n entre el PIB per c谩pita y la felicidad se volvi贸 m谩s lineal al aplicar una transformaci贸n logar铆tmica. Las transformaciones logar铆tmicas son excelentes para usar en variables con una distribuci贸n sesgada, como el PIB.\n\n\n\n12.2.4 El az煤car aumenta la felicidad?\nSe ha a帽adido una nueva columna a world_happiness llamada grams_sugar_per_day, que contiene la cantidad media de az煤car ingerida por persona y d铆a en cada pa铆s. En este ejercicio, examinar谩s el efecto del consumo medio de az煤car de un pa铆s en su puntuaci贸n de felicidad.\n\nworld_happiness = pd.read_csv('./data/world_happiness_add_sugar.csv', index_col=0)\nworld_happiness\n\n\n\n\n\n\n\n\ncountry\nsocial_support\nfreedom\ncorruption\ngenerosity\ngdp_per_cap\nlife_exp\nhappiness_score\ngrams_sugar_per_day\n\n\nUnnamed: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nFinland\n2\n5\n4.0\n47\n42400\n81.8\n155\n86.8\n\n\n2\nDenmark\n4\n6\n3.0\n22\n48300\n81.0\n154\n152.0\n\n\n3\nNorway\n3\n3\n8.0\n11\n66300\n82.6\n153\n120.0\n\n\n4\nIceland\n1\n7\n45.0\n3\n47900\n83.0\n152\n132.0\n\n\n5\nNetherlands\n15\n19\n12.0\n7\n50500\n81.8\n151\n122.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n129\nYemen\n100\n147\n83.0\n155\n2340\n68.1\n5\n77.9\n\n\n130\nRwanda\n144\n21\n2.0\n90\n2110\n69.1\n4\n14.1\n\n\n131\nTanzania\n131\n78\n34.0\n49\n2980\n67.7\n3\n28.0\n\n\n132\nAfghanistan\n151\n155\n136.0\n137\n1760\n64.1\n2\n24.5\n\n\n133\nCentral African Republic\n155\n133\n122.0\n113\n794\n52.9\n1\n22.4\n\n\n\n\n133 rows  9 columns\n\n\n\n\n12.2.4.1 Instrucciones:\n\n\n\n\nCrea un diagrama de dispersi贸n seaborn que muestre la relaci贸n entre grams_sugar_per_day (en el eje X) y happiness_score (en el eje Y).\nCalcula la correlaci贸n entre grams_sugar_per_day y happiness_score.\n\n\n# Scatterplot of grams_sugar_per_day and happiness_score\nsns.scatterplot(x='grams_sugar_per_day', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Correlation between grams_sugar_per_day and happiness_score\ncor = world_happiness['grams_sugar_per_day'].corr(world_happiness['happiness_score'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.6939100021829634\n\n\n\n\n\nPregunta\nSeg煤n estos datos, qu茅 afirmaci贸n sobre el consumo de az煤car y las puntuaciones de felicidad es cierta?\nRespuestas posibles\n\nUn mayor consumo de az煤car conduce a una mayor puntuaci贸n de felicidad.\nA menor consumo de az煤car, menor puntuaci贸n de felicidad.\nUn mayor consumo de az煤car se asocia a una mayor puntuaci贸n de felicidad.\nEl consumo de az煤car no est谩 relacionado con la felicidad.\n\nSi la correlaci贸n siempre implicara que una cosa causa la otra, la gente podr铆a hacer cosas son sentido, como comer m谩s az煤car para se m谩s feliz.\n\n\n\n12.2.5 Factores de confusi贸n\nUn estudio investiga la relaci贸n entre la residencia en el vecindario y la capacidad pulmonar. Los investigadores miden la capacidad pulmonar de treinta personas del vecindario A, situado cerca de una autov铆a, y de treinta personas del vecindario B, que no est谩 cerca de una autov铆a. Ambos grupos tienen unos h谩bitos de consumo de tabaco y un desglose por sexos similares.\n驴Cu谩l de los siguientes podr铆a ser un factor de confusi贸n en este estudio?\nRespuestas posibles\n\nCapacidad pulmonar\nVecindario\nContaminaci贸n atmosf茅rica\nCondici贸n de fumador\nSexo\n\nEs de esperar que haya m谩s contaminaci贸n atmosf茅rica en el vecindario situado cerca de la autov铆a, lo que puede provocar una menor capacidad pulmonar.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>12</span> <span class='chapter-title'>Correlaci贸n y dise帽o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#dise帽o-de-experimentos",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#dise帽o-de-experimentos",
    "title": "12 Correlaci贸n y dise帽o de experimentos",
    "section": "12.3 Dise帽o de experimentos",
    "text": "12.3 Dise帽o de experimentos\n\nVocabulario\n\nEl experimento responde a la prgunta: Cu谩l es el efecto del tratamiento sobre la respuesta?.\n\nTratamiento: Variable explicativa o independiente.\nRespuesta: Variable dependiente o de respuesta.\n\nEjemplo: Cu谩l es el efecto de un anuncio en el n煤mero de productos comprados?\n\nTratamiento: Anuncio\nRespuesta: N煤mero de productos comprados\n\n\nExperimentos Controlados\n\nLos participantes son asignados aleatoriamente a los grupos de tratamiento o al grupo de control. El grupo de tratamiento recibe el tratamiento y el de control no.\n\nGrupo de tratamiento ve los anuncios\nEl grupo de control no.\n\nLos grupos deben ser comparables de modo que la causalidad pueda ser inferida.\nSi los grupos no son comparables, esto podria llevar a confusi贸n.\n\nGrupo de tratamiento con edad promedio de : 25\nGrupo de control con edad promedio de: 50\nLa edad es un un potencial factor de confusi贸n.\n\n\nEl gold est谩ndar de los experimento usar谩\n\nEnsayo controlado aleatorio.\n\nLos participantes son asignados al azar al grupo de tratamiento o de control. No basado en alguna caracter铆stica.\nLa asignaci贸n aleatoria ayuda a asegurar que los grupos sean comparables.\n\nPlacebo\n\nSe parace al tratamiento, pero no tiene efecto.\nLos participantes no sabr谩n a cual grupo ir谩n.\n\nDoble ciego\n\nLa persona que administra el tratamiento no conoce cual es el tratamiento real o el placebo.\nPreviene el sesgo en la respuesta y/o en el an谩lisis de resultados.\n\nMenos oportunidades de que haya sesgo = mas fiable sera la conclusi贸n que el tratamiento afecta la respuesta.\n\nEstudios observacionales\n\nLos participantes no se asignan aleatoriamente a los grupos.\n\nLos participantes se asignan a si mismos, usualmente basado en caracter铆sticas preexistentes.\n\nMuchas preguntas no son conducidas a un experimento controlado.\n\nNo puedes forzar a alguien a fumar o tener un deseso.\nNo puede hacer que alguien tengan cierto comportamiento.\n\nSe establece asociaci贸n no causalidad.\n\nLos efectos del tratamiento pueden ser confundidos por factores que llevaron a ciertas personas al grupo de control o tratamiento.\nHay formas de controlar la confusi贸n para obtener m谩s conclusiones fiabiles acerca de la asociaci贸n.\n\n\nEstudios Longitudinales vs Estudios transversales\n\nEstudios Longitudinales\n\nSe sigue a los mismos participantes durante un periodo de tiempo para examinar el efecto del tratamiento en la respuesta.\nEl efecto de la edad en la altura no es confundida por generaci贸n.\nSon m谩s costosos, los resultados toman tiempo.\n\nEstudio transversal\n\nLos datos de los participantes son recolectados de una sola camptura en el tiempo.\nEl efecto de la edad en la altura se confunde por generaci贸n.\nSon m谩s baratos, r谩pidos y mas convenientes.\n\n\n\n\n12.3.1 Tipos de estudio\nAunque los experimentos controlados son ideales, muchas situaciones y preguntas de investigaci贸n no son propicias para un experimento controlado. En un experimento controlado, es probable que pueda inferirse la causalidad si los grupos de control y de prueba tienen caracter铆sticas similares y no hay ninguna diferencia sistem谩tica entre ellos. Por otra parte , la causalidad no suele inferirse de los estudios observacionales, cuyos resultados suelen interpretarse err贸neamente como consecuencia de ello.\n\n12.3.1.1 Instrucciones\n\nDetermina si cada estudio es un experimento controlado o un estudio observacional\n\n\n\n\n\n\n\n\nExperimento Controlado\nEstudio Observacional\n\n\n\n\nSe comparan los s铆ntomas de asma entre ni帽os asignados aleatoriamente a recibir servicios profesionales de control de plagas a domicilio o educaci麓酶n sobre el control de plagas.\nSe compara la prevalencia de enfermedades card铆acas entre veteranos con PTSD y veteranos sin PTSD.\n\n\nSe comparan las tasas de compra entre los usuarios de un sitio de comercio electr贸nico que son dirigidos aleatoriamente a una nueva versi贸n de la p谩gina de inicio o a una versi贸n antigua.\nHace una semana, se actualiz贸 la p谩gina de inico de un sitio de comercio electr贸nico. Las tasas de compra se comparan entre los usuarios que vieron las versiones antigua y nueva de la p谩gna de inicio.\n\n\nSe asigna aleatoriamente a los sujetos una dieta y se compara la p茅rdida de peso.\n\n\n\n\n\n\n\n12.3.2 Estudios longitudinales frente a estudios transversales\nUna empresa fabrica term贸metros y quiere estudiar la relaci贸n entre la antig眉edad de un term贸metro y su exactitud. Para ello, toman una muestra de 100 term贸metros diferentes de distintas antig眉edades y comprueban su exactitud. Son datos longitudinales o transversales?\nRespuestas posibles\nSelecciona una respuesta:\n\nLongitudinal\nTransversal\nAmbos\nNinguno\n\nSe trata de un estudio transversal, ya que los investigadores no est谩n siguiendo el mismo conjunto de term贸metros a lo largo del tiempo y midiendo repetidamente su exactitud con diferentes antig眉edades.",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>12</span> <span class='chapter-title'>Correlaci贸n y dise帽o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html",
    "title": "S铆ntesis estad铆stica",
    "section": "",
    "text": "Qu茅 es la estad铆stica?\nLa s铆ntesis estad铆stica te proporciona las herramientas que necesitas para condensar conjuntos de datos masivos y revelar lo m谩s destacado. En este cap铆tulo explorar谩s la s铆ntesis estad铆stica, lo que incluye la media, la mediana y la desviaci贸n t铆pica, y aprender谩s a realizar una interpretaci贸n exacta. Tambi茅n desarrollar谩s tus competencias de pensamiento cr铆tico, lo que te permitir谩 elegir la mejor s铆ntesis estad铆stica para tus datos.\nTipos de estad铆stica:\nTipos de datos:",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>9</span> <span class='chapter-title'>S铆ntesis estad铆stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#qu茅-es-la-estad铆stica",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#qu茅-es-la-estad铆stica",
    "title": "S铆ntesis estad铆stica",
    "section": "",
    "text": "Campo de la estad铆stica: Es la pr谩ctica y studio de la recogida y an谩lisis de datos.\nUn res煤men estad铆stico: Un dato o resumen de algunos datos.\n\n\n\n\n\n\n\n\n\nEstad铆stica Descriptiva\nEstad铆stica Inferencial\n\n\n\n\n\nDescribe y resume los datos.\n\n\nUsa una muestra de datos para hacer inferencias acerca de una gran poblaci贸n.\n\n\n\nEjemplos:\n\n50% de los amigos conducen al trabajo.\n25% toman el bus.\n25% bicicleta\n\nEjemplo:\n\nQu茅 porcentaje de personas manejan al trabajo?\n\n\n\n\n\n\n\n\n\n\n\n\nNum茅rico (Cuantitativo)\nCateg贸rico (Cualitativo)\n\n\n\n\n\nContinuos (se pueden medir)\n\nVelocidad de un avi贸n.\nTiempo de espera en una fila\n\n\n\nNominal (Sin orden)\n\nCasado / Divorciado.\nPa铆s de residencia.\n\n\n\n\n\nDiscretos (de recuento)\n\nN煤mero de mascotas.\nN煤mero de paquetes enviados.\n\n\n\nOrdinal (Ordenado)\n\nPreguntas de encuesta\n\n\n\n\n\n\nEstad铆stica descriptiva e inferencial\nLa estad铆stica puede utilizarse para responder a muchos tipos de preguntas, pero saber identificar qu茅 tipo de estad铆stica se necesita es esencial para sacar conclusiones exactas. En este ejercicio, afinar谩s tus competencias identificando qu茅 tipo se necesita para responder a cada pregunta.\n\n\n\n\n\n\n\nDescriptiva\nInferencial\n\n\n\n\n\nDados los datos de cada solicitud de atenci贸n al cliente realizada, 驴cu谩l es el tiempo medio que se tard贸 en responder?\n\n\nDespu茅s de entrevistar a 100 clientes, 驴qu茅 porcentaje de todos tus clientes est谩n satisfechos con tu producto?\n\n\n\n\nDados los datos de las 100 000 personas que vieron un anuncio, 驴qu茅 porcentaje de personas hicieron clic en 茅l?\n\n\nDados los datos de 20 peces capturados en un lago, 驴cu谩l es el peso medio de todos los peces del lago?\n\n\n\n\n\n\nClasificaci贸n de los tipos de datos\nEn el v铆deo, aprendiste sobre dos tipos principales de datos: num茅ricos y categ贸ricos. Las variables num茅ricas pueden clasificarse como discretas o continuas, y las variables categ贸ricas, como nominales u ordinales. Estas caracter铆sticas de una variable determinan qu茅 formas de resumir tus datos funcionar谩n mejor.\n\n\n\n\n\n\n\n\nNum茅rica continua\nNum茅rica discreta\nCateg贸rica\n\n\n\n\nTemperatura del aire\nN煤mero de art铆culos en stock\nC贸digo postal\n\n\nKilovatios de electricidad consumidos\nN煤mero de cursos de Datacamp realizados\nMarca de un producto",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>9</span> <span class='chapter-title'>S铆ntesis estad铆stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-tendencia-central",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-tendencia-central",
    "title": "S铆ntesis estad铆stica",
    "section": "Medidas de tendencia central",
    "text": "Medidas de tendencia central\n\nMedia: Funciona mejor para datos sim茅tricos.\nMediana: Funciona mejor para datos sesgados a izquierda y derecha.\nModa: Principalmente para datos categ贸ricos.\n\n\nMedia y mediana\nEn este cap铆tulo, trabajar谩s con el conjunto de datos food_consumption del 2018 Food Carbon Footprint Index, de nu3. El conjunto de datos food_consumption contiene el n煤mero de kilogramos de alimentos consumidos por persona y a帽o en cada country y categor铆a de alimentos (consumption), y su huella de carbono (co2_emissions) medida en kilogramos de di贸xido de carbono, o CO2.\nEn este ejercicio, calcular谩s medidas de tendencia central para comparar el consumo de alimentos en US y B茅lgica utilizando tus competencias en pandas y numpy.\n\nimport pandas as pd\n\n\nfood_consumption = pd.read_csv('../datasets/food_consumption.csv')\nprint(food_consumption.head())\n\n   Unnamed: 0    country food_category  consumption  co2_emission\n0           1  Argentina          pork        10.51         37.20\n1           2  Argentina       poultry        38.66         41.53\n2           3  Argentina          beef        55.48       1712.00\n3           4  Argentina     lamb_goat         1.56         54.63\n4           5  Argentina          fish         4.36          6.96\n\n\n\nInstrucciones:\n\nImporta las librer铆as pandas y numpy.\nSubdivide food_consumption para obtener las filas en las que el country esUSA\nCalcula la media del consumption de alimentos en el DataFrame usa_consumption.\nCalcula la mediana del consumption de alimentos en el DataFrame usa_consumption.\n\n\n# Import numpy with alias np\nimport numpy as np\n\n# Subset country for USA: usa_consumption\nusa_consumption = food_consumption[food_consumption['country'] == 'USA']\n\n# Calculate mean consumption in USA\nprint(np.mean(usa_consumption['consumption']))\n\n# Calculate median consumption in USA\nprint(np.median(usa_consumption['consumption']))\n\n44.650000000000006\n14.58\n\n\nLos c谩lculos muestran que la media y la mediana del consumo en los Estados Unidos son bastante diferentes.\n\n\n\nMedia frente a mediana\nEn el v铆deo has aprendido que la media es la suma de todos los puntos de datos dividida entre el n煤mero total de puntos de datos, y que la mediana es el valor central del conjunto de datos, donde el 50 % de los datos son menores que la mediana y el 50 % de los datos son mayores que la mediana. En este ejercicio, comparar谩s estas dos medidas de tendencia central.\n\nInstrucciones:\n\n\n\n\nImporta la librer铆a matplotlib.pyplot con el alias plt.\nSubdivide food_consumption para obtener las filas en las que el food_category es rice.\nCrea un histograma de co2_emissions en el DataFrame rice_consumption y muestra el gr谩fico.\n\n\n# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n\n# Subset for food_category equals rice\nrice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\nprint(rice_consumption.head())\n\n    Unnamed: 0      country food_category  consumption  co2_emission\n8            9    Argentina          rice         8.77         11.22\n19          20    Australia          rice        11.03         14.12\n30          31      Albania          rice         7.78          9.96\n41          42      Iceland          rice         3.89          4.98\n52          53  New Zealand          rice         9.16         11.72\n\n\n\n# Histogram of co2_emissions for rice and show plot\nplt.hist(rice_consumption['co2_emission'])\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta\n\nEcha un vistazo al histograma que acabas de crear de las emisiones de CO2 de los distintos pa铆ses para el arroz. Cu谩l de los siguientes t茅rminos describe mejor la forma de los datos?\nRespuestas posibles\n\nSin sesgo\nSesgado a la izquierda\nSesgado a la derecha\n\n\n\n\n\nUtiliza .agg() para calcular la media y la mediana de co2_emissions para el arroz.\n\n\n# Subset for food_category equals rice\nrice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\nprint(rice_consumption)\n\n      Unnamed: 0       country food_category  consumption  co2_emission\n8              9     Argentina          rice         8.77         11.22\n19            20     Australia          rice        11.03         14.12\n30            31       Albania          rice         7.78          9.96\n41            42       Iceland          rice         3.89          4.98\n52            53   New Zealand          rice         9.16         11.72\n...          ...           ...           ...          ...           ...\n1383        1384  Sierra Leone          rice       103.30        132.19\n1394        1395     Sri Lanka          rice       109.72        140.41\n1405        1406     Indonesia          rice       134.62        172.27\n1416        1417       Liberia          rice        94.75        121.25\n1427        1428    Bangladesh          rice       171.73        219.76\n\n[130 rows x 5 columns]\n\n\n\n# Calculate mean and median of co2_emission with .agg()\nprint(rice_consumption['co2_emission'].agg(['mean', 'median']))\n\nmean      37.591615\nmedian    15.200000\nName: co2_emission, dtype: float64\n\n\n\nPregunta\n\nDado el sesgo de estos datos, qu茅 medida de tendencia central resume mejor los kilogramos de emisiones de CO2 por persona y a帽o para el arroz?\nRespuestas posibles\n\nMedia\nMediana\nMedia y mediana",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>9</span> <span class='chapter-title'>S铆ntesis estad铆stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-dispersi贸n",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-dispersi贸n",
    "title": "S铆ntesis estad铆stica",
    "section": "Medidas de dispersi贸n",
    "text": "Medidas de dispersi贸n\nDescribe lo separado o juntos que se encuentran los grupos de datos.\n\nVarianza:\nMide la distancia media de cada punto de datos a la media de los datos. Se puede calcular usando np.var().\n\n\nDesviaci贸n est谩ndar\nSe calcula tomando la ra铆z cuadrada de la varianza. Se puede calcular usando np.sd().\n\n\nDesviaci贸n est谩ndar absoluto\nToma el valor absoluto de las distancias a la media y luego toma la media de las diferencias.\n\n\nDesviaci贸n estandar vs desviaci贸n media absoluta\n\nEn la desviaci贸n estandar los cuadrados de las distancias penaliza las largas distancias m谩s que las cortas.\nEn la desviaci贸n media absoluta todas las distancias se penalizar de forma equitativa.\n\n\n\nVarianza y desviaci贸n t铆pica\n\n\nCuartiles, cuantiles y quintiles\n\n\nEncontrar valores at铆picos mediante IQR",
    "crumbs": [
      "Introducci贸n a la Estad铆stica en Python",
      "<span class='chapter-number'>9</span> <span class='chapter-title'>S铆ntesis estad铆stica</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\n Nivel: Principiante\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nSeaborn es una potente biblioteca de Python que facilita la creaci贸n de visualizaciones de datos informativas y atractivas. Este curso de 4 horas proporciona una introducci贸n a c贸mo puedes utilizar Seaborn para crear diversos gr谩ficos, incluidos gr谩ficos de dispersi贸n, de recuento, de barras y de cajas, y c贸mo puedes personalizar tus visualizaciones.\nExplorar谩s esta biblioteca y crear谩s gr谩ficos Seaborn basados en diversos conjuntos de datos del mundo real, como la exploraci贸n de c贸mo cambia la contaminaci贸n atmosf茅rica en una ciudad a lo largo del d铆a y el estudio de lo que les gusta hacer a los j贸venes en su tiempo libre. Estos datos te dar谩n la oportunidad de conocer de primera mano las ventajas de Seaborn, incluyendo c贸mo puedes crear f谩cilmente subtramas en una sola figura y c贸mo calcular autom谩ticamente los intervalos de confianza.\nAl final de este curso, ser谩s capaz de utilizar Seaborn en diversas situaciones para explorar tus datos y comunicar eficazmente a otros los resultados de tus an谩lisis de datos. Estas habilidades son muy solicitadas para analistas de datos, cient铆ficos de datos y cualquier otro trabajo que pueda implicar la creaci贸n de visualizaciones de datos. Si quieres continuar tu aprendizaje, este curso forma parte de varios programas, incluido el programa de visualizaci贸n de datos, donde podr谩s a帽adir m谩s bibliotecas y t茅cnicas a tu conjunto de habilidades.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#m贸dulos-del-curso",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nInstroducci贸n a Seaborn\nVisualizar dos variables cuantitativas\nVisualizar variables categ贸ricas y cuantativas\nPersonalizar gr谩ficos con seaborn",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#datasets",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\nunemployment.csv\ndata_science_salaries.csv\nbooks.csv\ndivorce.csv\nplanes.csv",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html",
    "title": "Introducci贸n a Seaborn",
    "section": "",
    "text": "Introducci贸n a Seaborn\nQu茅 es Seaborn y cu谩ndo debes utilizarlo? En este cap铆tulo, 隆Lo descubrir谩s! Adem谩s, aprender谩s a crear gr谩ficos de dispersi贸n y de recuento tanto con listas de datos como con DataFrames de pandas. Tambi茅n conocer谩s una de las grandes ventajas de utilizar Seaborn: la posibilidad de a帽adir f谩cilmente una tercera varible a tus gr谩ficos utilizando el color para representar diferentes subgrupos.\nimport seaborn as sns  # Samuel Norman Seaborn (sns)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nheight = [62, 64, 69, 75, 66,\n          68, 65, 71, 76, 73]\nweight = [120, 136, 148, 175, 137,\n          165, 154, 172, 200, 187]\nsns.scatterplot(x=height, y=weight)\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ngender = ['Female', 'Female',\n          'Female', 'Female',\n          'Male', 'Male', 'Male',\n          'Male', 'Male', 'Male']\nsns.countplot(x=gender)",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>22</span> <span class='chapter-title'>Introducci贸n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#introducci贸n-a-seaborn",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#introducci贸n-a-seaborn",
    "title": "Introducci贸n a Seaborn",
    "section": "",
    "text": "Qu茅 es Seaborn?\n\nPuthon es una librer铆a de visualizaci贸n de datos\nCrea facilmente los tipos m谩s comunes de gr谩ficos\n\nPor qu茅 es 煤til Seaborn?\n\nExploraci贸n de datos\nComunicaci贸n de resultados\n\nVentajas de Seaborn\n\nF谩cil de usar\nTrabaja bien con estructuras de datos de pandas\nConstru铆do sobre matplotlib\n\nC贸mo iniciar?\n\n\n\nEjemplo 1: Scatter plot\n\n\n\nEjemplo 2: Crear un count plot\n\n\n\nHacer un gr谩fico de dispersi贸n con listas\nEn este ejecicio, utilizaremos un conjunto de datos que contiene informaci贸n sobre 227 pa铆ses. Este conjunto de datos contiene mucha informaci贸n interesante sobre cada pa铆s, como sus tasas de natalidad y mortalidad y su producto interno bruto (GDP). GDP es el valor de todos los bienes y servicios producidas en un a帽o, expresado en d贸lares por persona.\nHemos creado tres listas de datos a partir de este conjunto de datos para que puedas empezar. gdp es una lista que contiene el valor de GDP por pa铆s, expresado en d贸lares por persona. phones es una lista con el n煤mero de tel茅fonos m贸viles por cada 1000 personas en este pa铆s. Por 煤ltimo percent_literate es una lista que contiene el porcentaje de la poblaci贸n de cada pa铆s que sabe leer y escribir.\n\nimport pandas as pd\n\nruta = './data/countries-of-the-world.csv'\ndf = pd.read_csv(ruta)\ndf.head()\n\n\n\n\n\n\n\n\nCountry\nRegion\nPopulation\nArea (sq. mi.)\nPop. Density (per sq. mi.)\nCoastline (coast/area ratio)\nNet migration\nInfant mortality (per 1000 births)\nGDP ($ per capita)\nLiteracy (%)\nPhones (per 1000)\nArable (%)\nCrops (%)\nOther (%)\nClimate\nBirthrate\nDeathrate\nAgriculture\nIndustry\nService\n\n\n\n\n0\nAfghanistan\nASIA (EX. NEAR EAST)\n31056997\n647500\n48,0\n0,00\n23,06\n163,07\n700.0\n36,0\n3,2\n12,13\n0,22\n87,65\n1\n46,6\n20,34\n0,38\n0,24\n0,38\n\n\n1\nAlbania\nEASTERN EUROPE\n3581655\n28748\n124,6\n1,26\n-4,93\n21,52\n4500.0\n86,5\n71,2\n21,09\n4,42\n74,49\n3\n15,11\n5,22\n0,232\n0,188\n0,579\n\n\n2\nAlgeria\nNORTHERN AFRICA\n32930091\n2381740\n13,8\n0,04\n-0,39\n31\n6000.0\n70,0\n78,1\n3,22\n0,25\n96,53\n1\n17,14\n4,61\n0,101\n0,6\n0,298\n\n\n3\nAmerican Samoa\nOCEANIA\n57794\n199\n290,4\n58,29\n-20,71\n9,27\n8000.0\n97,0\n259,5\n10\n15\n75\n2\n22,46\n3,27\nNaN\nNaN\nNaN\n\n\n4\nAndorra\nWESTERN EUROPE\n71201\n468\n152,1\n0,00\n6,6\n4,05\n19000.0\n100,0\n497,2\n2,22\n0\n97,78\n3\n8,71\n6,25\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n# Convertir a numerico los datos tipo object\ndf['Phones (per 1000)'] = df['Phones (per 1000)'].str.replace(',', '.').astype(float)\ndf['Literacy (%)'] = df['Literacy (%)'].str.replace(',', '.').astype(float)\n\n# Crear las listas\ngdp = df['GDP ($ per capita)'].tolist()\nphones = df['Phones (per 1000)'].tolist()\npercent_literate = df['Literacy (%)'].tolist()\n\n\nInstrucciones\n\nImporta Matplotlib y Seaborn utilizando la convenci贸n de nomenclatura est谩ndar.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nCrea un gr谩fico de dispersi贸n de GDP (gdp) frente al n煤mero de tel茅fonos por cada 1000 personas (phones).\n\n\n# Create scatterplot with GDP on x-axis and number of phones on the y-axis\nsns.scatterplot(x=gdp, y=phones)\nplt.show()\n\n\n\n\n\n\n\n\n\nCombina el diagrama de dispersi贸n para que muestre el porcentaje de la poblaci贸n que sabe leer y escribir (percent_literate) en el eje y.\n\n\nsns.scatterplot(x=gdp, y=percent_literate)\nplt.show()\n\n\n\n\n\n\n\n\nAunque este gr谩fico no muestra una relaci贸n lineal entre el PIB y el porcentaje de alfabetizaci贸n, los pa铆ses con un PIB m谩s bajo parecen tener m谩s probabilidades de tener un porcentaje menor de la poblaci贸n que puede leer y escribir.\n\n\n\nHacer un gr谩fico de recuento con una lista\nEn el ejercicio anterior, exploramos un conjunto de datos que contienen informaci贸n sobre 227 pa铆ses. Exploremos m谩s a fondo estos dato: concretamente, 驴cu谩ntos pa铆ses hay en cada regi贸n del mundo?\nPara ello, tendremos que utilizar un gr谩fico de recuento. Los gr谩ficos de recuento toman una lista categ贸rica y devuelven barras que representan el n煤mero de entradas de la lista por categor铆a. Puedes crear una aqu铆 utilizando una lista de regiones para cada pa铆s, que es uva variable llamada region.\n\n# Se convierte la columna Region en lista y se quitan los espacios\nregion = df['Region'].tolist()\nregion = [item.strip() for item in region]\n\n\nInstrucciones\n\nImporta Matplotlib y Seaborn utilizando las convenciones de nomenclatura est谩ndar.\nUtiliza Seaborn para crear un gr谩fico de recuento con region en el eje y.\nVisualiza el gr谩fico\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create count plot with region on the y-axis\nsns.countplot(y=region)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nfrica Subsahariana contiene la mayor铆a de los pa铆ses en esta lista.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>22</span> <span class='chapter-title'>Introducci贸n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#utilizar-pandas-con-seaborn",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#utilizar-pandas-con-seaborn",
    "title": "Introducci贸n a Seaborn",
    "section": "Utilizar pandas con Seaborn",
    "text": "Utilizar pandas con Seaborn\n\nQu茅 es Pandas?\n\nLibrer铆a de Python para an谩lisis de datos.\nPuede leer conjunto de datos de m煤ltiples tipos de archivos. Por ejemplo csv, txt.\nEl conjunto de datos toma la forma de objeto DataFrame.\n\nTrabajando con DataFrames\n\n\nimport pandas as pd\ndf = pd.read_csv('masculinity.csv')\ndf.head()\n\n\nUsando DataFrames con countplot()\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('masculinity.csv')\nsns.countplot(x='how_masucline', data=df)\nplt.show()\n\n\nDatos ordenados frente a datos desordenados\nAqu铆 tenemos un conjunto de datos que muestra de una encuesta a ni帽os sobre sus animales favoritos. Pros, 驴Podemos utilizar este conjunto de datos tal cual con Seaborn? Vamos a utilizar pandas para importar el archivo csv con los datos recogidos en la encuestra y determinar si est谩 ordenado, lo cual es esencial para que funcione bien con Seaborn.\nPara empezar, se ha asignado la tura del archivo csv a la variable csv_filepath.\n\nInstrucciones\n\n\n\n\nLee el archivo csv situado en csv_filepath en un DataFrame llamado df.\nImprime la cabecera de df para mostrar las cinco primeras filas.\n\n\ncsv_filepath = './data/1.2.1_example_csv.csv'\n\n\n# Import pandas\nimport pandas as pd\n\n# Create a DataFrame from csv file\ndf = pd.read_csv(csv_filepath)\n\n# Print the head of df\nprint(df.head())\n\n  Unnamed: 0               How old are you?\n0     Marion                             12\n1      Elroy                             16\n2        NaN  What is your favorite animal?\n3     Marion                            dog\n4      Elroy                            cat\n\n\n\nPregunta\n\nVisualiza las cinco primeras filas del DataFrame df. 驴Est谩 ordenado? 驴Por qu茅 si o por qu茅 no?\nRespuestas posibles\n\nSi, porque no hay erratas ni faltan valores.\nSi, porque est谩 vien organizado y es f谩cil de leer.\nNo, porque una misma columna contiene distintos tipos de formaci贸n.\n\n\n\n\nHacer un gr谩fico de recuento con un DataFrame\nEn este ejercicio examinaremos las respuestas a una encuesta enviada a los j贸venes. Nuestra pregunta principal aqu铆 es: 驴cu谩ntos j贸venes encuestados afirman tener miedo a las ara帽as? Se pidi贸 a los participantes en la encuesta que estuvieran de acuerdo o en desacuerdo con la afirmaci贸n Tengo miedo a las ara帽as. Las respuestas var铆an de 1 a 5, donde 1 es Totalmente en desacuerdo y 5 es Totalmente de acuerdo.\nPara empezar, la ruta del archivo csv con los datos de la encuesta se ha asignado a la variable csv_filepath.\n\nInstrucciones\n\nImporta Matplotlib, pandas y Seaborn utilizando los nombres est谩ndar.\nCrea un DataFrame llamado df a partir del archivo csv situado en csv_filepath.\nUtilizando la funci贸n countplot() con los argumentos x= y data= para crear un gr谩fico de recuento con los valores de la columna \"Spiders\" en el eje x.\nVisualiza el gr谩fico.\n\n\ncsv_filepath = './data/young-people-survey-responses.csv'\n\n\n# Import Matplotlib, pandas and Seaborn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a DataFrame from csv file\ndf = pd.read_csv(csv_filepath)\n\n# Create a countplot with \"Spiders\" on the x-axis\nsns.countplot(x='Spiders', data=df)\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nEste gr谩fico nos muestra que la gran mayor铆a de los j贸venes informaron no tener miedo a las ara帽as.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>22</span> <span class='chapter-title'>Introducci贸n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#a帽adir-una-tercera-variable-con-el-tono",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#a帽adir-una-tercera-variable-con-el-tono",
    "title": "Introducci贸n a Seaborn",
    "section": "A帽adir una tercera variable con el tono",
    "text": "A帽adir una tercera variable con el tono\nPara probarlos usaremos el siguiente Dataset:\n\nDataset Tips\n\n\nimport pandas as pd\nimport seaborn as sns\ntips = pd.read_csv('./data/tips.csv')\ntips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\nUn Scatter plot b谩sico\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nUn Scatter plot con hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nConfigurando el orden del hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker',\n                hue_order=['Yes',\n                            'No'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nEspecificando los colores de hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {'Yes': 'black',\n              'No': 'red'}\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker',\n                palette=hue_colors)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nUsando hue con count plots\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.countplot(x='smoker',\n              data=tips,\n              hue='sex')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nGr谩ficos de tono y dispersi贸n\nEn el video anterior aprendimos como hue nos permite hacer f谩cilmente subgrupos dentro de los gr谩ficos de Seaborn. Vamos a probarlo explorando los datos de los alumnos de secundaria. Tenemos mucha informaci贸n sobre cada alumno, como su edad, d贸nde vive, sus h谩bitos de estudio y sus actividades extraescolares.\nPor ahora, nos fijaremos en la relaci贸n entgre el n煤mero de faltas que tienen en la escuela y su calificaci贸n final en el curso, segmentada por el lugar donde vive el alumno (zona rural frente a zona urbana).\n\nstudent_data = pd.read_csv('./data/student-alcohol-consumption.csv', index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows  29 columns\n\n\n\n\nInstrucciones\n\nCrea un gr谩fico de dispersi贸n con absensces en el eje x y la calificaci贸n final (\"G3\") en el eje y utilizando el DataFrame student_data. Colorea los puntos del gr谩fico en funci贸n de \"location\" (urbano vs.rural)\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a scatter plot of absences vs. final grade\nsns.scatterplot(x='absences', \n                y='G3',\n                data=student_data,\n                hue='location')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nHaz que rural aparezca antes que urban en la leyenda del gr谩fico.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Change the legend order in the scatter plot\nsns.scatterplot(x='absences', \n                y='G3',\n                data=student_data,\n                hue='location',\n                hue_order=['Rural', 'Urban'])\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes con m谩s ausencias tienden a tener calificaciones m谩s bajas tanto en 谩reas rurales como urbanas.\n\n\n\nGr谩ficos de tono y recuento\nSigamos explorando nuestro conjunto de datos de alumnos de secundaria examinando una nueva variable. La columna school indica las iniciales de la escuela a la que asisti贸 al alumno: GP o MS.\nEn el 煤ltimo ejercicio, creamos un gr谩fico de dispersi贸n en el que los puntos del gr谩fico se coloreaban en funci贸n de si el alumno viv铆a en zona urbana o rural. 驴Cu谩ntos alumnos viven en zonas urbanas frente a zonas rurales, y var铆a esto en funci贸n de la escuela a la que asiste el alumno? Hagamos un gr谩fico de recuento con subgrupos para averiguarlo.\n\nInstrucciones\n\nRellena el diccionario palette_colors para asignar el valor de ubicaci贸n \"Rural\" al color \"green\" y el valor de ubicaci贸n \"Urban\" al color \"blue\".\nCrea un gr谩fico de recuento con \"school\" en el eje x utilizando el DataFrame student_data.\n\nA帽ade subgrupos al gr谩fico, utilizando la variable \"location\"`` y utliliza el diccionariopalette_colors` para que los subgrupos de ubicaci贸n sean verdes o azules.\n\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a dictionary mapping subgroup values to colors\npalette_colors = {'Rural': 'green',\n                  'Urban': 'blue'}\n\n# Create a count plot of school with location subgroups\nsns.countplot(x='school',\n              data=student_data,\n              hue='location',\n              palette=palette_colors)\n\n# Display plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes en GP tienden a venir de una ubicaci贸n urbana, pero los estudiantes en MS est谩n m谩s equitativamente divididos.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>22</span> <span class='chapter-title'>Introducci贸n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html",
    "title": "Visualizar dos variables cuantitativas",
    "section": "",
    "text": "Introducci贸n a las plots (tramas) y subplots (subtramas) relacionales\nEn este cap铆ulo, crear谩s y personalizar谩s gr谩ficos que visualizan la relaci贸n entre dos variables cuantitativas. Para ello, utilizar谩s gr谩ficos se dispersi贸n y de l铆neas para explorar c贸mo cambia el nivel de contaminaci贸n atmosf茅rica en una ciudad a lo largo de un d铆a y c贸mo se relacionan los caballos de potencia con la eficiencia del combustible en los coches. Tambi茅n ver谩s otra gran ventaja de utilizar Seaborn: 隆la posibilidad de crear f谩cilmente subtramas en una sola figura!\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='smoker')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            row='smoker')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='smoker',\n            row='time')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day')\nplt.show()\nEl gr谩fico se ve peque帽o si todos estan en la misma fila\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day',\n            col_wrap=2)\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day',\n            col_wrap=2,\n            col_order=['Thur',\n                       'Fri',\n                       'Sat',\n                       'Sun'])\nplt.show()",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>23</span> <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci贸n-a-las-plots-tramas-y-subplots-subtramas-relacionales",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci贸n-a-las-plots-tramas-y-subplots-subtramas-relacionales",
    "title": "Visualizar dos variables cuantitativas",
    "section": "",
    "text": "Gr谩ficos relacionales\n\nAltura vs Peso\nN煤mero de ausencias de un alumno vs Nota final\nGDP vs Personas que saben leer y escribir\n\nIntruducci贸n a relplot()\n\nCrea gr谩ficos relacionales: scatterplots o line plots\n驴Por qu茅 usar relplot() en lugar de scatterplot()?\n\nrelplot() permite crear subgr谩ficos en una sola figura.\n\n\nScatterplot() vs relplot()\n\n# para poder mostrar el dataset en los ejemplos\nimport pandas as pd\ntips = pd.read_csv('./data/tips.csv')\n\n\nUsando scatterplot()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips)\nplt.show()\n\n\n\n\n\n\n\n\n\nUsando relplot()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter')\nplt.show()\n\n\n\n\n\n\n\n\nSubplots en columnas\n\n\n\nSubplots en filas\n\n\n\nSubplots en filas y columnas\n\n\n\nSubgrupos por d铆a de la semana\n\n\n\n\nWrapping columns\n\nSe pueden establecer dos gr谩ficos por fila\n\n\n\n\nOrden de las columnas\n\n\n\nCrear subtramas con columna y fila\nHemos visto en ejercicios anteriores que los alumnos con m谩s faltas (\"absences\") tienden a tener notas finales m谩s bajas (\"G3\"). 驴Se mantiene esta relaci贸n independientemente de cu谩nto tiempo estudien los alumnos cada semana?\nPara responder a esto, observaremos la relaci贸n entre el n煤mero de faltas de asistencia a clase de un alumno y su calificaci贸n final en el curso, creando subtramas separadas en funci贸n del tiempo de estudio semanal de cada alumnos (\"study_time\").\n\nimport pandas as pd\nstudent_data = pd.read_csv('./data/student-alcohol-consumption.csv', index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows  29 columns\n\n\n\n\nInstrucciones\n\nModifica el c贸digo paora utilizar relplot() en lugar de scatterplot().\n\n\n# Change to use relplot() instead of scatterplot()\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nModifica el c贸digo para crear un gr谩fico de dispersi贸n para cada nivel de la variable \"study_time\", ordenado en columnas.\n\n\n# Change to make subplots based on study time\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='study_time')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nAdapta tu c贸digo para crear un gr谩fico de dispersi贸n para cada nivel del tiempo de estudio semanal de un alumno, esta vez ordenado en filas.\n\n\n# Change this scatter plot to arrange the plots in rows instead of columns\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter',\n            row='study_time')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDebido a que estos subgr谩ficos ten铆an un gran rango de valores x, es m谩s f谩cil leerlos dispuestos en filas en lugar de columnas.\n\n\n\nCrear subtramas de dos factores\nSigamos examinando el conjunto de datos student_data de alumnos de secundaria. Aqu铆 queremos responder a la siguiente pregunta: 驴la nota del primer semestre de un alumno (\"G1\") tiende a correlacionarse con su nota final (\"G3\")?\nHay muchos aspectos de la vida de un alumno que pueden dar lugar a una nota final m谩s alta o m谩s baja en la clase. Por ejemplo, algunos alumnos reciben apoyo educativo adicional de su centro escolar (\"schoolsup\") o de su familia (\"famsup\"), lo que podr铆a traducirse en mejores notas. Intentamos controlar estos dos factores creando subtramas en funci贸n de si el alumno recibi贸 apoyo educativo adicional de su escuela o de su familia.\n\nInstrucciones\n\nUtiliza relplot() para crear un gr谩fico de dispersi贸n con \"G1\" en el eje x y \"G3\" en el eje y, utilizando el DataFrame student_data\n\n\n# Create a scatter plot fo G1 vs. G3\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            )\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCrea subtramas de columnas en funci贸n de su el alumno recibi贸 ayuda de la escuela (\"schoolsup\"), ordenadas de forma que si vaya antes que no.\n\n\n# Adjust to add subplots based on school support\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='schoolsup',\n            col_order=['yes', 'no']\n            )\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA帽ade subgrupos de filas en funci贸n de su el alumno recibi贸 ayuda de la familia (\"famsup\"), ordenados de forma que si vaya antes que no. Esto dar谩 lugar a subtramas basadas en dos factores.\n\n\n# Adjust further to add subplots based on family support\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='schoolsup',\n            col_order=['yes', 'no'],\n            row='famsup',\n            row_order=['yes', 'no'])\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la nota del primer semestre si correlaciona con la nota final, independientemente dl tipo de apoyo que recibi贸 el estudiante.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>23</span> <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#personalizar-gr谩ficos-de-dispersi贸n",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#personalizar-gr谩ficos-de-dispersi贸n",
    "title": "Visualizar dos variables cuantitativas",
    "section": "Personalizar gr谩ficos de dispersi贸n",
    "text": "Personalizar gr谩ficos de dispersi贸n\n\nResumen Scatter plot\n\nMuestran la realci贸n entre dos variables cuantitativas.\nHemos visto:\n\nSubplots (col y row)\nSubgrupos con color (hue)\n\nNuevas personalizaciones:\n\nSubgrupos con tama帽o de punto y estilo.\nCambio en la transparencia de los puntos.\n\nSe pueden utilizar en scatterplot() y relplot()\n\nSubgrupos con tama帽o de punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            size='size')\nplt.show()\n\n\n\n\n\n\n\n\nEl gr谩fico anterior es dif铆cil de leer pues todos los puntos son del mismo color. Su visualizaci贸n puede facilitarse utilizando lo siguiente:\n\nTama帽o de punto y hue\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            size='size',\n            hue='size')\nplt.show()\n\n\n\n\n\n\n\n\n\nSubbrupos con estilo de punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            hue='smoker',\n            size='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\nCambiando la transparencia del punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set alpha to be between 0 and 1\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            alpha=0.4)\n\nplt.show()\n\n\n\n\n\n\n\n\nEste 煤ltimo gr谩fico es muy 煤til cuando hay gran concentraci贸n de puntos\n\nCambiar el tama帽o de los puntos del diagrama del dispersi贸n\nEn este ejercicio, exploraremos el conjunto de datos mpg de Seaborn, que contiene una fila por modelo de coche e incluye informaci贸n como el a帽o de fabricaci贸n del coche, el n煤mero de millas por gal贸n (M.P.G.) que alcanza, la potencia de su motor (medida en caballos) y su pa铆s de origen.\n驴Cu谩l es la relaci贸n entre la potencia del motor de un coche (\"horsepower\") y su eficiencia de combustible (\"mpg\")? 驴Y c贸mo var铆a esta relaci贸n seg煤n el n煤mero de cilindros (\"cylinders\") que tenga el coche? Averig眉茅moslo.\nSigamos utilizando relplot() en lugar de scatterplot() ya que ofrece m谩s flexibilidad.\n\nimport pandas as pd\nmpg = pd.read_csv('./data/mpg.csv')\nmpg.head()\n\n\n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nmodel_year\norigin\nname\n\n\n\n\n0\n18.0\n8\n307.0\n130.0\n3504\n12.0\n70\nusa\nchevrolet chevelle malibu\n\n\n1\n15.0\n8\n350.0\n165.0\n3693\n11.5\n70\nusa\nbuick skylark 320\n\n\n2\n18.0\n8\n318.0\n150.0\n3436\n11.0\n70\nusa\nplymouth satellite\n\n\n3\n16.0\n8\n304.0\n150.0\n3433\n12.0\n70\nusa\namc rebel sst\n\n\n4\n17.0\n8\n302.0\n140.0\n3449\n10.5\n70\nusa\nford torino\n\n\n\n\n\n\n\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr谩fico de dispersi贸n con \"horsepower\" en el eje x y \"mpg\" en el eje y. Var铆a el tama帽o de los puntos seg煤n el n煤mero de cilindros del coche (\"cylinders\").\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create scatter plot of horsepower vs. mpg\nsns.relplot(x='horsepower', y='mpg',\n            data=mpg,\n            kind='scatter',\n            size='cylinders')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPara que el gr谩fico se m谩s f谩cil de leer, utiliza hue para variar el color de los puntos seg煤n el n煤mero de cilindros del coche (\"cylinders\").\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='horsepower', y='mpg',\n            data=mpg,\n            kind='scatter',\n            size='cylinders',\n            hue='cylinders')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos coches con mayor potencia tienden a tener un menor n煤mero de millas por gal贸n. Tambi茅n tienden a tener un mayor n煤mero de cilindros.\n\n\n\nCambiar el estilo de los puntos del gr谩fico de dispersi贸n\nSigamos explorando el conjunto de datos mpg de Seaborn observando la relaci贸n entre la velocidad a la que se puede acelerar un coche (\"acceleration\") y su eficiencia de combustible (\"mpg\"). 驴Var铆an estas propiedades seg煤n el pa铆s de origen (\"origin\")?\nObserva que la variable \"acceleration\" es el tiempo de aceleraci贸n de 0 a 60 millas por hora, en segundos. Los valores m谩s altos indican una aceleraci贸n m谩s lenta.\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr谩fico de dispersi贸n con \"acceleration\" en el eje x y \"mpg\" en el eje y. Var铆a el estilo y el color de los puntos de la trama seg煤n el pa铆s de origen (\"origin\").\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a scatter plot of acceleration vs. mpg\nsns.relplot(x='acceleration', y='mpg',\n            data=mpg,\n            kind='scatter',\n            style='origin',\n            hue='origin')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos coches de EE.UU tienden a acelerar m谩s r谩pido y obtener menos millas por gal贸n en comparaci贸n con los coches de Europa y Jap贸n.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>23</span> <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci贸n-a-los-gr谩ficos-lineales",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci贸n-a-los-gr谩ficos-lineales",
    "title": "Visualizar dos variables cuantitativas",
    "section": "Introducci贸n a los gr谩ficos lineales",
    "text": "Introducci贸n a los gr谩ficos lineales\n\nQu茅 son los diagramas de lineas?\n\nHay dos tipos de gr谩ficos relacionales: scatterpltos y lineplots\nScatterplots\n\nCada punto en el gr谩fico es una observaci贸n independiente.\n\nLineplots\n\nCada punto representa la misma cosa, t铆picamente seguida por el tiempo.\n\n\nEjemplo de Scatterplot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='scatter')\nplt.show()\n\n\n\nEjemplot de lineplot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line')\nplt.show()\n\n\n\nSubgrupos por localizaci贸n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location')\nplt.show()\n\n\n\nA帽adiendo marcadores\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location',\n            markers=True)\nplt.show()\n\n\n\nApagando los estilos de l铆neas\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location',\n            markers=True,\n            dashes=False)\nplt.show()\n\n\n\nM煤ltiples observaciones por valor de x\n\nScatter plot\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='scatter')\n\nplt.show()\n\n\n\nLine plot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='Line')\n\nplt.show()\n\n\n- La regi贸n sombreada es el intervalo de confianza\n    - Asuma que el dataset es una muestra aleatoria\n    - Hay 95% de confianza que la media est谩 dentro de este intervalo.\n    - Indicar la incertidumbre de nuestra estimaci贸n.\n\nReemplzando el intervalo de confianza con la desviaci贸n est谩ndar.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='line',\n            ci='sd')\nplt.show()\n\n\n\nDesactivando el intervalo de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='line',\n            ci=None)\nplt.show()\n\n\n\nInterpretaci贸n de gr谩ficos lineales\nEn este ejercicio, seguiremos explorando el conjunto de datos mpg de Seaborn, que contiene una fila por modelo de coche e incluye informaci贸n como el a帽o de fabricaci贸n del coche, su eficacia de combustible (medida en millas por gal贸n o M.P.G) y su pa铆s de origen (USA, Europa o Jap贸n).\n驴C贸mo ha cambiado con el tiempo la media de millas por gal贸n que alcanzan estos coches? 隆Utilicemos gr谩ficos lineales para averiguarlo!\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr谩fico de l铆neas con \"model_year\" en el eje x y \"mpg\" en el eje y.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a line plot\nsns.relplot(x='model_year', y='mpg',\n            data=mpg,\n            kind='line')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPreguntas\n\n驴Cu谩l de las siguientes no es una interpretaci贸n correcta de este gr谩fico?\nRespuestas posibles\n\nEl promedio de millas por gal贸n ha aumentado generalmente con el tiempo.\nLa distribuci贸n de millas por gal贸n es menor en 1973 que en 1977.\nEl intervalo de confianza del 95 % para la media de millas por gal贸n en 1970 es de aproximadamente 16 - 19,5 millas por gal贸n.\nEste gr谩fico supone nuestros datos son una muestra aleatoria de todos los coches de US, Europa y Jap贸n.\n\nLa regi贸n sombreada representa un intervalo de confianza para la media, no la distribuci贸n de las observaciones.\n\n\n\nVisualizaci贸n de la desviaci贸n est谩ndar con gr谩fico de l铆neas\nEn el 煤ltimo ejercicio, vimos c贸mo ha cambiado a lo largo del tiempo la media de millas por gal贸n que alcanzan los coches. Ahora utilicemos un gr谩fico lineal para visualizar c贸mo ha cambiado la distribuci贸n de millas por gal贸n a lo largo del tiempo.\n\nInstrucciones\n\nCambia el gr谩fico para que el 谩rea sombreada muestre la desviaci贸n est谩ndar en lugar del intervalo de confianza para la media.\n\n\n# Make the shaded area show the standard deviation\nsns.relplot(x='model_year', y='mpg',\n            data=mpg,\n            kind='line',\n            errorbar='sd') # el par谩metro ci fue deprecado\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nA diferencia del gr谩fico en el 煤ltimo ejercicio, este gr谩fico nos muestra la distribuci贸n de millas por gal贸n para todos los coches en cada a帽o.\n\n\n\nTrazar subgrupos en gr谩ficos de l铆neas\nSigamos examinando el conjunto de datos mpg. Hemos visto que la media de millas por gal贸n de los coches ha aumentado con el tiempo, pero, 驴c贸mo ha cambiado la media de caballos de los coches con el tiempo? 驴Y difiere esta tendencia seg煤n el pa铆s de origen?\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr谩fico de l铆neas con \"model_year\" en el eje x y \"horse_power\" en el eje y. Desactiva los intervalos de confianza en el gr谩fico.\n\n\n# Import matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create line plot of model year vs. horsepower\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None)\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCrea l铆neas diferentes para cada pa铆s (\"origin\") que var铆en tanto en estilo de l铆nea como en color.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create line plot of model year vs. horsepower\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None,\n            style='origin',\n            hue='origin')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA帽ade marcadores para cada punto de datos a las l铆neas.\n\n\nUtiliza el par谩metro dashes para utilizar l铆neas continuas para todos los pa铆ses, permitiendo al mismo tiempo diferentes estilos de marcador para cada l铆nea.\n\n\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None,\n            style='origin',\n            hue='origin',\n            markers=True,\n            dashes=False)\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nAhora hemos a帽adido subgrupos, podemos ver que esta tendencia a la baja en la potencia fue m谩s pronunciada entre los coches de EE.UU.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>23</span> <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html",
    "title": "Visualizar una variable categ贸rica y una cuantitativa",
    "section": "",
    "text": "Gr谩ficos de recuento y de barras.\nLas variables categ贸ricas est谩n presentes en casi todos los conjuntos de datos, pero destacan especialmente en los datos de encuestas. En este cap铆tulo aprender谩s a crear y personalizar gr谩ficos categ贸ricos, como gr谩ficos de caja, gr谩ficos de barras, gr谩ficos de recuentro y gr谩ficos de puntos. Por el camino, explorar谩s datos de encuestas a j贸venes sobre sus intereses, a estudiantes sobre sus h谩bitos de estudio y a hombres adultos sobre sus sentimientos acerca de la masculinidad.\nimport matplotlib.pyplot as plt\nimport seaborn as from django.conf import settings\nsns.countplot(x='how_masculine',\n              data=maculinity_data)\n\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count')\n\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncategory_order=['No answer',\n                'Not at all',\n                'Not very',\n                'Somewhat',\n                'Very']\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count',\n            order=category_order)\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='day', y='total_bill',\n            data=tips,\n            kind='bar')\nplt.show()\nimport matplotlib.plyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='day', y='total_bill',\n            data=tips,\n            kind='bar',\n            ci=None)\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='total_bill', y='day',\n            data=tips,\n            kind='bar')\nEs com煤n poner la variable categ贸rica en el eje x",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>24</span> <span class='chapter-title'>Visualizar una variable categ贸rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr谩ficos-de-recuento-y-de-barras.",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr谩ficos-de-recuento-y-de-barras.",
    "title": "Visualizar una variable categ贸rica y una cuantitativa",
    "section": "",
    "text": "Gr谩ficos categ贸ricos\n\nEjemplos: Gr谩ficos de recuento y de barras\nIncluyen variables categ贸ricas.\nComparaciones entre grupos\n\n\ncatplot()\n\nUsado para crear gr谩ficos categ贸ricos\nTiene las mismas ventajas de relplot()\nSe pueden crear facilmente subgr谩ficos con col= y row=\n\ncountplot() vs.catplot()\n\n\n\n\nCambiando el orden\n\n\n\n\nGr谩fico de barras\n\nMuestran la media de una variable cuantitativa por categor铆a\n\n\n\n\n\nIntervalos de confianza\n\nLas l铆neas muestran los intervalos de confianza del 95% para la media.\nMuestran el nivel de incertidumbre sobre las estimaciones.\nAsumiendo que nuestros datos sean una muestra aleatoria.\n\nDesactivando los intervalos de confianza\n\n\n\n\nCambiando la orientaci贸n de las barras\n\n\n\n\n\nGr谩ficos de recuento\nEn este ejercicio, volveremos a explorar nuestro conjunto de datos que contiene las respuestas a una encuesta enviada a los j贸venes. Podr铆amos sospechar que los j贸venes pasan mucho tiempo en internet, pero 驴Cu谩nto declaran utilizar internet al d铆a? Utilicemos un gr谩fico de recunto para desglosar el n煤mero de respuestas de la encuesta en cada categor铆a y luego exploremos si cambia en funci贸n de la edad.\nComo recordatorio, para crear un gr谩fico de recuento, utilizaremos la funci贸n catplot() y especificaremos el nombre de la variable categ贸rica a contar (x=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr谩fico (kind=\"count\").\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = (10, 5)\n\nruta = './data/young-people-survey-responses.csv'\nsurvey_data = pd.read_csv(ruta, index_col=0)\nsurvey_data.head()\n\n\n\n\n\n\n\n\nMusic\nTechno\nMovies\nHistory\nMathematics\nPets\nSpiders\nLoneliness\nParents' advice\nInternet usage\nFinances\nAge\nSiblings\nGender\nVillage - town\nAge Category\nInterested in Math\n\n\n\n\n0\n5.0\n1.0\n5.0\n1.0\n3.0\n4.0\n1.0\n3.0\n4.0\nfew hours a day\n3.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n1\n4.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n2.0\n2.0\nfew hours a day\n3.0\n19.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n2\n5.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n5.0\n3.0\nfew hours a day\n2.0\n20.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n3\n5.0\n2.0\n5.0\n4.0\n4.0\n1.0\n5.0\n5.0\n2.0\nmost of the day\n2.0\n22.0\n1.0\nfemale\ncity\n21+\nTrue\n\n\n4\n5.0\n2.0\n5.0\n3.0\n2.0\n1.0\n1.0\n3.0\n3.0\nfew hours a day\n4.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n\n\n\n\n\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr谩fico de recuento utilizando el DataFrame survery_data con \"Internet usage\" en el eje x.\n\n\n# Create count plot of internet usage\nsns.catplot(x='Internet usage',\n            data=survey_data,\n            kind='count')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nHaz que las barras sean horizontales en lugar de verticales\n\n\n# Change the orientation of the plot\nsns.catplot(y='Internet usage',\n            data=survey_data,\n            kind='count')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nSepara este gr谩fico en dos subtramas de columnas contiguas en funci贸n de \"Age Category\", que separa a los encuestados en menores de 21 a帽os y mayores de 21 a帽os. A partir de 21 a帽os.\n\n\n# Separate ubti cikynb subplots based on age category\nsns.catplot(y='Internet usage',\n            data=survey_data,\n            kind='count',\n            col='Age Category')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la mayor铆a de los j贸venes usan internet durante pocas horas todos los d铆as, independientemente de su edad.\n\n\n\nDiagramas de barras con porcentajes\nSigamos explorando las respuestas a una encuesta enviada a los j贸venes. La variable \"Interested in Math\" es True si la persona declar贸 estar interesada o muy interesada en las matem谩ticas, y False en caso contrario. 驴Qu茅 porcentaje de j贸venes afirma estar interesado en las matem谩ticas, y var铆a esto en funci贸n del g茅nero? Utilicemos un diagrama de barras para averiguarlo.\nComo recordatorio, crearemos un gr谩fico de barras utilizando la funci贸n catplot(), proporcionando el nombre de la varible categ贸rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr谩fico categ贸rico (kind=\"bar\").\n\nInstrucciones\n\nUtiliza el DataFrame survey_data y sns.catplot() para crear un gr谩fico de barras con \"Gender\" en el eje x y \"Interested in Math\" en el eje y.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a bar plot of interest in math, separated by gender \nsns.catplot(x='Gender', y='Interested in Math',\n            data=survey_data,\n            kind='bar')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nCuando la variable y es Verdadero/Falso, los gr谩ficos de barras mostrar谩n el porcentaje de respuestas que informan Verdadero. Este gr谩fico nos muestra que los hombres informan un inter茅s mucho mayor en las matem谩ticas en comparaci贸n con las mujeres.\n\n\n\nPersonalizar gr谩ficos de barras\nEn este ejercicio, exploraremos datos de alumnos de secundaria. La variable \"study_time\" registra el tiempo de estudio semanal declarado por cada estudiante como una de las siguientes categor铆as: \"&lt;2 hours\", \"2 to 5 hours\", \"5 to 10 hours\", o \"&gt;10 hours\". 驴Los alumnos que declaran estudiar m谩s tienden a obtener mejores notas finales Comparemos la nota media final entre los alumnos de cada categor铆a mediante un diagrama de barras.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/student-alcohol-consumption.csv'\nstudent_data = pd.read_csv(ruta, index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows  29 columns\n\n\n\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr谩fico de barras con \"study_time\" en el eje x y la calificaci贸n final (\"G3\") en el eje y, utilizando el DataFrame student_data.\n\n\n# Create bar plot of average final grade in each study category\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nUtilizando el par谩metro order y la lista category_order que se proporciona, reorganiza las barras para que est茅n en orden de menor tiempo de estudio a mayor.\n\n\n# List of categories from lowest to highest\ncategory_order = ['&lt;2 hours',\n                  '2 to 5 hours',\n                  '5 to 10 hours',\n                  '&gt;10 hours']\n\n# Rearrange the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar',\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nActualiza el gr谩fico para que ya no muestre los intervalos de confianza.\n\n\n# List of categories from lowest to highest\ncategory_order = ['&lt;2 hours',\n                  '2 to 5 hours',\n                  '5 to 10 hours',\n                  '&gt;10 hours']\n\n# Rearrange the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar',\n            order=category_order,\n            errorbar=None) # ci=None deprecated\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes en nuestra muestra que estudiaron m谩s tienen un promedio de calificaciones ligeramente m谩s alto, pero no es una relaci贸n fuerte.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>24</span> <span class='chapter-title'>Visualizar una variable categ贸rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#diagramas-de-caja",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#diagramas-de-caja",
    "title": "Visualizar una variable categ贸rica y una cuantitativa",
    "section": "Diagramas de caja",
    "text": "Diagramas de caja\n\n驴Qu茅 es un diagrama de caja?\n\nMuestra la distribuci贸n de datos cuantitativos.\nSe puede ver la mediana, la dispersi贸n, la asimetr铆a y los datos at铆picos.\nFacilita la comparaci贸n entre grupos.\n\n\n\n\nC贸mo crear un diagrama de caja en Seaborn\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box')\nplt.show()\n\n\n\nCambiar el orden de las categor铆as\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                order=['Dinner',\n                        'Lunch'])\nplt.show()\n\n\n\nOmitir los valores at铆picos usando sym\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                sym='')\nplt.show()\n\n\n\nCambiando los bigotes usando whis\n\nPor defecto, los bigotes se extienden a 1.5 * el rango intercuartil.\nPuede ser extendido a 2.0 * IQR: whis=2.0\nMuestra los percentiles 5 y 95: whis=[5, 95]\nMuestra los valores m铆nimo y m谩ximo: whis=[0, 100]\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                whis=[0, 100])\nplt.show()\n\n\n\nCrea e interpreta un diagrama de cajas\nSigamos utilizando el conjunto de datos student_data. En un ejercicio anterior, exploramos la realci贸n entre el estudio y la nota final utlizando un digrama de barras para comparar la nota final media (\"G3\") entre los estudiantes de diferentes categor铆as de \"study_time\".\nEn este ejercicio, intentaremos utilizar un diagrama de cajas para ver esta relaci贸n. Como recordatorio, para crear un gr谩fico de caja tendr谩s que utilizar la funci贸n catplot() y especificar el nombre de la variable categ贸rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrme de pandas a utilizar (data=____), y el timpo de gr谩fico (kind=\"box\").\n\nInstrucciones\n\nUtiliza sns.catplot(), y el DataFrame student_data para crear un gr谩fico de caja con \"study_time\" en el eje x y \"G3\" en el eje y. Establece el orden de las categor铆as en study_time_order.\n\n\n# Specify the category ordering\nstudy_time_order = ['&lt;2 hours', '2 to 5 hours',\n                    '5 to 10 hours', '&gt;10 hours']\n\n# Create a box plot and set the order of the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='box',\n            order=study_time_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta 驴 Cu谩l de las siguientes es una interpretaci贸n correcta de este diagrama de caja?\n\nRespuestas Posibles\n\nEl percentil 75 de las notas es m谩s alto entre los alumnos que estudian m谩s de 10 horas a la semana.\nNo hay valores at铆picos en estos gr谩ficos de caja.\nEl percentil 5 de las notas entre los alumnos que estudian memnos de 2 horas es de 5,0.\nLa nota media entre los alumnos que estudian menos de 2 horas es de 10,0.\n\nLa l铆nea del medio de cada caja representa la mediana.\n\n\n\nOmitir valores at铆picos\nAhora vamos a utilizar el conjunto de datos student_data para ocmparar la distribuci贸n de las calificaciones finales (\"G3\") entre los estudiantes que tienen acceso a internet en casa y los que no. Para ello, utilizaremos la variable `internet, que es un indicador binario (si/no) de si un alumno tiene acceso a internet en casa.\nDado que internet puede ser menos accesible en las zonas rurales, a帽adiremos subgrupos en funci贸n de d贸nde viva el alumno. Pra ello, podemos utilizar la varible \"location\", que es un indicador de su un estudiante vive en una localidad urbana (Urban) o rural (Rural).\nComo recordatorio, puedes omitir los valores at铆picos en los gr谩ficos de caja estableciendo el par谩metro sym iguan a una cadena vac铆a (\"\").\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr谩fico de caja con el DataFrame student_data, poniendo internet en el eje x y \"G3\" en el eje y.\n\n\n# Create a box plot with subgroups and omit the outliers\nsns.catplot(x='internet', y='G3',\n            data=student_data,\n            kind='box',\n            col='location',\n            hue='location',\n            showfliers=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLas calificaciones medianas son bastante similares entre cada grupo, pero la dispersi贸n de la distribuci贸n parece mayor entre los estudiantes que tienen acceso a internet.\n\n\n\nAjustar los bigotes\nEn la lecci贸n vimos que m煤ltiples formas de definir los bigotes en un diagrama de caja. En esta serie de ejercicios, seguiermos utilizando el conjunto de datos student_data para comparar la distribuci贸n de las calificaciones finales (\"G3\") entre los estudiantes que mantienen un relaci贸n rom谩ntica y los que no. Utilizaremos la variable \"romantic\", que es un indicador si/no de si el alumno tiene una relaci贸n rom谩ntica.\nVamos a crear un diagrama de cajas para ver esta relaci贸n y probar distintas formas de definir los bigotes.\n\nInstrucciones\n\nAjusta el c贸digo para que los bigotes del diagrama de caja se extiendan hata 0,5 * IQR. Recuerda: el IQR es el rango intercuart铆lico.\n\n\n# Set the whiskers to 0.5 * IQR\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=0.5)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el c贸digo para que los bigotes se extiendan hasta los percentiles 5 y 95\n\n\n# Extend the whiskers to the 5th and 95th percentile\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=[5, 95])\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el c贸digo para que los bigotes se extiendan hsta los valores m铆nimo y m谩ximo.\n\n\n# Set the wiskers at the min and max values\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=[0, 100])\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLa nota media es la misma entre estos dos grupos, pero la nota m谩xima es m谩s alta entre los estudiantes que no est谩n en una relaci贸n rom谩ntica.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>24</span> <span class='chapter-title'>Visualizar una variable categ贸rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr谩fico-de-puntos",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr谩fico-de-puntos",
    "title": "Visualizar una variable categ贸rica y una cuantitativa",
    "section": "Gr谩fico de puntos",
    "text": "Gr谩fico de puntos\n\n驴Qu茅 son los gr谩ficos de puntos?\n\nLos puntos muestran la media de una variable cuantitativa.\nLas l铆neas verticales muestran los intervalos de confianza del 95%.\n\nGr谩ficos de puntos vs Gr谩ficos de l铆neas\n\nAmbos muestran:\n\nLa media de una variable cuantitativa.\nLos intervalos de confianza del 95% para la media\n\nDiferencias:\n\nLos gr谩ficos de l铆nea tienen variables cuantitativas (usualmente tiempo) en el eje x.\nLos gr谩ficos de puntos son variables categ贸ricas en el eje x.\n\n\nGr谩ficos de puntos vs Gr谩ficos de barras\n\nAmbos muestran:\n\nLa media de una variable cuantitativa.\nLos intervalos de confianza del 95% para la media\n\n\n\n\n\nCrear un Gr谩fico de puntos\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            kind='point',\n            hue='feel_masculine')\n            \nplt.show()\n\n\n\nDesconectando los puntos\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            kind='point',\n            hue='feel_masculine',\n            join=False)\n            \nplt.show()\n\n\n\nDesplegando la mediana\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import median\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            estimator=median)\n            \nplt.show()\n\n\n\nPersonalizar los intervalos de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            capsize=0.2)\n            \nplt.show()\n\n\n\nDesactivar los intervalos de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            ci=None)\n            \nplt.show()\n\n\n\nPersonalizar los gr谩ficos de puntos\nSigamos examinando datos de alumnos de secundaria, esta vez utilizando un gr谩fico de puntos para responder a la pregunta: 驴Influye la calidad de la realci贸n familiar del alumno en el n煤mero de faltas que tiene en la escuela? Aqu铆 utilizaremos la variable \"famrel\", que describe la calidad de la relaci贸n familiar de un alumno de 1 (muy mala) a 5 (muy buena).\nComo recordatorio, para crear un gr谩fico de puntos, utiliza la funci贸n catplot() y especifica el nombre de la variable categ贸rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr谩fico categ贸rico (kind=\"point\").\n\nInstrucciones\n\nUtiliza sns.catplot() y el DataFrame student_data para crear un gr谩fico de puntos con \"famrel\" en el eje x y el n煤mero de ausencias (\"absences\") en el eje y.\n\n\n# Create a point plot of family relationship vs. absences\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA帽ade may煤sculas al final de los intervalos de confianza con el tama帽o 0.2.\n\n\n# Add caps to the cofidence interval\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point',\n            capsize=0.2)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nElimina las l铆neas que unen los puntos de cada categor铆a.\n\n\n# Remove the lines joining the points\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point',\n            capsize=0.2,\n            linestyle='none') # deprecated join=False\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nAunque el n煤mero promedio de ausencias es ligeramente menor entre los estudiantes con relaciones familiares de mayor calidad, los grandes intervalos de confianza nos dicen que no podemos estar seguros de que haya una asociaci贸n real aqu铆.\n\n\n\nGr谩ficos de punto con subgrupos\nSigamos explorando el conjunto de datos de los alumnos de secundaria. Esta vez, formularemos la pregunta: 驴estar en una relaci贸n rom谩ntica est谩 asociado a una mayor o menor asistencia a la escuela? 驴Y difiere esta asociaci贸n en funci贸n de la escuela a la que asisten los alumnos? Averig眉茅moslo mediante un gr谩fico de puntos.\n\nInstrucciones\n\nUtiliza sns.catplot() y el DataFrame student_data para crear un gr谩fico de puntos con el estado de la relaci贸n (\"romantic\") en el eje x y el n煤mero de ausencias (\"absences\") en el eje y. Colorea los puntos seg煤n la escuela a la que asistan (\"school\").\n\n\n# Create a point plot that uses color to create subgroups\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nDesactiva los intervalos de confianza del gr谩fico.\n\n\n# Turn off the confidence intervals for this plot\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school',\n            errorbar=None) # deprecated ci=None)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nComo puede haber valores at铆picos de alumnos con muchas ausencias, utiliza la funci贸n median que hemos importado de numpy para mostar la mediana de n煤mero de ausencias en lugar de la media.\n\n\n# Import median function from numpy\nfrom numpy import median\n\n# Plot the median number of absences instead of the mean\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school',\n            errorbar=None,\n            estimator=median)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que los estudiantes en relaciones rom谩nticas tienen un promedio y una mediana m谩s altos de ausencias en la escuela GP, pero esta asociaci贸n no se mantiene en la escuela MS.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>24</span> <span class='chapter-title'>Visualizar una variable categ贸rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "",
    "text": "Cambiar el estilo y el color de la trama\nEn este 煤ltimo cap铆tulo, aprender谩s a a帽adir t铆tulos informativos a los gr谩ficos y etiquetas a los ejes, 隆que son una de las partes m谩s importantes de cualquier visualizaci贸n de datos! Tambi茅n aprender谩s a personalizar el estilo de tus visualizaciones para orientar m谩s r谩pidamente a tu audiencia hacia los puntos clave. Despu茅s, pondr谩s en com煤n todo lo que has aprendido en los ejercicios finales del curso.\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\nplt.show()\nsns.set_style('whitegrid')\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\nplt.show()\nsns.set_palette('RdBu')\n\ncategory_order = [\"No answer\",\n                  \"Not al all\",\n                  \"Not very\",\n                  \"Somewhat\",\n                  \"Very\"]\n\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count',\n            order=category_order)\nplt.show()\ncustom_palette = [\"red\", \"green\", \"orange\", \"blue\",\n                  \"yellow\", \"purple\"]\n\nsns.set_palette(custom_palette)\ncustom_palette = [\"#FBB4AE\", \"#B3CDE3\", \"#CCEBC5\",\n                  \"#DECBE4\", \"#FED9A6\", \"#FFFFCC\",\n                  \"#E5B8BD\", \"#FDDAEC\", \"#F2F2F2\"]\n\nsns.set_palette(custom_palette)\nsns.catplot(x='age',\n            y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\n\nplt.show()\nsns.set_context('talk')\n\nsns.catplot(x='age',\n            y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\n\nplt.show()",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#cambiar-el-estilo-y-el-color-de-la-trama",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#cambiar-el-estilo-y-el-color-de-la-trama",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "",
    "text": "Por qu茅 personalizar?\n\nRazones para cambiar de estilo:\n\nPreferencias personales\nMejorar la legibilidad\nGuiar la interpretaci贸n\n\n\nCambiando los estilos de las figuras\n\nLos estilos de las figuras incluyen el fondo y los ejes\nOpciones: white, dark, whitegrid, darkgrid, ticks\nPara establecer uno de ellos como estilo global para todos los gr谩ficos se utiliza sns.set_style()\n\nEstilo de figura por defecto (white)\n\nSi solo nos interesa la tendencia general:\n\n\n\n\n\nEstilo de figura: whitegrid\n\nPara determinar valores espec铆ficos:\n\n\n\n\n\nCambiando la paleta\n\nLos cambios en la paleta de la figura, cambia el color de los elementos principales del gr谩fico\nsns.set_palette()\nUse las paletas preestablecidas o personalizadas\n\nPaletas divergentes\n\n\n\nEjemplo (Paleta divergente)\n\n\n\n\nPaletas secuenciales\n\n\n\nEjemplo de paleta secuencial\n\n\n\nPaletas personalizadas\n\n\n\n\n\n\nCambiar la escala del gr谩fico\n\nEn las figuras context cambia la escala de los elementos y etiquetas del gr谩fico\n`sns.set_context()`\nDel mas peque帽o al m谩s grande: paper, notebook, talk, poster.\n\nContexto por defecto: paper\n\n\n\n\nContexto grande: talk\n\nPresentaciones donde el p煤blico este mas alejado del gr谩fico\n\n\n\n\n\nCambiar de estilo y de paleta\nVamos a nuestro conjunto de datos que contiene los resultados de una encuestra realizada a j贸venes sobre sus h谩bitos y preferencias. Hemos proportcionado el c贸digo para crear un gr谩fico de recuento de sus respuestas a la pregunta 驴Con qu茅 frecuencia escuchas los consejos de tus padres?. Ahora vamos a cambiar el estilo y la paleta para que esta trama sea m谩s f谩cil de interpretar.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/young-people-survey-responses.csv'\nsurvey_data = pd.read_csv(ruta, index_col=0)\nsurvey_data.head()\n\n\n\n\n\n\n\n\nMusic\nTechno\nMovies\nHistory\nMathematics\nPets\nSpiders\nLoneliness\nParents' advice\nInternet usage\nFinances\nAge\nSiblings\nGender\nVillage - town\nAge Category\nInterested in Math\n\n\n\n\n0\n5.0\n1.0\n5.0\n1.0\n3.0\n4.0\n1.0\n3.0\n4.0\nfew hours a day\n3.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n1\n4.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n2.0\n2.0\nfew hours a day\n3.0\n19.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n2\n5.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n5.0\n3.0\nfew hours a day\n2.0\n20.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n3\n5.0\n2.0\n5.0\n4.0\n4.0\n1.0\n5.0\n5.0\n2.0\nmost of the day\n2.0\n22.0\n1.0\nfemale\ncity\n21+\nTrue\n\n\n4\n5.0\n2.0\n5.0\n3.0\n2.0\n1.0\n1.0\n3.0\n3.0\nfew hours a day\n4.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n\n\n\n\n\nTransformaci贸n de los datos de la columna \"Parents' advice\"\n\nsurvey_data[\"Parents' advice\"] = survey_data[\"Parents' advice\"].map({1: 'Never',\n                                                                     2: 'Rarely',\n                                                                     3: 'Sometimes',\n                                                                     4: 'Often',\n                                                                     5: 'Always'})\n\n\nInstrucciones\n\nConfigura el estilo en \"whitegrid\" para ayudar al p煤blico a determinar el n煤mero de respuestas de cada categor铆a.\n\n\n# Set the style to \"whitegrid\"\nsns.set_style('whitegrid')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count',\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nEstablece la paleta de colores en la paleta secuencial denominada \"Purples.\n\n\n# Set the color palette to \"Purples\"\nsns.set_style('whitegrid')\nsns.set_palette('Purples')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count',\n            order=category_order,\n            hue=\"Parents' advice\", legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia la paleta de colores a la paleta divergente \"RdBu\"\n\n\n# Change the color palette to \"RdBu\"\nsns.set_style('whitegrid')\nsns.set_palette('RdBu')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count', \n            hue=\"Parents' advice\", legend=False,\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nEste estilo y la paleta de colores divergente resaltan mejor la diferencia entre el n煤mero de j贸venes que suelen escuchar los consejos de sus padres frente a los que no lo hacen.\n\n\n\nCambiar la escala\nEn este ejercicio, seguiremos examinando el conjunto de datos que contienen las respuestas de una encuesta a j贸venes. 驴Var铆a el porcentaje de personas que declaran sentirse solas en funci贸n del n煤mero de hermanos que tienen? Averig眉茅moslo utlizando un diagrama de barras, al tiempo que exploramos las cuatro escalas de diagrama diferentes de Seaborn. (contextos).\n\nInstrucciones\n\nEstablece la escala (contexto) en \"paper\", que es la m谩s pequie帽a de las opciones de escala.\n\n\n# Set the context to \"paper\"\nsns.set_context('paper')\n\n# Create bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"notebook\" para aumentar la escala.\n\n\n# Change the context to \"notebook\"\nsns.set_context(\"notebook\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"talk\" para aumentar la escala.\n\n\n# Change the context to \"notebook\"\nsns.set_context(\"talk\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"poster\", que es la mayor escala disponbible.\n\n\n# Change the context to \"poster\"\nsns.set_context(\"poster\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nCada nombre de contexto da la sugerencia de Seaborn sobre cu谩ndo usar una escala de gr谩fico dada (es un art铆culo, en un cuadrno de iPythonm en una charla/presentaci贸n o en una sesi贸n de p贸ster).\n\n\n\nUtilizar una paleta personalizada\nHasta ahora, hemos analizado varias cosas en el conjunto de datos de las respuestas a las encuestas de los j贸venes, como el uso que hacen de internet, la frecuencia con que escuchan a sus padres y cu谩ntos de ellos dicen sentirse solos. Sin embargo, algo que no hemos hecho es un resumen b谩sico del tipo de personas que responden a esta encuesta, incluyendo su edad y g茅nero. Proporcionar estos res煤menes b谩sicos es siempre una buena pr谩ctica cuando se trata de un conjunto de datos desconocido.\nEl c贸digo proporcionado crear谩 un diagrama de cajas que mostrar谩 la distribuci贸n de edades de los encuestados masculinos frente a los femeninos. Vamos a ajustar el c贸digo para personalizar la apariencia , esta vez utilizando una paleta de colores personalizada.\n\nInstrucciones\n\nEstablece el estilo en \"darkgrid\".\nEstablece una paleta de colores personalizada con los c贸digos hexadecimales de color \"#39A7D0\" y \"#36ADA4\".\n\n\nsns.set_context('notebook')\n\n# Set the style to \"darkgrid\"\nsns.set_style('darkgrid')\n\n# Set a custom color palette\nsns.set_palette(['#39A7D0', '#36ADA4'])\n\n# Create the box plot of age distribution by gender\nsns.catplot(x='Gender', y='Age',\n            data=survey_data, kind='box',\n            hue='Gender', legend=False)  # se agregan pues palette sera deprecated\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la edad media es la misma para hombres y mujeres, pero la distribuci贸n de las mujeres se inclina hacia edades m谩s j贸venes que la de los hombres.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a帽adir-t铆tulos-y-etiquetas-parte-1",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a帽adir-t铆tulos-y-etiquetas-parte-1",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "A帽adir t铆tulos y etiquetas: Parte 1",
    "text": "A帽adir t铆tulos y etiquetas: Parte 1\n\nCreando visualizaciones informativas\n\nSe a帽ade un t铆tulo.\nLas etiquetas de los ejes son informativas.\nLas etiquetas del eje x estan giradas para mayor claridad.\n\n\n\n\nObjetos FacetGrid vs.AxesSubplot\n\nLos gr谩ficos de Seaborn creean dos diferentes tipos de objetos: FacetGrid y AxesSubplot.\n\n\n\ng = sns.scatterplot(x='height', y='weight', data=df)\ntype(g)\n\n\nmatplotlib.axes._subplots.AxesSubplot\n\n\nFacetGrid vac铆o\n\nEsta formado por uno o varios AxesSuubplots\n\n\nObjetos FacetGrid vs.AxesSubplot\n\n\n\n\n\n\n\n\nTipo de Objeto\nTipo de gr谩fico\nCaracter铆sticas\n\n\n\n\nFacetGrid\nrelplot(), catplot()\nPuede crear subplots\n\n\nAxesSubplot\nscatterplot, countplot, etc.\nCrea un solo gr谩fico\n\n\n\nA帽adiendo un t铆tulo al FacetGrid\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box')\n\ng.fig.suptitle('New Title',\n                y=1.03)\n\nplt.show()\n\n\n\nFacetGrids vs.AxesSubplots\nEn la lecci贸n reciente, aprendimos que las funciones de trazado de Seaborn crean dos tipos diferentes de objetos: objetos FacetGrid y objetos AxesSubplot. El m茅todo para a帽adir un t铆tulo a tu gr谩fico variar谩 en funci贸n del tipo de objeto que sea.\nEn el c贸digo proporcionadom hemos utilizado relplot() con el conjunto de datos de millas por gal贸n para crear un gr谩fico de dispersi贸n que muestra la realaci贸n entre el peso de un coche y su potencia. Este gr谩fico de dispersi贸n se asigna a la variable g. Identifiquemos de qu茅 tipo de objeto se trata.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/mpg.csv'\nmpg = pd.read_csv(ruta)\nmpg.head()\n\n\n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nmodel_year\norigin\nname\n\n\n\n\n0\n18.0\n8\n307.0\n130.0\n3504\n12.0\n70\nusa\nchevrolet chevelle malibu\n\n\n1\n15.0\n8\n350.0\n165.0\n3693\n11.5\n70\nusa\nbuick skylark 320\n\n\n2\n18.0\n8\n318.0\n150.0\n3436\n11.0\n70\nusa\nplymouth satellite\n\n\n3\n16.0\n8\n304.0\n150.0\n3433\n12.0\n70\nusa\namc rebel sst\n\n\n4\n17.0\n8\n302.0\n140.0\n3449\n10.5\n70\nusa\nford torino\n\n\n\n\n\n\n\n\nInstrucciones\n\nIdentifica qu茅 tipo de objeto es el gr谩fico g y as铆gnalo a la variable type_of_g\n\n\nsns.set_style('white')\n\n# Create a scatter plot\ng = sns.relplot(x='weight', y='horsepower',\n                    data=mpg, kind='scatter')\n\n# Identify plot type\ntype_of_g = type(g)\n\n# Print type\nprint(type_of_g)\n\n&lt;class 'seaborn.axisgrid.FacetGrid'&gt;\n\n\n\n\n\n\n\n\n\n\nPregunta\n\nAcabamos de ver que sns.relplot() crea objetos FacetGrid. 驴Qu茅 otra funci贸n Seaborn crea un objeto FacetGrid en lugar de un objeto AxesSubplot?\nRespuestas posibles\n\nsns.catplot()\nsns.scatterplot()\nsns.boxplot()\nsns.countplot()\n\ncatplot() admite la creaci贸n de subgr谩ficos, por lo que crea un objeto FacetGrid.\n\n\n\nA帽adir un t铆tulo a un objeto FacetGrid\nEn el ejercicio anterior, utilizamos relplot() con el conjunto de datos de millas por gal贸n para crear un gr谩fico de dispersi贸n que mostrara la relaci贸n entre el peso de un coche y su potencia. Esto cre贸 el objeto FacetGrid. Ahora que sabemos qu茅 tipo de objeto es, vamos a a帽adir un t铆tulo a esta trama.\n\nInstrucciones\n\nA帽ade un t铆tulo a esta trama: \"Car Wight vs. Horsepower\".\n\n\n# Create a scatter plot\ng = sns.relplot(x='weight', y='horsepower',\n            data=mpg, kind='scatter')\n\n# Add a title \"Car Weight vs. Horsepower\"\ng.fig.suptitle('Car Weight vs. Horsepower')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que el peso de un coche est谩 correlacionado positivamente con su potencia.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a帽adir-t铆tulos-y-etiquetas-parte-2",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a帽adir-t铆tulos-y-etiquetas-parte-2",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "A帽adir t铆tulos y etiquetas: Parte 2",
    "text": "A帽adir t铆tulos y etiquetas: Parte 2\n\nA帽adiendo un t铆tulo a AxesSubplot\n\nFacetGrid\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data,\n                kind='box')\n\ng.fig.suptitle('New Title',\n               y=1.03)\n\n\nAxesSubplot\n\ng = sns.boxplot(x='Region', y='Birtrate',\n                data=gdp_data)\n\ng.set_title('New Title',\n            y=1.03)\n\n\nT铆tulos para subgr谩ficos\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\n# T铆tulo general\ng.fig.suptitle('New Title',\n                y=1.03)\n\n# T铆tulo de cada gr谩fico\ng.set_title('This is {col_name}')\n\n\n\nA帽adir etiquetas a los ejes\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\ng.set(xlabel='New X Label',\n      ylabel='New Y Label')\n\nplt.show()\n\n\n\nRotando las etiquetas del eje x\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\nplt.xticks(rotation=90)\nplt.show()\n\n\n\nA帽adir un t铆tulo y etiquetas de eje\nSigamos examinando el conjunto de datos de millas por gal贸n. Esta vez crearemos un gr谩fico lineal para responder a la pregunta: 驴C贸mo cambia a lo largo del tiempo la media de millas por gal贸n que alcanzan los coches en cada uno de los tres lugares de origen? Para mejorar la legibilidad de este gr谩fico, a帽adiremos un t铆tulo y etiquetas de eje m谩s informativas.\nEn el c贸digo proporcionado, creamos el gr谩fico de l铆neas utilizando la funci贸n lineplot(). Ten encuenta que lineplot() no admite la creaci贸n de subtramas, por lo que devuelve un obejeto AxesSubplot en lugar d eun objeto FacetGrid.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/mpg_mean.csv'\nmpg_mean = pd.read_csv(ruta, index_col=0)\nmpg_mean.head()\n\n\n\n\n\n\n\n\nmodel_year\norigin\nmpg_mean\n\n\n\n\n0\n70\neurope\n25.200000\n\n\n1\n70\njapan\n25.500000\n\n\n2\n70\nusa\n15.272727\n\n\n3\n71\neurope\n28.750000\n\n\n4\n71\njapan\n29.500000\n\n\n\n\n\n\n\n\nInstrucciones\n\nA帽ade el siguiente t铆tulo a la trama: \"Average MPG Over Time\".\n\n\n# Create a line plot\ng = sns.lineplot(x='model_year', y='mpg_mean',\n                 data=mpg_mean, hue='origin')\n\n# Add title \"Average MPG Over Time\"\ng.set_title('Average MPG Over Time')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nEtiqueta el eje x como \"Car Model Year\" y el eje y como \"Average MPG\".\n\n\n# Create a line plot\ng = sns.lineplot(x='model_year', y='mpg_mean',\n                 data=mpg_mean, hue='origin')\n\n# Add title \"Average MPG Over Time\"\ng.set_title('Average MPG Over Time')\n\n# Add x-axis and y-axis labels\ng.set(xlabel='Car Model Year',\n      ylabel='Average MPG')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nEl promedio de millas por gal贸n logrado est谩 aumentando con el tiempo para los tres lugares de origen, pero EE.UU.j siempre es m谩s bajo que Europa y Jap贸n.\n\n\n\nRotar etiquetas x-tick\nEn este ejercicio, seguiremos ecaminando el conjunto de datos de millas por gal贸n. En el c贸digo proporcionado, creamos un gr谩fico de puntos que muestra la aceleraci贸n media de los coches en cada uno de los tres lugares de origen. Observa que la variable \"acceleration\" es el tiempo de aceleraci贸n de 0 a 60 millas por hora, en segundos. Los valores m谩s altos indican una aceleraci贸n m谩s lenta.\nUtilicemos este gr谩fico para practicar la rotaci贸n de las etiquetas x-tick. Recuerda que la funci贸n para rotar las etiquetas x-tick es una funci贸n independiente de Matplotlib y no una funci贸n aplicada al propio objeto gr谩fico.\n\nInstrucciones\n\nGira 90 grados las etiquetas x-tick.\n\n\n# Create point plot\nsns.catplot(x='origin', y='acceleration',\n            data=mpg, kind='point',\n            linestyle='none', capsize=0.1)  # join=False deprecated\n\n# Rotate x-tick labels\nplt.xticks(rotation=90)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDado que los valores m谩s altos indican una aceleraci贸n m谩s lenta, parece que los coches de Jap贸n y Europa tienen una aceleraci贸n significativamente m谩s lenta en comparaci贸n con los de EE.UU.",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#unirlo-todo",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#unirlo-todo",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "Unirlo Todo",
    "text": "Unirlo Todo\n\nInicio Para importar Seaborn:\n\n\nimport seaborn as sns\n\nPara importar Matplotlib:\n\nimport matplotlib.pyplot as plt\n\nPara mostrar un gr谩fico:\n\nplt.show()\n\n\nGr谩ficos Relacionales\n\nMuestran la relaci贸n entre dos variables cuantitativas.\nEjemplos: scatter plots, line plots\n\n\n\nsns.relplot(x='x_variable_name',\n            y='y_variable_name',\n            data=pandas_df,\n            kind='scatter')\n\n\nGr谩ficos Categ贸ricos\n\nDescriben la distribuci贸n de una variable cuantitativa dentro de categor铆as definida por una variable categ贸rica\nEjemplos: bar plots, count plots, box plots, pint plots\n\n\n\nsns.catplot(x='x_variable_name',\n            y='y_variable_name',\n            data=pandas_df,\n            kind='bar')\n\n\nA帽adiendo una tercer variable (hue)\n\nConfigurar hue creatra subgrupos que son desplegados como diferentes colores en un solo gr谩fico\n\n\nA帽adiendo una tercer variable (row/col)\n\nConfigurar row y/o col en relplot() o catplot() crear谩 subgrupos que son desplegados en subgr谩ficos separados.\n\n\nPersonalizaci贸n\n\nCambiar el fondo: sns.set_style()\nCambiar los colores de los elementos principales: sns.set_palette()\nCambiar la escala: sns.set_context()\nA帽adir un t铆tulo\n\n\n\n\n\n\n\n\nTipo de Objeto\nTipo de gr谩fico\nC贸mo a帽adir un t铆tulo\n\n\n\n\nFacetGrid\nrelplot(), catplot()\ng.fig.suptitle()\n\n\nAxesSubplot\nscatterplot(), countplot(), etc.\ng.set_title()\n\n\n\n\nToques finales\n\nA帽adir etiquetas al eje x y eje y\n\n\n\ng.set(xlabel='new x-axis label',\n      ylabel='new y-axis label')\n\nRotar etiquetas el eje x\n\nplt.xticks(rotation=90)\n\n\nDiagrama de cajas con subgrupos\nEn este ejercicio, examinaremos el conjunto de datos que contiene las respuestas de una encuesta realizada a j贸venes. Una de las preguntas que se hicieron a los j贸venes fue: 驴Te interesa tener mascotas? Exploraremos si la distribuci贸n de edades de los que responden si tiende a ser mayor o menor que la de los que responden no, distinguiendo seg煤n el g茅nero.\n\nsurvey_data['Interested in Pets'] = survey_data['Pets'].apply(\n    lambda x: 'Yes' if x &gt;= 4.0 else 'No')\n\n\nInstrucciones\n\nConfigura la paleta de colores en \"Blues\".\nA帽ade subgrupos para colorear los gr谩ficos de caja en funci贸n de \"Interested in Pets\".\nEstablece el t铆tulo del objeto FacetGrid g en `Age of Those Interested in Pets vs.Not.\nRealiza la visualizaci贸n del gr谩fico utlizando una funci贸n Matplotlib.\n\n\n# Set palette to \"Blues\"\nsns.set_palette('Blues')\n\n# Adjust to add subgroups based on \"Interested in Pets\"\ng = sns.catplot(x='Gender', y='Age',\n                data=survey_data,\n                kind='box', hue='Interested in Pets')\n\n# Set title to \"Age of Those Interested in Pets vs. Not\"\ng.fig.suptitle('Age of Those Interested in Pets vs. Not')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDespu茅s de controlar por g茅nero, parece que las distribuciones de edad de las personas est谩n interesadsas en las mascotas son similares a las de las que no lo est谩n\n\n\n\nDiagrama de barras con subgrupos y subtramas\nEn este ejercicio, volveremos a nuestro conjunto de datos de la encuesta a j贸venes e investigaremos si la proporci贸n de personas a las que les gusta la m煤sica tecno (\"Likes Techno\") var铆a seg煤n su g茅nero. (\"Gender\") o su lugar de residencia (\"Village - town\"). 隆Este ejercicio nos dar谩 la oportunidad de practicar las muchas cosas que hemos aprendido a lo largo de este curso!\nAntes hay que transformar la columna Techno por Likes Techno\n\nsurvey_data['Likes Techno'] = survey_data['Techno'].apply(lambda x: True if x &gt;= 4.0 else False)\n\n\nInstrucciones\n\nEstablece el estilo de la figura en \"dark\".\nAjusta el c贸digo del diagrama de barras para a帽adir subtramas basadas en \"Gender\", dispuestas en columnas.\nA帽ade el t铆tulo \"Percentage of Young People Who Like Techno\" a esta trama FacetGrid.\nEtiqueta el eje x \"Location of Residence\" y el eje y \"% Who Like Techno\"\n\n\nplt.style.use('seaborn-v0_8')\n\n# Set the figure style to \"dark\"\nsns.set_style('dark')\n\n# Adjust to add subplots per gender\ng = sns.catplot(x='Village - town', y='Likes Techno',\n                data=survey_data, kind='bar',\n                col='Gender')\n\n# Add title and axix labels\ng.fig.suptitle('Percentage of Young People Who Like Techno',\n                y=1.02)\ng.set(xlabel='Location of Residence',\n      ylabel='% Who Like Techno')\n\n# Show plot\nplt.show()",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#bien-hecho-y-ahora-qu茅",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#bien-hecho-y-ahora-qu茅",
    "title": "Personalizar los gr谩ficos de Seaborn",
    "section": "隆Bien hecho! 驴Y ahora qu茅?",
    "text": "隆Bien hecho! 驴Y ahora qu茅?\n\nExplorar y comunicar los resultados\n\n\n\nSeguientes pasos:\n\nVisualizaciones avanzadas con Seaborn\nMatplotlib avanzado personalizado",
    "crumbs": [
      "Introducci贸n a la Visualizaci贸n de Datos con Seaborn",
      "<span class='chapter-number'>16</span> <span class='chapter-title'>Personalizar los gr谩ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html",
    "href": "07_Analisis_exploratorio_de_datos/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\nEste curso interactivo cubre el proceso de exploraci贸n y an谩lisis de datos en Python, desde entender un nuevo dataset hasta la limpieza e imputaci贸n de valores.\n Nivel: Intermedio\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nAs铆 que tienes algunos datos interesantes, 驴por d贸nde empiezas tu an谩lisis? Este curso cubrir谩 el proceso de exploraci贸n y an谩lisis de datos, desde la comprensi贸n de lo que se incluye en un conjunto de datos hasta la incorporaci贸n de los resultados de la exploraci贸n a un flujo de trabajo de ciencia de datos.\nUtilizando datos sobre cifras de desempleo y precios de billetes de avi贸n, aprovechar谩s Python para resumir y validar datos, calcular, identificar y reemplazar valores perdidos, y limpiar valores num茅ricos y categ贸ricos. A lo largo del curso, crear谩s hermosas visualizaciones Seaborn para comprender las variables y sus relaciones.\nPor ejemplo, examinar谩s c贸mo se relacionan el consumo de alcohol y el rendimiento de los alumnos. Por 煤ltimo, el curso mostrar谩 c贸mo los hallazgos exploratorios alimentan los flujos de trabajo de la ciencia de datos creando nuevas caracter铆sticas, equilibrando caracter铆sticas categ贸ricas y generando hip贸tesis a partir de los hallazgos.\nAl final de este curso, tendr谩s la confianza necesaria para realizar tu propio an谩lisis exploratorio de datos (EDA) en Python. 隆Ser谩s capaz de explicar tus conclusiones visualmente a los dem谩s y sugerir los siguientes pasos para recopilar informaci贸n a partir de tus datos!",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html#m贸dulos-del-curso",
    "href": "07_Analisis_exploratorio_de_datos/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nConocer un conjunto de datos\nLimpieza e imputaci贸n de datos\nRelaciones en los datos\nConvertir el an谩lisis exploratorio en acci贸n",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html#datasets",
    "href": "07_Analisis_exploratorio_de_datos/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\nunemployment.csv\ndata_science_salaries.csv\nbooks.csv\ndivorce.csv\nplanes.csv",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html",
    "title": "Conocer un conjunto de datos",
    "section": "",
    "text": "Exploraci贸n inicial\n驴Cu谩l el la mejor manera de abordar un nuevo conjunto de datos? Aprende a validar y resumir datos categ贸ricos y num茅ricos y a crear visualizaciones Seaborn para comunicar tus conclusiones.\nbooks = pd.read_csv('books.csv')\nbooks.head()\nbooks.info()\nbooks.value_counts('genre')\nbooks.describe()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.histplot(data=books, x='rating')\nplt.show()\nsns.histplot(data=books, x='rating', binwidth=.1)\nplt.show()",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>17</span> <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#exploraci贸n-inicial",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#exploraci贸n-inicial",
    "title": "Conocer un conjunto de datos",
    "section": "",
    "text": "An谩lisis Exploratorio de Datos\n\nEs el proceso de limpiar y revisar datos para:\n\nObterner informaci贸n (Estad铆stica descriptiva, correlaciones)\nGenrar hip贸tesis\n\n\nUna primera mirada con .head()\n\n\n\n\nReuniendo m谩s .info()\n\n\n\n\nUna mirada cercana a las columnas categ贸ricas\n\n\n\n\nColumnas num茅ricas con .describe()\n\n\n\n\nVisualizando datos num茅ricos\n\n\n\n\nAjustando la anchura del bin\n\n\n\n\nFunciones para la exploraci贸n inicial\nEst谩s investigando las tasas de desempleo en todo el mundo y te han dado un nuevo conjunto de datos con el que trabajar. Los datos se han guardado y cargado para ti como un DataFrame de pandas llamado unemployment. Nunca antes hab铆as visto los datos, as铆 que tu primera tarea es utilizar unas cuantas funciones de pandas para conocer estos nuevos datos.\n\nimport pandas as pd\n\nruta = './data/clean_unemployment.csv'\nunemployment = pd.read_csv(ruta)\n\n\nInstrucciones\n\nUtiliza una funci贸n de pandas para imprimir las cinco primeras filas del DataFrame unemployment.\n\n\n# Print the first five rows of unemployment\nprint(unemployment.head())\n\n  country_code          country_name      continent   2010   2011   2012  \\\n0          AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1          AGO                Angola         Africa   9.43   7.36   7.35   \n2          ALB               Albania         Europe  14.09  13.48  13.38   \n3          ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4          ARG             Argentina  South America   7.71   7.18   7.22   \n\n    2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0  11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1   7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2  15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3   2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4   7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n\n\n\nUtiliza una funci贸n pandas para imprimir un resumen de los valores y tipos de datos de las columnas que no faltan del DataFrame unemployment.\n\n\n# Print a summary of non-missing values and data types in the unemployment DataFrame]\nprint(unemployment.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 182 entries, 0 to 181\nData columns (total 15 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   country_code  182 non-null    object \n 1   country_name  182 non-null    object \n 2   continent     177 non-null    object \n 3   2010          182 non-null    float64\n 4   2011          182 non-null    float64\n 5   2012          182 non-null    float64\n 6   2013          182 non-null    float64\n 7   2014          182 non-null    float64\n 8   2015          182 non-null    float64\n 9   2016          182 non-null    float64\n 10  2017          182 non-null    float64\n 11  2018          182 non-null    float64\n 12  2019          182 non-null    float64\n 13  2020          182 non-null    float64\n 14  2021          182 non-null    float64\ndtypes: float64(12), object(3)\nmemory usage: 21.5+ KB\nNone\n\n\n\nImprime las estad铆sticas de resument (recuento, media, desviaci贸n est谩ndar, valores m铆nimo, m谩ximo y cuartil) de cada columna num茅rica en unemployment.\n\n\n# Print summary statistics for numerical columns in unemployment\nprint(unemployment.describe())\n\n             2010        2011        2012        2013        2014        2015  \\\ncount  182.000000  182.000000  182.000000  182.000000  182.000000  182.000000   \nmean     8.409286    8.315440    8.317967    8.344780    8.179670    8.058901   \nstd      6.248887    6.266795    6.367270    6.416041    6.284241    6.161170   \nmin      0.450000    0.320000    0.480000    0.250000    0.200000    0.170000   \n25%      4.015000    3.775000    3.742500    3.692500    3.625000    3.662500   \n50%      6.965000    6.805000    6.690000    6.395000    6.450000    6.170000   \n75%     10.957500   11.045000   11.285000   11.310000   10.695000   10.215000   \nmax     32.020000   31.380000   31.020000   29.000000   28.030000   27.690000   \n\n             2016        2017        2018        2019        2020        2021  \ncount  182.000000  182.000000  182.000000  182.000000  182.000000  182.000000  \nmean     7.925879    7.668626    7.426429    7.243736    8.420934    8.390879  \nstd      6.045439    5.902152    5.818915    5.696573    6.040915    6.067192  \nmin      0.150000    0.140000    0.110000    0.100000    0.210000    0.260000  \n25%      3.800000    3.690000    3.625000    3.487500    4.285000    4.335000  \n50%      5.925000    5.650000    5.375000    5.240000    6.695000    6.425000  \n75%     10.245000   10.315000    9.257500    9.445000   11.155000   10.840000  \nmax     26.540000   27.040000   26.910000   28.470000   29.220000   33.560000  \n\n\nAhora haz aprendido que unemployment contiene 182 filas de datos de pa铆ses, incluyendo country_code, country_name, continent y porcentajes de desempleo desde 2010 hasta 2021. 隆Si miraste muy de cerca, podr铆as haber notado que a algunos pa铆ses les falta informaci贸n en la columna continent! Continuemos explorando estos datos en el pr贸ximo ejercicio.\n\n\n\nContar valores categ贸ricos\nRecordemos del ejercicio anterior que el DataFrame unemployment contiene 182 filas de datos de pa铆ses que incluyen country_code, country_name, continent y porcentajes de desempleo de 2010 a 2021.\nAhora vas a explorar los datos categ贸ricos contenidos en unemployment para comprender los datos que contiene relacionados con cada continente.\n\nInstrucciones\n\nUtiliza un m茅todo para contar los valores asociados a cada continent en el DataFrame unemployment.\n\n\n# Count the values associated with each continent in unemployment\nprint(unemployment['continent'].value_counts())\n\ncontinent\nAfrica           53\nAsia             47\nEurope           39\nNorth America    18\nSouth America    12\nOceania           8\nName: count, dtype: int64\n\n\n驴Sab铆as que hay 23 pa铆ses en Am茅rica del Norte, que incluye pa铆ses en el Caribe y Am茅rica Central? Puede que hayas notado que Am茅rica del Norte tiene 18 puntos de datos en el DataFrame unemployment, por lo que nos falta informaci贸n de algunos de los pa铆ses en nuestro conjunto de datos.\n\n\n\nDesempleo mundial en 2021\n隆Es hora de explorar algunos de los datos num茅ricos en unemployment! 驴Cu谩l fue el desempleo t铆pico en un a帽o determinado? 驴Cu谩l era la tasa de desempleo m铆nima y m谩xima, y c贸mo era la distribuci贸n de las tasas de desempleo en el mundo? Un histogrpama es una buena forma de hacerse una idea de las respuestas a estas preguntas.\nTu tarea en este ejercicio es crear un histograma que muestre la distribuci贸n de las tasas de paro mundiales en 2021.\n\nInstrucciones\n\nImporta las bibliotecas de visualizaci贸n necesarias\nCrea un histograma de la distribuci贸n de los porcentajes de desempleo de 2021 en todos los pa铆ses en unemployment; muestra un punto pocentual completo en cada casilla.\n\n\n# Import the required visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a histogram of 2021 unemployment; show a full percent in each bin\nsns.histplot(x='2021', data=unemployment, binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\nParece que el desempleo en el 2021 se mantuvo alrededor del 3% al 8% para la mayor铆a de los pa铆ses en el conjunto de datos, pero algunos pa铆ses experimentaron un desempleo muy alto del 20% al 35%.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>17</span> <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#validaci贸n-de-datos",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#validaci贸n-de-datos",
    "title": "Conocer un conjunto de datos",
    "section": "Validaci贸n de datos",
    "text": "Validaci贸n de datos\n\nValidando los tipos de datos\n\n\nbooks.dtypes\n\n\n\nActualizando los tipos de datos\n\n\nbooks['year'] = books['year'].astype(int)\nbooks.dtypes\n\n\n\n\n\nTipo\nNombre Python\n\n\n\n\nString\nstr\n\n\nInteger\nint\n\n\nFloat\nfloat\n\n\nDictionary\ndict\n\n\nList\nlist\n\n\nBoolean\nbool\n\n\n\n\nValidando datos categ贸ricos\n\n\nbooks['genre'].isin(['Fiction', 'Non Fiction'])\n\n\nPara validar los datos que no est谩n en la lista\n\n~books['genre'].isin(['Fiction', 'Non Fiction'])\n\n\nPara filtrar el DataFrame por los valores en nuestra lista\n\nbooks[books['genre'].isin(['Fiction', 'Non Fiction'])].head()\n\n\n\nValidando los datos num茅ricos\n\nPara ver solo las columnas num茅ricas en un DataFrame:\n\nbooks.select_dtypes('number').head()\n\nPara conocer un intervalo espec铆fico:\n\nbooks['year'].min()\n\n\n\nbooks['year'].max()\n\n\nSe puede ver una imagen m谩s detallada de la distribuci贸n de los datos, utilizando boxplot:\n\nsns.boxplot(data=books, x='year')\nplt.show()\n\n\nTambi茅n se puede ver los datos agrupados por una variable categ贸rica.\n\nsns.boxplot(data=books, x='year', y='genre')\nplt.show()\n\n\n\nDetectar tipos de datos\n隆Se ha modificado una columna en el DataFrame unemployment y ahora tiene un tipo de datos incorrecto! Este tipo de datos te impedir谩 realizar una exploraci贸n y un an谩lisis eficaces, por lo que tu tarea consiste en identificar qu茅 columna tiene un tipo de datos incorrecto y, a continuaci贸n, corregirlo.\n\nInstrucciones\nPregunta\n\n驴Cu谩l de las siguientes columnas requiere una actualizaci贸n de su tipo de datos?\n\n\nprint(unemployment.dtypes)\n\ncountry_code     object\ncountry_name     object\ncontinent        object\n2010            float64\n2011            float64\n2012            float64\n2013            float64\n2014            float64\n2015            float64\n2016            float64\n2017            float64\n2018            float64\n2019             object\n2020            float64\n2021            float64\ndtype: object\n\n\nRespuestas posibles\n\ncountry_name\ncontinent\n2019\n2021\n\n\n\n\n\nActualiza el tipo de datos de la columna 2019 de unemployment a float.\n隆Vuelve a imprimir el dtypes del DataFrame umemployment para comprobar que se ha actualizado el tipo de datos!\n\n\n# Update the data type of the 2019 column to a float\nunemployment['2019'] = unemployment['2019'].astype('float')\n\n# Print the dtypes to check your work\nprint(unemployment.dtypes)\n\ncountry_code     object\ncountry_name     object\ncontinent        object\n2010            float64\n2011            float64\n2012            float64\n2013            float64\n2014            float64\n2015            float64\n2016            float64\n2017            float64\n2018            float64\n2019            float64\n2020            float64\n2021            float64\ndtype: object\n\n\nCambiar el tipo de dato de la columna 2019 significa que ahora puedes realizar c谩lculos sobre ella, incluyendo validar su rango.\n\n\n\nValidar continentes\nTu colega te ha informado de que los datos sobre el desempleo de los pa铆ses de Ocean铆a no son fiables, y te gustar铆a identificar y excluir a estos pa铆ses de tus datos de unemployment. 隆La funci贸n .isin() puede ayudarte con eso!\nTu tarea consiste en utilizar isin() para identificar los pa铆ses que no est谩n en Ocean铆a. Estos pa铆ses deber铆an devolver True mientras que los pa铆ses de Ocean铆a deber谩n devolver False. Esto te permitir谩 utilizar los resultados de isin() para filtrar r谩pidamente los pa铆ses de Ocean铆a utilizando la indexaci贸n booleana.\n\n\nInstrucciones\n\nDefina una Serie Booleana que describan si cada continent est谩 o no fuera de Ocean铆a; llama a esta Serie not_oceania.\n\n\n# Define a Series describing whether each continent is outside of Oceania\nnot_oceania = ~unemployment['continent'].isin(['Oceania'])\n\n\nUtiliza la indexaci贸n booleana para imprimir el DataFrame unemployment sin ninguno de los datos relacionados con los pa铆ses de Ocean铆a.\n\n\n# Define a Series describing whether each continent is outside of Oceania\nnot_oceania = ~unemployment['continent'].isin(['Oceania'])\n\n# Print unemployment without records related  to countries in Oceania\nprint(unemployment[not_oceania])\n\n    country_code          country_name      continent   2010   2011   2012  \\\n0            AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1            AGO                Angola         Africa   9.43   7.36   7.35   \n2            ALB               Albania         Europe  14.09  13.48  13.38   \n3            ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4            ARG             Argentina  South America   7.71   7.18   7.22   \n..           ...                   ...            ...    ...    ...    ...   \n175          VNM               Vietnam           Asia   1.11   1.00   1.03   \n178          YEM           Yemen, Rep.           Asia  12.83  13.23  13.17   \n179          ZAF          South Africa         Africa  24.68  24.64  24.73   \n180          ZMB                Zambia         Africa  13.19  10.55   7.85   \n181          ZWE              Zimbabwe         Africa   5.21   5.37   5.15   \n\n      2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0    11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1     7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2    15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3     2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4     7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n175   1.32   1.26   1.85   1.85   1.87   1.16   2.04   2.39   2.17  \n178  13.27  13.47  13.77  13.43  13.30  13.15  13.06  13.39  13.57  \n179  24.56  24.89  25.15  26.54  27.04  26.91  28.47  29.22  33.56  \n180   8.61   9.36  10.13  10.87  11.63  12.01  12.52  12.85  13.03  \n181   4.98   4.77   4.78   4.79   4.78   4.80   4.83   5.35   5.17  \n\n[174 rows x 15 columns]\n\n\nValidaste datos categ贸ricos y usaste tu validaci贸n .isin() para excluir datos en los que no estabas interesado. Filtrar los datos que no necesitas al comienzo de tu proceso de EDA es una excelente manera de organizarte para la exploraci贸n que est谩 por venir.\n\n\nRango de validaci贸n\nAhora es el momento de validar nuestros datos num茅ricos. En la lecci贸n anterior vimos, utilizando .describe(), que la mayor tasa de desempleo durante 2021 fue de casi el 34 %, mientras que la m谩s baja estuvo justo por encima de cero.\nTu tarea en este ejercicio es obtener informaci贸n mucho m谩s detallada sobre el rango de los datos de unemployment utilizando el diagrama de caja de Seaborn, y tambi茅n visualizar谩s el rango de las tasas de desempleo en cada continente para comprender las diferencias de rango geogr谩fico.\n\nInstrucciones\n\nImprime las tasas de desempleo m铆nima y m谩ximam en este orden, durante 2021.\nCrea un diagrama de caja de las tasas de desempleo de 2021 (en el eje x), desglosadas por continente (en el eje y).\n\n\n# Print the minimum an maximum unemployment rates during 2021\nprint(unemployment['2021'].min(), unemployment['2021'].max())\n\n# Create a boxplot of 2021 unemployment rates, broken down by continent\nsns.boxplot(data=unemployment, x='2021', y='continent', \n            hue='continent', legend=False)\nplt.show()\n\n0.26 33.56\n\n\n\n\n\n\n\n\n\nObserva c贸mo var铆an los rangos de desempleo entre continentes. Por ejemplo, el percentil 50 de frica es m谩s bajo que el de Am茅rica del Norte, pero el rango es mucho m谩s amplio.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>17</span> <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#resumen-de-datos",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#resumen-de-datos",
    "title": "Conocer un conjunto de datos",
    "section": "Resumen de datos",
    "text": "Resumen de datos\n\nExplorando grupo de datos\n\n.groupby() grupo de datos por categor铆a.\nFunci贸n de agregaci贸n indica c贸mo se resume un grupo de datos.\n\n\n\nbooks.groupby('genre').mean()\n\n\n\nFunciones de agregaci贸n\n\nSuma: .sum()\nConteo: .cont\nM铆nimo: .min()\nM谩ximo: .max()\nVarianza: .var()\nDesviaci贸n est谩ndar: .std()\n\nAgregaci贸n de datos no agrupados\n\n.agg() aplica funciones de agregaci贸n a trav茅s de un DataFrame\nPor defecto agrega todas las filas de una columna determinada\nSe suele utilizar cuando queremos m谩s de una funci贸n\nSolo lo aplica a las columnas num茅ricas\n\n\n\nbooks.agg(['mean', 'std'])\n\n\n\nEspecificando agregaciones para columnas\n\n\nbooks.agg({'rating': ['mean', 'std'], 'year': ['median']})\n\n\n\nNombrando columnas resumen\n\n\nbooks.groupby('genre').agg(\n    mean_rating = ('rating', 'mean'),\n    std_rating = ('rating', 'std'),\n    median_year = ('year', 'median')\n)\n\n\n\nVisualizando res煤menes categoricos\n\nCalculan autom谩ticamente la media de una variable cuantitativa\n\n\n\nsns.barplot(data=books, x='genre', y='rating')\nplt.show()\n\n\n\nRes煤menes con .groupby() y .agg()\nEn este ejercicio, explorar谩s las medias y desviaciones est谩ndar de los datos anuales de desempleo. En primer lugar, encontrar谩s las medias y desviaciones est谩ndar independientemente del continente para observar las tendencias mundiales del desempleo. Despu茅s, comprobar谩s las tendencias del desempleo desglosadas por continente.\n\nimport pandas as pd\n\nruta = './data/clean_unemployment.csv'\nunemployment = pd.read_csv(ruta)\nprint(unemployment.head())\n\n  country_code          country_name      continent   2010   2011   2012  \\\n0          AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1          AGO                Angola         Africa   9.43   7.36   7.35   \n2          ALB               Albania         Europe  14.09  13.48  13.38   \n3          ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4          ARG             Argentina  South America   7.71   7.18   7.22   \n\n    2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0  11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1   7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2  15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3   2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4   7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n\n\n\nInstrucciones\n\nImprime la media y las desviaci贸n est谩ndar d elas tasas de paro de cada a帽o (en ese orden).\n\n\n# Print the mean and standard deviation of rates by year\nprint(unemployment[\n    ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n].agg(['mean', 'std']))\n\n          2010      2011      2012      2013      2014      2015      2016  \\\nmean  8.409286  8.315440  8.317967  8.344780  8.179670  8.058901  7.925879   \nstd   6.248887  6.266795  6.367270  6.416041  6.284241  6.161170  6.045439   \n\n          2017      2018      2019      2020  \nmean  7.668626  7.426429  7.243736  8.420934  \nstd   5.902152  5.818915  5.696573  6.040915  \n\n\n\nImprime la media y la desviaci贸n est谩ndar (en ese orden) de las tasas de paro de cada a帽o agrupadas por continente.\n\n\n# Print yearly mean and standard deviation grouped by continent\nprint(unemployment[\n    ['continent', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n].groupby(\"continent\").agg(['mean', 'std']))\n\n                    2010                 2011                 2012            \\\n                    mean       std       mean       std       mean       std   \ncontinent                                                                      \nAfrica          9.343585  7.411259   9.369245  7.401556   9.240755  7.264542   \nAsia            6.240638  5.146175   5.942128  4.779575   5.835319  4.756904   \nEurope         11.008205  6.392063  10.947949  6.539538  11.325641  7.003527   \nNorth America   8.663333  5.115805   8.563333  5.377041   8.448889  5.495819   \nOceania         3.622500  2.054721   3.647500  2.008466   4.103750  2.723118   \nSouth America   6.870833  2.807058   6.518333  2.801577   6.410833  2.936508   \n\n                    2013                 2014            ...      2016  \\\n                    mean       std       mean       std  ...      mean   \ncontinent                                                ...             \nAfrica          9.132453  7.309285   9.121321  7.291359  ...  9.277547   \nAsia            5.852128  4.668405   5.853191  4.681301  ...  6.094894   \nEurope         11.466667  6.969209  10.971282  6.759765  ...  9.394615   \nNorth America   8.840556  6.081829   8.512222  5.801927  ...  7.941111   \nOceania         3.980000  2.640119   3.976250  2.659205  ...  3.877500   \nSouth America   6.335000  2.808780   6.347500  2.834332  ...  7.230833   \n\n                             2017                2018                2019  \\\n                    std      mean       std      mean       std      mean   \ncontinent                                                                   \nAfrica         7.459439  9.284528  7.407620  9.237925  7.358425  9.264340   \nAsia           5.051796  6.171277  5.277201  6.090213  5.409128  5.949149   \nEurope         5.822793  8.359744  5.177845  7.427436  4.738206  6.764359   \nNorth America  5.503090  7.391111  5.326446  7.281111  5.253180  7.095000   \nOceania        2.477866  3.872500  2.492834  3.851250  2.455893  3.773750   \nSouth America  3.052309  7.281667  3.398994  7.496667  3.408856  7.719167   \n\n                              2020            \n                    std       mean       std  \ncontinent                                     \nAfrica         7.455293  10.307736  7.928166  \nAsia           5.254008   7.012340  5.699609  \nEurope         4.124734   7.470513  4.071218  \nNorth America  4.770490   9.297778  4.963045  \nOceania        2.369068   4.273750  2.617490  \nSouth America  3.379845  10.275000  3.411263  \n\n[6 rows x 22 columns]\n\n\nEstos datos est谩n bien resumidos, pero es un poco largo. 驴Qu茅 pasar铆asi quisieras enfocarte en un resumen de solo un a帽o y hacerlo m谩s legible? 隆Int茅ntalo en el siguiente ejercicio!\n\n\n\nAgregaciones con nombre\nYa has visto c贸mo .groupby() y .agg() pueden combinarse para mostrar res煤menes para categor铆as. A veces, es 煤til nombrar nuevas columnas al agregar, para que se quede claro en la salida del c贸digo qu茅 agregaciones se est谩n aplicando y d贸nde.\nTu tarea consiste en crear un DataFrame llamado continent_summary que muestre una fila por cada continente. Las columnas del DataFram,e contendr谩n la tasa de paro media de cada continente en 2021, as铆 como la desviaci贸n est谩ndar de la tasa de empleo del 2021. Y por supuesto, 隆renombrar谩s las columnas para que su contenido quede claro!\n\nInstrucciones\n\nCrea una columna llamada mean_rate_2021 que muestre la tasa de paro media de 2021 para cada continente.\nCrea una columna llamada std_rate_2021 que muestre la desviaci贸n est谩ndar de la tasa de paro de 2021 para cada continente.\n\n\ncontinent_sumary = unemployment[\n    ['continent', '2021']\n].groupby('continent').agg(\n    # Create the mean_rate_2021 column\n    mean_rate_2021 = ('2021', 'mean'),\n    # Create the std_rate_2021 column\n    std_rate_2021 = ('2021', 'std'),\n)\nprint(continent_sumary)\n\n               mean_rate_2021  std_rate_2021\ncontinent                                   \nAfrica              10.473585       8.131636\nAsia                 6.906170       5.414745\nEurope               7.414872       3.947825\nNorth America        9.155000       5.076482\nOceania              4.280000       2.671522\nSouth America        9.924167       3.611624\n\n\nEl desempleo promedio de 2021 vari贸 ampliamente por continente, y tambi茅n lo hizo el desempleo dentro de esos continentes.\n\n\n\nVisualizar res煤menes categ贸ricos\nComo has aprendido en este cap铆tulo, Seaborn tiene muchas visualizaciones estupendas para la exploraci贸n, incluido un gr谩fico de barras para mostrar un valor medio agregado por categor铆a de datos.\nEn Seaborn, los gr谩ficos de barras incluyen una barra vertical que indica el intervalo de confianza del 95 % para la media categ贸rica. Como los intervalos de confianza se calculan utilizando tanto el n煤mero de valores como la variabilidad de esos valores, dan una indicaci贸n 煤til de hasta qu茅 punto se puede confiar en los datos.\nTu tarea consiste en crear un diagrama de barras para visualizar las medias y los intervalos de confianza de las tasas de desempleo en los distintos continentes.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nInstrucciones\n\nCrea un diagrama de barras que muestre los continentes en el eje x y lsus respectivas tasas medias de desempleo en 2021 en el eje y.\n\n\n# Create a bar plot of continents and their average unemployment\nsns.barplot(data=unemployment, x='continent', y='2021',\n            hue='continent', legend=False)\nplt.show()\n\n\n\n\n\n\n\n\nAunque Europa tiene un mayor desempleo promedio que Asia, tambi茅n tiene un intervalo de confianza m谩s peque帽o para ese promedio, por lo que el valor promedio es m谩s confiable.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>17</span> <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html",
    "title": "Limpieza e imputaci贸n de datos",
    "section": "",
    "text": "Tratar los datos que faltan\nExplorar y analizar datos a menudo significa tratar con valores perdidos, tipos de datos incorrectos y valores at铆picos. En este cap铆tulo, aprender谩s t茅cnicas para gestionar estos problemas y agilizar tus procesos en EDA.\nprint(salaries.isna().sum())\nthreshold = len(salaries) * 0.05\nprint(threhold)\ncols_to_drop = salaries.columns[salaries.isna().sum() &lt;= threshold]\nprint(cols_to_drop)\nsalaries.dropna(subset=cols_to_drop, inplace=True) # Para actualizar el DataFrame\ncols_with_missing_values = salaries.columns[salaries.isna().sum() &gt; 0]\nprint(cols_with_missing_values)\nfor col in cols_with_missing_values[:-1]:\n        salaries[col].fillna(salaries[col].mode()[0])\nprint(salaries.isna().sum())\nsalaries_dict = salaries.groupby('Experience')['Salary_USD'].median().to_dict()\nprint(salaries_dict)\nsalaries['Salary_USD'] = salaries['Salary_USD'].fillna(salaries['Experience'].map(salaries_dict))",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>18</span> <span class='chapter-title'>Limpieza e imputaci贸n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#tratar-los-datos-que-faltan",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#tratar-los-datos-que-faltan",
    "title": "Limpieza e imputaci贸n de datos",
    "section": "",
    "text": "Por qu茅 un dato faltante es un problema?\n\nAfectan las distribuciones\nLos datos de la poblaci贸n son menos repreesntativos\nPuede resultar en conclusiones incorrectas\n\nEjemplo datos de profesionales de datos\n\n\n\n\n\n\n\n\n\nColumn\nDescription\nData type\n\n\n\n\nWorking_Year\nYear the data was obtained\nFloat\n\n\nDesignation\nJob title\nString\n\n\nExperience\nExperience level e.g., \"Mid\", \"Senior\"\nString\n\n\nEmployment_Satus\nType of employment contract e.g., \"FT\", \"PT\"\nString\n\n\nEmployee_Location\nCountry of employment\nString\n\n\nCompany_Size\nLabels for company size e.g., \"S\", \"M\", \"L\"\nString\n\n\nRemote_Working_Ratio\nPorcentage of time working remotely\nInteger\n\n\nSalary_USD\nSalary in US dollars\nFloat\n\n\n\n\nRevisando los datos faltantes\n\n\n\n\nEstrategias para el manejo de datos faltantes\n\nEliminar los datos faltantes\n\n5 % o menos del total de valores\n\nImputar la media, mediana o la moda\n\nDepende de la distribuci贸n y contexto\n\nImputar por sub-grupos\n\nDiferentes niveles de experiencia tienen diferente mediana en el salario\n\n\nEliminando valores faltantes\n\n\n\n\n\n\n\nImputando una estad铆stica de resumen\n\n\n\n\n\nRevisando los valores faltantes que faltan\n\n\n\n\nImputando por subgrupo\n\n\n\n\n\n\nTratar los datos que faltan\nEs importante tratar los datos que faltan antes de empezar el an谩lisis.\nUn enfoque consiste en descartar los valores que faltan si representan una peque帽a proporci贸n, normalmente el 5 %, de los datos.\nTrabajando con un conjunto de datos sobre precios de tiquetes de avi贸n, almacenado como un DataFrame de pandas llamado planes, tendr谩s que contar el n煤mero de valores perdidos en todas las columnas, calcular el cinco porciento de todos los valores, utilizar este umbral para eliminar observaciones y comprobar cu谩ntos valores perdidos quedan en el conjunto de datos.\n\nimport pandas as pd\n\nruta = './data/planes.csv'\nplanes = pd.read_csv(ruta)\nprint(planes.head)\n\n&lt;bound method NDFrame.head of            Airline Date_of_Journey    Source Destination  \\\n0      Jet Airways       9/06/2019     Delhi      Cochin   \n1           IndiGo      12/05/2019   Kolkata    Banglore   \n2           IndiGo      01/03/2019  Banglore   New Delhi   \n3         SpiceJet      24/06/2019   Kolkata    Banglore   \n4      Jet Airways      12/03/2019  Banglore   New Delhi   \n...            ...             ...       ...         ...   \n10655     Air Asia       9/04/2019   Kolkata    Banglore   \n10656    Air India      27/04/2019   Kolkata    Banglore   \n10657  Jet Airways      27/04/2019  Banglore       Delhi   \n10658      Vistara      01/03/2019  Banglore   New Delhi   \n10659    Air India       9/05/2019     Delhi      Cochin   \n\n                       Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n0      DEL  LKO  BOM  COK    09:25  04:25 10 Jun      19h     2 stops   \n1            CCU  NAG  BLR    18:05         23:30   5h 25m      1 stop   \n2            BLR  NAG  DEL    16:50         21:35   4h 45m      1 stop   \n3                  CCU  BLR    09:00         11:25   2h 25m    non-stop   \n4            BLR  BOM  DEL    18:55  10:25 13 Mar  15h 30m      1 stop   \n...                      ...      ...           ...      ...         ...   \n10655              CCU  BLR    19:55         22:25   2h 30m    non-stop   \n10656              CCU  BLR    20:45         23:20   2h 35m    non-stop   \n10657              BLR  DEL      NaN         11:20       3h    non-stop   \n10658              BLR  DEL    11:30         14:10   2h 40m    non-stop   \n10659  DEL  GOI  BOM  COK    10:55         19:15   8h 20m     2 stops   \n\n                   Additional_Info    Price  \n0                          No info  13882.0  \n1                          No info   6218.0  \n2                          No info  13302.0  \n3                          No info   3873.0  \n4      In-flight meal not included  11087.0  \n...                            ...      ...  \n10655                      No info   4107.0  \n10656                      No info   4145.0  \n10657                          NaN   7229.0  \n10658                      No info  12648.0  \n10659                      No info  11753.0  \n\n[10660 rows x 11 columns]&gt;\n\n\n\nInstrucciones\n\nImprime el n煤mero de valores perdidos en cada columna del DataFrame\n\n\n# Count the number of missing values in each column\nprint(planes.isna().sum())\n\nAirline            427\nDate_of_Journey    322\nSource             187\nDestination        347\nRoute              256\nDep_Time           260\nArrival_Time       194\nDuration           214\nTotal_Stops        212\nAdditional_Info    589\nPrice              616\ndtype: int64\n\n\n\nCalcula a cu谩ntas observaciones equivale el cinco porciento del DataFrame planes\n\n\n# Find the five percent threshold\nthreshold = len(planes) * 0.05\nprint(threshold)\n\n533.0\n\n\n\n\n\n\nCrea cols_to_drop aplicando una indexaci贸n booleana a las columnas del DataFrame con valores perdidos menores o iguales que el umbral.\nUtiliza este filtro para eliminar los valores que faltan y guardar el DataFrame actualizado.\n\n\n# Create a filter\ncols_to_drop = planes.columns[planes.isna().sum() &lt;= threshold]\nprint(cols_to_drop)\n\n# Drop missing values for columns below the threshold\nplanes.dropna(subset=cols_to_drop, inplace=True)\n\nprint(planes.isna().sum())\n\nIndex(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops'],\n      dtype='object')\nAirline              0\nDate_of_Journey      0\nSource               0\nDestination          0\nRoute                0\nDep_Time             0\nArrival_Time         0\nDuration             0\nTotal_Stops          0\nAdditional_Info    300\nPrice              368\ndtype: int64\n\n\nAl crear un umbral de valores faltantes y usarlo para filtrar columnas, haz logrado eliminar los valores faltantes de todas las columnas excepto \"Additinal_Info\" y \"Price\".\n\n\n\nEstrategias para datos que faltan\nLa regla del cinco porciento ha funcionado muy bien en tu conjunto de dato planes, 隆eliminando los valores perdidos de nueve de las 11 columnas!\nAhora tienes que decidir qu茅 hacer con las columnas \"Additional_Info\" y \"Price\", a las que les faltan los valores 300 y 368 respectivamente.\nPrimero echar谩s un vistazo a lo que contiene \"Additional_Info\", y despu茅s visualizar谩s el precio de los billetes de avi贸n de distintas compa帽铆as a茅reas.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nInstrucciones\n\nImprime los valores y frecuencias de \"Additional_Info\".\n\n\n# Check the values of the Additional_Info column\nprint(planes['Additional_Info'].value_counts())\n\nAdditional_Info\nNo info                         6399\nIn-flight meal not included     1525\nNo check-in baggage included     258\n1 Long layover                    14\nChange airports                    7\nNo Info                            2\nBusiness class                     1\nRed-eye flight                     1\n2 Long layover                     1\nName: count, dtype: int64\n\n\n\nCrea un boxplot de \"Price\" frente a \"Airline\"\n\n\n# Create a box plot of Price by Airline\nsns.boxplot(data=planes, x='Airline', y='Price',\n            hue='Airline', legend=False)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta\n\n\n驴C贸mo debes tratar los valores que faltan en \"Additional_Info\" y \"Price\".?\n\nRespuestas Posibles\n\nElimina la columna \"Additional_Info\" e imputa la media para los valores que faltan de \"Price\".\nElimina los valores de \"No info\" de \"Additiona_Info\" e imputa la mediana de los valores que faltan de \"Price\".\nElimina la columna \"Additional_Info\" e imputa la media por \"Airline\" para los valores que falten de \"Price\".\nElimina la columna \"Additional_Info\" e imputa la mediana por \"Airline\" para los valores que falten de \"Price\".\n\nNo necesitamos la columna \"Additional_Info\", y deber铆as imputar la mediana de \"Price\" por \"Airline\" para representar los datos con precisi贸n.\n\n\n\nImputar los precios de los aviones que faltan\n!Ahora solo queda una columna con valores perdidos!\nHas eliminado la columna \"Additional_Info\" de planes, el 煤ltimo paso es imputar los datos que faltan en la columna \"Price\" del conjunto de datos.\nComo recordatorio, t煤 generaste este diagrama de caja, que suger铆a que imputar el precio medio bas谩ndose en el \"Airline\" 隆es un enfoque s贸lido!\n\n# Eliminamos la columna Additional_Info\nplanes = planes.drop('Additional_Info', axis=1)\nplanes.columns\n\nIndex(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops', 'Price'],\n      dtype='object')\n\n\n\nInstrucciones\n\nAgrupa planes por aerol铆nea y calcula el precio medio.\n\n\n# Calculate median plane ticket prices by Airplane\nairline_prices = planes.groupby('Airline')['Price'].median()\n\nprint(airline_prices)\n\nAirline\nAir Asia              5192.0\nAir India             9443.0\nGoAir                 5003.5\nIndiGo                5054.0\nJet Airways          11507.0\nMultiple carriers    10197.0\nSpiceJet              3873.0\nVistara               8028.0\nName: Price, dtype: float64\n\n\n\nConvierte los precios medios agrupados en un diccionario.\n\n\n# Convert to a dictionary\nprices_dict = airline_prices.to_dict()\nprint(prices_dict)\n\n{'Air Asia': 5192.0, 'Air India': 9443.0, 'GoAir': 5003.5, 'IndiGo': 5054.0, 'Jet Airways': 11507.0, 'Multiple carriers': 10197.0, 'SpiceJet': 3873.0, 'Vistara': 8028.0}\n\n\n\n\n\n\nImputa condicionalmente los valores perdidos de \"Price\" asignando los valores de la columna \"Airline\" en funci贸n de prices_dict\nComprueba si faltan valores\n\n\n# Map the dictionary to missing values of Price by Airline\nplanes['Price'] = planes['Price'].fillna(planes['Airline'].map(prices_dict))\n\n# Check for missing values\nprint(planes.isna().sum())\n\nAirline            0\nDate_of_Journey    0\nSource             0\nDestination        0\nRoute              0\nDep_Time           0\nArrival_Time       0\nDuration           0\nTotal_Stops        0\nPrice              0\ndtype: int64\n\n\nConvertiste un DataFrame agrupado a un diccionario y luego lo usaste para llenar condicionalmente los valores faltantes de \"Price\" bas谩ndote en \"Airline\". Ahora vamos a explorar c贸mo realizar an谩lisis exploratorio en datos categ贸ricos.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>18</span> <span class='chapter-title'>Limpieza e imputaci贸n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#convertir-y-analizar-datos-categ贸ricos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#convertir-y-analizar-datos-categ贸ricos",
    "title": "Limpieza e imputaci贸n de datos",
    "section": "Convertir y analizar datos categ贸ricos",
    "text": "Convertir y analizar datos categ贸ricos\n\nPrevisualizar los datos\n\n\nprint(salaries.select_dtypes('object').head())\n\n\n\nT铆tulos de los trabajos\n\n\nprint(salaries['Designation'].value_counts())\n\n\n\nprint(salaries['Designation'].nunique())\n\n\n\n\nExtrayendo valores desde las categor铆as\n\nEl formato actual de los datos limita la capacidad de generar informaci贸n.\npandas.Series.str.contains()\n\nBusca en una columna una cadena especifica o m煤ltiples cadenas.\n\n\n\n\nsalaries['Designation'].str.contains('Scientist')\n\n\n\nFiltrar filas que contienen una o m谩s frases\n\nPalabras de interes: Machine Learning o AI\n\n\n\nsalaries['Designation'].str.contains('Machine Learning|AI')\n\n\n\nBuscar m煤ltiples frases en una cadena de caracteres\n\nPalabras de interes: Cualquiera que inicie con Data\n\n\n\nsalaries['Designation'].str.contains('Data')\n\n\nAhora que se tiene una idea de c贸mo funciona este m茅todo, definamos una lista de t铆tulos de trabajo que queremos encontrar:\n\njob_categories = ['Data Science', 'Data Analytics',\n                   'Data Engineering', 'Machine Learning',\n                   'Managerial', 'Consultant']\n\nLuego necesitamos crear variables que contengan nuestros filtros\n\ndata_science = 'Data Scientist|NLP'\ndata_analyst = 'Analyst|Analytics'\ndata_engineer = 'Data Engineer|ETL|Architect|Infrastructure'\nml_engineer = 'Machine Learning|ML|Bid Data|AI'\nmanager = 'Manager|Head|Director|Lead|Principal|Staff'\nconsultant = 'Consultant|Freelance'\n\nEl siguiente paso es crear una lista con nuestro rango de condiciones para el m茅todo str.contains\n\nconditions = [\n    (salaries['Designation'].str.contains(data_science)),\n    (salaries['Designation'].str.contains(data_analyst)),\n    (salaries['Designation'].str.contains(data_engineer)),\n    (salaries['Designation'].str.contains(ml_engineer)),\n    (salaries['Designation'].str.contains(manager)),\n    (salaries['Designation'].str.contains(consultant))\n]\n\nFinalmente, podemos crear nuestra nueva columna Job_Category usando la funci贸n de selecci贸n de Numpy\n\nsalaries['Job_Category'] = np.select(conditions,\n                                     job_categories,\n                                     default='Other')\n\nAl obtener una vista previa de la Designaci贸n y nuestra nueva columna Job_Category, podemos verificar los primeros cinco valores.\n\nprint(salaries[['Designation', 'Job_Category']].head())\n\n\n\nVisualizaci贸n de la frecuencia de la categor铆a job\n\n\nsns.countplot(data=salaries, x='Job_Category')\nplt.show()\n\n\n\nEncontrar el n煤mero de valores 煤nicos\nTe gustar铆a practicar algunas de las habilidades de manipulaci贸n y an谩lisis de datos categ贸ricos que acabas de ver. Para ayudarte a identificar qu茅 datos podr铆an reformatearse para extraer valor, vas a averiguar qu茅 columnas no num茅ricas del conjunto de datos planes tienen un gran n煤mero de valores 煤nicos.\n\nInstrucciones\n\nFiltra planes para las columnas que sean del tipo datos \"object\".\nRecorre las columnas del conjunto de datos.\nA帽ade el iterador de columna a la sentencia print y, a continucaci贸n, llama a la funci贸n para que devuelva el n煤mero de valores 煤nicos de la columna.\n\n\n# Filter the DataFrame for objects columns\nnon_numeric = planes.select_dtypes('object')\n\n# Loop through columns\nfor column in non_numeric.columns:\n    # Print the number of unique values\n    print(f\"Number of unique values in {column} column: {non_numeric[column].nunique()}\")\n\nNumber of unique values in Airline column: 8\nNumber of unique values in Date_of_Journey column: 44\nNumber of unique values in Source column: 5\nNumber of unique values in Destination column: 6\nNumber of unique values in Route column: 122\nNumber of unique values in Dep_Time column: 218\nNumber of unique values in Arrival_Time column: 1220\nNumber of unique values in Duration column: 362\nNumber of unique values in Total_Stops column: 5\n\n\nCuriosamente, \"Duration\" es actualmente una columna de tipo objeto cuando deber铆a ser una columna num茅rica, 隆y tiene 362 valores 煤nicos! Vamos a averiguar m谩s sobre esta columna.\n\n\n\nCategor铆a de duraci贸n de vuelos\nComo has visto, hay 362 valores 煤nicos en la columna \"Duration\" de planes. Llamando a planes['Duration'].head(), vemos los siguientes valores.\n\n\n0        19h\n1     5h 25m\n2     4h 45m\n3     2h 25m\n4    15h 30m\nName: Duration, dtype: object\n\n\nParece que no ser谩 sencillo convertirlo a n煤meros. Sin embargo, 隆podr铆as clasificar los vuelos por duraci贸n y examinar la frecuencia de las distintas longitudes de vuelo!\nCrear谩s una columna \"Duration_Category\" en el DataFrame planes. Antes tendr谩s que crear una lista de valores que deseas insertar en el DataFrame, seguida de los valores existentes a partir de los cuales deben crearse.\n\nInstrucciones\n\nCrea una lista de categor铆as que contengan \"Short-haul\", \"Medium\" y \"Long-haul\".\n\n\n# Create a list of categories\nflight_categories = ['Short-haul', 'Medium', 'Long-haul']\n\n\n\n\n\nCrea short_flights, una cadena para capturar valores de \"0h\", \"1h\", \"2h\", \"3h\", \"4h\" teniendo cuidado de evitar valores como \"10h\".\nCrea medium_flights para capturar cualquier valor entre cinco y nueve horas. ~\nCrea long_flights para capturar cualquier valor comprendido entre 10 y 16 horas, ambos inclusive.\n\n\n# Create a list of categories\nflight_categories = ['Short-haul', 'Medium', 'Long-haul']\n\n# Create short-haul values\nshort_flights = '^0h|^1h|^2h|^3h|^4h'\n\n# Create medium-haul values\nmedium_flights = '^5h|^6h|^7h|^8h|^9h'\n\n# Create long-haul values\nlong_flights = '^10h|^11h|^12h|^13h|^14h|^15h|^16h'\n\nAhora has creado tus categor铆as y valores, es hora de agregar condicionalmente las categor铆as en el DataFrame\n\n\n\nA帽adir categor铆as de duraci贸n\nAhora que has configurado las categor铆as y los valores que quieres capturar, 隆es hora de construir una nueva columna para analizar la frecuencia de los vuelos seg煤n su duraci贸n!\nLas variablesflight_categories, short_flights, medium_flights y long_flights que creaste anteriormente est谩n a tu disposici贸n.\n\nimport numpy as np\n\n\nInstrucciones\n\nCrea conditions, una lista que contenga subconjuntos de planes['Duration'] basados en short_flights, medium_flights y long_flights.\nCrea la columna \"Duration_Category\" llamando a una funci贸n que acepte tu lista conditions y flight_categories, estableciendo los valores no encontrados en \"Extreme duration\".\nCrea un gr谩fico fque muestre el recuento de cada categor铆a.\n\n\n# Create conditions for values in flight_categories to be created\nconditions = [\n    (planes['Duration'].str.contains(short_flights)),\n    (planes['Duration'].str.contains(medium_flights)),\n    (planes['Duration'].str.contains(long_flights))\n]\n\n# Apply the conditions list to the flight_categories\nplanes['Duration_Category'] = np.select(conditions, flight_categories,\n                                        default='Extreme duration')\n\n# Plot the counts of each category\nsns.countplot(data=planes, x='Duration_Category',\n              hue='Duration_Category', legend=False)\nplt.show()\n\n\n\n\n\n\n\n\n隆Est谩 claro que la mayor铆a de los vuelos son de corta distancia.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>18</span> <span class='chapter-title'>Limpieza e imputaci贸n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#trabajar-con-datos-num茅ricos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#trabajar-con-datos-num茅ricos",
    "title": "Limpieza e imputaci贸n de datos",
    "section": "Trabajar con datos num茅ricos",
    "text": "Trabajar con datos num茅ricos\n\nEl dataset origina de los salarios\n\n\nprint(salaries.info())\n\n\n\nSalario en Rupias\n\n\nprint(salaries['Salary_In_Rupees'].head())\n\n\n\nConvirtiendo cadena de caracteres en n煤meros\n\nRemover las comas de los valores Salary_In_Rupees\nConvertir la columna a tipo de dato float\nCrear una nueva columna convirtiendo la moneda a d贸lares\n\n\n\npd.Series.str.replace('Caracter a remover', 'Caracter a reemplazar')\n\n\nsalaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].str.replace(',', '')\nprint(salaries['Salary_In_Rupees'].head())\n\n\n\nsalaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].astype(float) \n\n1 Indian Rupee = 0.012 US Dollars\n\nsalaries['Salary_USD'] = salaries['Salary_In_Rupees'] * 0.012\n\n\nPrevisualizando la nueva columna\n\n\nprint(salaries[['Salary_In_Rupees', 'Salary_USD']].head())\n\n\n\nA帽adiendo un resumen esrtad铆stico al DataFrame\n\n\nsalaries.groupby('Company_Size')['Salary_USD'].mean()\n\n\nCalculo de la desviaci贸n est谩ndar de los salarios por experiencia:\n\n\nsalaries['std_dev'] = salaries.groupby('Experience') \\ \n                      ['Salary_USD'].transform(lambda x: x.std())\n\n\nprint(salaries[['Experience', 'std_dev']].value_counts())\n\n\nRepitamos el proceso para otros datos estad铆sticos:\n\nsalaries['median_by_comp_size'] = salaries.groupby('Company_Size') \\\n                                  ['Salary_USD'].transform(lambda x: x.median())\n\n\nprint(salaries[['Company_Size', 'median_by_comp_size']].head())\n\n\n\nDuraci贸n del vuelo\nTe gustar铆a analizar la duraci贸n de los vuelos, pero por desgracia, la columna \"Duration\" de DataFrame planes contiene actualmente valores de cadena.\nTendr谩s que limpiar la columna y convertirla al tipo de datos correcto para el an谩lisis.\n\nimport re\n\ndef duration_to_decimal_str(duration_str: str) -&gt; str:\n    '''\n    Convierte una duraci贸n de vuelo de formato '2h 30m' a una cadena en formato decimal en horas, como '2.5h'.\n    \n    Par谩metros:\n    -----------\n    duration_str : str\n        Cadena de texto que representa la duraci贸n de un vuelo, como '2h 30m', '45m', '19h', etc.\n\n    Retorna:\n    --------\n    str\n        Cadena con duraci贸n expresada en horas decimales, con un solo decimal y el sufijo 'h'. Ej: '2.5h'\n    '''\n    horas = re.search(r'(\\d+)\\s*h', duration_str)\n    minutos = re.search(r'(\\d+)\\s*m', duration_str)\n\n    h = int(horas.group(1)) if horas else 0\n    m = int(minutos.group(1)) if minutos else 0\n\n    decimal_hours = round(h + m / 60, 1)\n    return f'{decimal_hours}h'\n\n\n\nplanes['Duration'] = planes['Duration'].apply(duration_to_decimal_str)\n\n\nInstrucciones\n\nImprime los cinco primeros valores de la columna \"Duration\".\n\n\n# Preview the column\nprint(planes['Duration'].head())\n\n0    19.0h\n1     5.4h\n2     4.8h\n3     2.4h\n4    15.5h\nName: Duration, dtype: object\n\n\n\nRetira \"h\" de la columna\n\n\n# Remove the string character\nplanes['Duration'] = planes['Duration'].str.replace('h', '')\nprint(planes['Duration'].head())\n\n0    19.0\n1     5.4\n2     4.8\n3     2.4\n4    15.5\nName: Duration, dtype: object\n\n\n\nConvierte la columna al tipo de datos float.\n\n\n# Convert to float data type\nplanes['Duration'] = planes['Duration'].astype(float)\nprint(planes['Duration'].head())\n\n0    19.0\n1     5.4\n2     4.8\n3     2.4\n4    15.5\nName: Duration, dtype: float64\n\n\n\nTraza un histograma de los valores de \"Duration\"\n\n\n# Plot a histogram\nsns.histplot(data=planes, x='Duration')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nA帽adir estad铆sticas descriptivas\nAhora \"Duration\" y \"Price\"contienen valores num茅ricos en el DataFrame planes, y te gustar铆a calcular para ellos estad铆sticas de resumen condicionadas a los valores de otras columnas.\n\nInstrucciones\n\nA帽ade una columna a planes que contenga la desviaci贸n est谩ndar de \"Price\" basada en \"Airline\".\n\n\n# Price standard deviation by Airline\nplanes['airline_price_st_dev'] = planes.groupby('Airline')['Price'].transform(lambda x: x.std())\nprint(planes[['Airline', 'airline_price_st_dev']].value_counts())\n\nAirline            airline_price_st_dev\nJet Airways        4159.846432             3082\nIndiGo             2245.529140             1632\nAir India          3692.609285             1399\nMultiple carriers  3558.323763              959\nSpiceJet           1798.900648              653\nVistara            2888.915498              376\nAir Asia           1979.826234              260\nGoAir              2764.926625              147\nName: count, dtype: int64\n\n\n\nCalcula la mediana de \"Duration\" en \"Airline\", almacen谩ndola como una columna llamada \"airline_median_duration\".\n\n\n# Median Duration by Airline\nplanes['airline_median_duration'] = planes.groupby('Airline')['Duration'].transform(lambda x: x.median())\nprint(planes[['Airline', 'airline_median_duration']].value_counts())\n\nAirline            airline_median_duration\nJet Airways        13.3                       3082\nIndiGo             2.9                        1632\nAir India          15.5                       1399\nMultiple carriers  10.2                        959\nSpiceJet           2.5                         653\nVistara            3.2                         376\nAir Asia           2.8                         260\nGoAir              2.9                         147\nName: count, dtype: int64\n\n\n\nEncuenta la media \"Price\" por \"Destination\", guard谩ndola como una columna llamada \"price_destination_mean\".\n\n\n# Mean Price by Destination\nplanes['price_destination_mean'] = planes.groupby('Destination')['Price'].transform(lambda x: x.mean())\nprint(planes[['Destination', 'price_destination_mean']].value_counts())\n\nDestination  price_destination_mean\nCochin       10473.585927              3631\nBanglore     9093.622872               2291\nDelhi        5248.541082                998\nNew Delhi    11579.306944               720\nHyderabad    5190.274021                562\nKolkata      4907.156863                306\nName: count, dtype: int64\n\n\nParece que Jet Airways tiene la mayor desviaci贸n est谩ndar en precio, Air India tiene la mayor duraci贸n median, y Nueva Delhi, en promedio, es el destiono m谩s caro. Ahora veamos c贸mo manejar los datos at铆picos.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>18</span> <span class='chapter-title'>Limpieza e imputaci贸n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#gesti贸n-de-valores-at铆picos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#gesti贸n-de-valores-at铆picos",
    "title": "Limpieza e imputaci贸n de datos",
    "section": "Gesti贸n de valores at铆picos",
    "text": "Gesti贸n de valores at铆picos\n\nQu茅 es un outlier?\n\nEs una observaci贸n que est谩 muy alejada de otros puntos de datos.\n\nUsando estad铆stica descriptiva\n\n\nprint(salaries['Salary_USD'].describe())\n\n\n\nUsando el rango intercuartil\n\nRango intercuartil (IQR)\n\nIQR = 75th - 25th percentil\nUpper outliers &gt; 75th percentile + (1.5 * IQR)\nLower Outliers &lt; 25th percentile - (1.5 * IQR)\n\n\n\n\nsns.boxplot(data=salaries, y='Salaary_USD')\nplt.show()\n\n\n\nIdentificando Umbrales\n\n\n# 75th percentil\nseventy_fifth = salaries['Salary_USD'].quantile(0.75)\n\n# 25th percentil\ntwenty_fifth = salaries['Salary_USD'].quantile(0.25)\n\n# Interquartil range\nsalaries_iqr = seventy_fifth - twenty_fifth\n\nprint(salaries_iqr)\n\n\n\n# Upper threshold\nupper = seventy_fifth + (1.5 * salaries_iqr)\n\n# Lower threshold\nlower = twenty_fifth - (1.5 * salaries_iqr)\n\nprint(upper, lower)\n\n\n\nSubdividiendo nuestros datos\n\n\nsalaries[(salaries['Salary_USD'] &lt; lower) | (salaries['Salary_USD'] &gt; upper)] \\\n        [['Experience', 'Employee_Location', 'Salary_USD']]\n\n\n\n驴 Por qu茅 buscar los Outliers?\n\nLos Outliers son valores extremos\n\nPueden no representar con precisi贸n los datos\n\nPueden sesgar la media y la desviaci贸n est谩ndar\nPruebas de estad铆stica y modelos de machine learning requieren datos que tengan una distribuci贸n normal y no esten sesgados.\n\nQu茅 hacer con los Outliers?\n\nPreguntas que nos debemos hacer:\n\nPor qu茅 existen los outliers?\nLos valores son precisos?\n\n\nEliminaci贸n de Outliers\n\n\nno_outliers = salaries[(salaries['Salar_USD'] &gt; lower) & (salaries['Salary_USD'] &lt; upper)]\n\n\nprint(no_outliers['Salary_USD'].describe())\n\n\n\nDistribuci贸n de Salarios\n\n\n\nQu茅 hacer con los valores at铆picos?\nIdentificar los valores at铆picos es un paso integral en la realizaci贸n de an谩lisis exploratorios de datos.\nEn este ejercicio, se te presentar谩n escenarios en los que hay valores at铆picos, y tendr谩s que decidir qu茅 acci贸n debes tomar.\n\nInstrucciones\n\nColoca cada escenario en el cubo adecuado en funci贸n del enfoque que deba adaptarse para tratar los valores at铆picos.\n\n\n\n\n\n\n\nElimina los valores at铆picos\nDejar los valores at铆picos en el conjunto de datos\n\n\n\n\nUn sensor de temperatura tiene un registro de 100 grados Celsius, pero el sensor solo funciona correctamente a temperaturas de hasta 80 grados.\nse registran las alturas de distintos animales y uno de ellos es m谩s de 1.5 veces la IQR m谩s el percentil 75.\n\n\nLa velocidad de un coche se registra como 5000 km/h.\nLos pa铆ses tienen una superficie total media de 667.143 km2, pero un pa铆s tiene 1.637.687 km2.\n\n\nUn participante en un estudio tiene una edad de menos 35 a帽os.\nUn jugador de baloncesto hace una media de 35 puntos por partido cuando la media en toda la liga es de solo 10 puntos por partido.\n\n\n\n\nPuede ser dif铆cil decidir qu茅 hacer con los valores at铆picos, pero debes saber c贸mo gestionarlos, 隆ya que a menudo se dan en el mundo real!\n\n\n\nIdentificar valores at铆picos\nHas demostrado que reconoces qu茅 hacer cuando se te presentan valores at铆picos, pero 驴Puedes identificarlos utilizando visualizaciones?\nIntenta averiguar si hay valores at铆picos en las columnas \"Price\" o \"Duration\" del dataframe planes.\n\nIntrucciones\n\nTraza la distribuci贸n de la columna \"Price\" de planes.\n\n\n# Plot a histogram of flight prices\nsns.histplot(data=planes, x='Price')\nplt.show()\n\n\n\n\n\n\n\n\n\nMuestra las estad铆sticas descriptivas de la duraci贸n del vuelo.\n\n\n# Display descriptive statistics for flight duration\nprint(planes['Duration'].describe())\n\ncount    8508.000000\nmean       10.726704\nstd         8.472415\nmin         0.100000\n25%         2.800000\n50%         8.700000\n75%        15.500000\nmax        47.700000\nName: Duration, dtype: float64\n\n\n\nPregunta\n\n驴Qu茅 columna contiene potencialmente valores at铆picos?\nRespuestas Posibles\n\n\"Price\"\n\"Duration\"\n\"Price\" y \"Duration\"\nNinguna\n\nLos histogramas, diagramas de caja y estad铆sticas descriptivas tambi茅n son m茅todos 煤tiles para identificar valores extremos. 隆Ahora vamos a tratarlos!\n\n\n\nEliminar valores at铆picos\nAunque eliminar los valores at铆picos no siempre es el camino a seguir, para tu an谩lisis has decidido que solo incluir谩s los vuelos en los que el \"Price\" no sea un valor at铆pico.\nPor lo tanto tienes que encontrar el umbral superior y utilizarlo para eliminar los valores que lo superen del Dataframe planes.\n\nInstrucciones\n\nHalla los percentiles 75 y 25, guardando como price_seventy_fifth y price_twenty_fifth respectivamente.\n\n\n# Find the 75th and 25th percentiles\nprice_seventy_fifth = planes['Price'].quantile(0.75)\nprice_twenty_fifth = planes['Price'].quantile(0.25)\n\n\nCalcula el IQR, almacen谩ndolo como prices_iqr.\n\n\n# Calculate iqr\nprices_iqr = price_seventy_fifth - price_twenty_fifth\nprint(prices_iqr)\n\n7014.0\n\n\n\nCalcula los umbrales superior e inferior de los valores at铆picos.\n\n\n# Calculate the thresholds\nupper = price_seventy_fifth + (1.5 * prices_iqr)\nlower = price_twenty_fifth - (1.5 * prices_iqr)\n\n\nElimina los valores at铆picos de planes.\n\n\n# Subset the data\nplanes = planes[(planes['Price'] &gt; lower) & (planes['Price'] &lt; upper)]\n\nprint(planes['Price'].describe())\n\ncount     8438.000000\nmean      8877.466046\nstd       4001.838236\nmin       1759.000000\n25%       5224.000000\n50%       8372.000000\n75%      12121.000000\nmax      22270.000000\nName: Price, dtype: float64\n\n\n隆Habilidades rid铆culas para eliminar valores at铆picos! Lograste crear umbrales basados en el IQR y los usaste para filtrar el conjunto de datos planes para eliminar precios extremos. Originalmente, el conjunto de datos ten铆a un precio m谩ximo de casi 55000, pero la salida de planes['Price'].describe() muestra que el m谩ximo se ha reducido a alrededor de 23000, 隆reflejando una distribuci贸n menos sesgada para el an谩lisis!",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>18</span> <span class='chapter-title'>Limpieza e imputaci贸n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html",
    "title": "Relaciones en los datos",
    "section": "",
    "text": "Patrones a lo largo del tiempo\nLas variables de los conjuntos de datos tienen relaciones entre s铆. En este cap铆tulo, examinar谩s las relaciones entre datos num茅ricos, categ贸ricos e incluso DateTime, explorando la direcci贸n y la fuerza de estas relaciones, as铆 como las formas de visualizarlas.\ndivorce = pd.read_csv(\"divorce.csv\")\ndivorce.head()\ndivorce.dtypes\ndivorce = pd.read_csv(\"divorce.csv\", parse_dates=[\"marriage_date\"])\ndivorce.dtypes\ndivorce['marriage_date'] = pd.to_datetime(divorce['marriage_date'])\ndivorce_dtypes\ndivorce.head(2)\ndivorce['marriage_date'] = pd.to_datetime(divorce[['month', 'day', 'year']])\ndivorce.head(2)\nEs posible extraer s贸lo el mes, el d铆a o el a帽o de una columna que contenga una fecha completa, usando los atributos dt.month, dt.day y dt.year.\ndivorce['marriage_month'] = divorce['marriage_date'].dt.month()\ndivorce.head()\nsns.lineplot(data=divorce, x='marriage_month', y='marriage_duration')\nplt.show()\nLos amplios intervalos de confianza sugieren que se necesita m谩s an谩lisis.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>19</span> <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#patrones-a-lo-largo-del-tiempo",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#patrones-a-lo-largo-del-tiempo",
    "title": "Relaciones en los datos",
    "section": "",
    "text": "Importando data DateTime\n\nDataTime necesita ser explicitamente declarada en pandas\n\n\n\n\n\n\n\n\nEste tipo de datos abre muchas posibilidades para el an谩lisis, como observar patrones a lo largo de a帽os, meses o incluso d铆as de la semana.\n\n\n\nConviritiendo los datos a DataTime\n\npd.to_datetime() convierte los argumentos de datos DateTime\n\n\n\n\n\nCreando datos DateTime\n\n\n\n\n\n\n\n\n\nVisualizando patrones a lo largo del tiempo\n\n\n\n\n\nImportar datos DateTime\n隆Ahora trabajar谩s con todo el conjunto de datos del divorcio! Los datos desciben los matrimonios mexicanos disueltos entre 2000 y 2015. Contiene las fechs de matrimonio y divorcio, el nivel educativo, la fecha de nacimiento, los ingresos de cada miembro de la pareja y la duraci贸n del matrimonio, as铆 como el n煤mero de hijos que ten铆a la pareja en el momento del divorcio.\nLos nombres de ls columnas y los tipos de datos son los siguientes:\n\n隆Parece que hay mucha informaci贸n de fecha en estos datos que todav铆a no son de tipo DateTime! Tu tarea es arreglarlo para que puedas explorar patrones a lo largo del tiempo.\n\nimport pandas as pd\n\nruta = './data/divorce.csv'\ndivorce = pd.read_csv(ruta)\ndivorce.head()\n\n\n\n\n\n\n\n\ndivorce_date\ndob_man\neducation_man\nincome_man\ndob_woman\neducation_woman\nincome_woman\nmarriage_date\nmarriage_duration\nnum_kids\n\n\n\n\n0\n2006-09-06\n1975-12-18\nSecondary\n2000.0\n1983-08-01\nSecondary\n1800.0\n2000-06-26\n5.0\n1.0\n\n\n1\n2008-01-02\n1976-11-17\nProfessional\n6000.0\n1977-03-13\nProfessional\n6000.0\n2001-09-02\n7.0\nNaN\n\n\n2\n2011-01-02\n1969-04-06\nPreparatory\n5000.0\n1970-02-16\nProfessional\n5000.0\n2000-02-02\n2.0\n2.0\n\n\n3\n2011-01-02\n1979-11-13\nSecondary\n12000.0\n1981-05-13\nSecondary\n12000.0\n2006-05-13\n2.0\nNaN\n\n\n4\n2011-01-02\n1982-09-20\nProfessional\n6000.0\n1988-01-30\nProfessional\n10000.0\n2007-08-06\n3.0\nNaN\n\n\n\n\n\n\n\n\nInstrucciones\n\nImporta divorce.csv, guardando como DataFrame, divorce: indica en la funci贸n de importaci贸n que las columnas divorce_date, dob_man, dob_woman, y marriage_date deben importarse como valores DateTime.\n\n\n# Import divorce.csv, parseing the appropriate columns as dateds in the import\ndivorce = pd.read_csv('./data/divorce.csv', parse_dates=['divorce_date', 'dob_man', 'dob_woman', 'marriage_date'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date        datetime64[ns]\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\nBuen trabajo parseando esas fechas al mismo tiempo que importabas los datos en pandas. 隆Ahora, intenta actualizar los tipos de datos DateTime en una DataFrame que ya ha sido importado!\n\n\n\nActualizar tipo de datos a DateTime\nAhora se te ha cargado el DataFrame divorce, pero una columna se almacea como una cadena que deber铆a ser un dato DateTime. 驴Cu谩l es? Una vez que hayas identificado la columna, la actualizar谩s para que puedas explorarla m谩s de cerca en el siguiente ejercicio.\n\nruta = './data/divorce.csv'\ndivorce = pd.read_csv(ruta, parse_dates=['divorce_date', 'dob_man', 'dob_woman'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date                object\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\n\nInstrucciones\n\nPregunta\n\n驴Cu谩l de las columnas del DataFrame divorce no se ha actualizado a un tipo de datos DateTime, pero deber铆a hacerse?\nRespuestas posibles\n\ndivorce_date\nmarriage_date\neducation_woman\nnum_kids\n\n\nCovierte la columna marriage_date del DataFrame divorce en valores de DateTime.\n\n\n# Convert the marriage_date column to DateTime values\ndivorce['marriage_date'] = pd.to_datetime(divorce['marriage_date'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date        datetime64[ns]\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\nAhora, est谩s listo para ver c贸mo la fecha de matrimonio de una pareja se relaciona con otros datos.\n\n\n\nVisualizar las relaciones a lo largo del tiempo\nAhora que tus datos de fechas se guardan como datos DateTime, 隆puedes explorar patrones a lo largo del tiempo! 驴Tiene relaci贸n el a帽o en que se cas贸 una pareja con el n煤mero de hijos que tiene en el momento del divorcio? 隆Tu tarea es averiguarlo!\n\nInstrucciones\n\nDefine una columna llamada marriage_year, que solo contiene la parte del a帽o de la columna marriage_date.\n\n\n# Define the marriage_year column\ndivorce['marriage_year'] = divorce['marriage_date'].dt.year\n\n\nCrea un gr谩fico de l铆neas que muestre el n煤mero medio de hijos que tuvo una pareja durante su matrimonio, ordenado por el a帽o en que la pareja se cas贸.\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Create a lineplot showing the average  number of kids by year\nsns.lineplot(data=divorce, x='marriage_year', y='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\n隆Bien hecho! Haz descubierto un patr贸n aqu铆, parece que las parejas que se casaron en a帽os posteriores tambi茅n tuvieron menos hijos durante su matrimonio.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>19</span> <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#correlaci贸n",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#correlaci贸n",
    "title": "Relaciones en los datos",
    "section": "Correlaci贸n",
    "text": "Correlaci贸n\n\nCorrelaci贸n\n\nDescribe la direcci贸n de la relaci贸n de entre dos variables as铆 como su fuerza.\nConfigurar numeric_only=True previene errores con columnas no num茅ricas.\nEl m茅todo .cor() calcula el coeficiente de correlaci贸n de Pearson.\n\n\n\ndivorce.corr(numeric_only=True)\n\n\n\n\n\n\n\n\nincome_man\nincome_woman\nmarriage_duration\nnum_kids\nmarriage_year\n\n\n\n\nincome_man\n1.000000\n0.318047\n0.085321\n0.040848\n0.019170\n\n\nincome_woman\n0.318047\n1.000000\n0.078677\n-0.018015\n0.026433\n\n\nmarriage_duration\n0.085321\n0.078677\n1.000000\n0.447358\n-0.812469\n\n\nnum_kids\n0.040848\n-0.018015\n0.447358\n1.000000\n-0.461495\n\n\nmarriage_year\n0.019170\n0.026433\n-0.812469\n-0.461495\n1.000000\n\n\n\n\n\n\n\n\nMapas de calor de correlaci贸n\n\n\nsns.heatmap(divorce.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nCorrelaci贸n en contexto\n\n\ndivorce['divorce_date'].min()\n\nTimestamp('2000-01-08 00:00:00')\n\n\n\ndivorce['divorce_date'].max()\n\nTimestamp('2015-11-03 00:00:00')\n\n\n\nVisualizaci贸n de las relaciones\n\nEs importante complementar nuestros c谩lculos de correlaci贸n con gr谩ficos de dispersi贸n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuerte relaci贸n, pero no lineal\nEl coeficiente de correlaci贸n de Pearson: -6.48e-18\n\n\nRelaci贸n cuadr谩tica; no lineal\nCoeficiente de correlaci贸n de Pearson: .971211\n\n\n\n\n\nScatter plots\n\n\nsns.scatterplot(data=divorce, x='income_man', y='income_woman')\nplt.show()\n\n\n\n\n\n\n\n\n\nPairplots\n\nEs 煤til para obtener una descripci贸n general r谩pida de las relaciones dentro del conjunto de datos.\nTanta informaci贸n en un elemento visual puede ser dif铆cil de interpretar con grandes conjuntos de datos.\n\n\n\nsns.pairplot(data=divorce)\nplt.show()\n\n\n\n\n\n\n\n\nEs posible limitar el n煤mero de relaciones graficadas estableciendo el argumento vars igual a las variables de inter茅s.\n\nsns.pairplot(data=divorce, vars=['income_man', 'income_woman', 'marriage_duration'])\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretar un mapa de calor\n驴Cu谩l de las siguientes afirmaciones es correcta respecto a las relaciones entre variables en el DataFrame divorce?\n\ndivorce['marriage_moth'] = divorce['marriage_date'].dt.month\ndivorce.head()\n\n\n\n\n\n\n\n\ndivorce_date\ndob_man\neducation_man\nincome_man\ndob_woman\neducation_woman\nincome_woman\nmarriage_date\nmarriage_duration\nnum_kids\nmarriage_year\nmarriage_moth\n\n\n\n\n0\n2006-09-06\n1975-12-18\nSecondary\n2000.0\n1983-08-01\nSecondary\n1800.0\n2000-06-26\n5.0\n1.0\n2000\n6\n\n\n1\n2008-01-02\n1976-11-17\nProfessional\n6000.0\n1977-03-13\nProfessional\n6000.0\n2001-09-02\n7.0\nNaN\n2001\n9\n\n\n2\n2011-01-02\n1969-04-06\nPreparatory\n5000.0\n1970-02-16\nProfessional\n5000.0\n2000-02-02\n2.0\n2.0\n2000\n2\n\n\n3\n2011-01-02\n1979-11-13\nSecondary\n12000.0\n1981-05-13\nSecondary\n12000.0\n2006-05-13\n2.0\nNaN\n2006\n5\n\n\n4\n2011-01-02\n1982-09-20\nProfessional\n6000.0\n1988-01-30\nProfessional\n10000.0\n2007-08-06\n3.0\nNaN\n2007\n8\n\n\n\n\n\n\n\n\nInstrucciones\nRespuestas Posibles\n\nmarriage_duration est谩 fuertemente correlacionada de forma positiva con marriage_month.\nLa correlaci贸n entre num_kids y income_man es m谩s fuerte que la correlaci贸n entre num_kids y marriage_duration.\nUn marriage_year m谩s tard铆o provoca un menor n煤mero de hijos, representado por num_kids.\nUn marriage_year m谩s tard铆o est谩 correlacionado con tener menos hijos.\n\n\n\n\nVisualizar las relaciones entre variables\nEn el 煤ltimo ejercicio, habr谩s observado que un marriage_duration m谩s largo est谩 correlacionado con tener m谩s hijos , representado por la columna num_kids. El coeficiente de correlaci贸n entre las variables marriage_duration y num_kids es 0.45.\nEn este ejercicio, crear谩s un gr谩fico de dispersi贸n para visualizar la relaci贸n entre estas variables.\n\nInstrucciones\n\nCree un diagrama de dispersi贸n que muestre marriage_duration en el eje x y num_kids en el eje y.\n\n\n# Create the scatterplot\nsns.scatterplot(data=divorce, x='marriage_duration', y='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\nHay una ligera relaci贸n positiva en el gr谩fico de dispersi贸n. En el conjunto de datos, las parejas sin hijos no tienen valor en la columna num_kids. Si est谩s seguro que todos o la mayor铆a de los valores faltantes en num_kids est谩n relacionados con parejas sin hijos, podr铆as considerar actualizar estos valores a 0, lo que podr铆a aumentar la correlaci贸n.\n\n\n\nVisualizar las relaciones entre m煤ltiples variables\nSeaborns .pairplot() es excelente para comprender las relaciones entre varias o todas las vatiables de un conjunto de datos, agregando gr谩ficos de dispersi贸n por pares en un solo visual.\nTu tarea consiste en utilizar un pairplot par comparar la relaci贸n entre marriage_duration y income_woman.\n\nInstrucciones\n\nCrea un diagrama de pares para visualizar las relaciones entre income_woman y marriage_duration en el DataFrame divorce.\n\n\n# Create a pairplot for income_woman and marriage_duration\nsns.pairplot(data=divorce, vars=['income_woman', 'marriage_duration'])\nplt.show()\n\n\n\n\n\n\n\n\nAl igual que la matriz de correlaci贸n , puedes ver que la relaci贸n entre income_woman y marriage_duration no es fuerte. Tambi茅n puedes tener una idea de las distribuciones de ambas variables en los gr谩ficos superior izquierdo e inferior derecho.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>19</span> <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#relaciones-y-distribuciones-de-los-factores",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#relaciones-y-distribuciones-de-los-factores",
    "title": "Relaciones en los datos",
    "section": "Relaciones y distribuciones de los factores",
    "text": "Relaciones y distribuciones de los factores\n\nNivel de educaci贸n: male partner\n\n\ndivorce['education_man'].value_counts()\n\neducation_man\nProfessional    1313\nPreparatory      501\nSecondary        288\nPrimary          100\nOther              3\nName: count, dtype: int64\n\n\n\nExplorando las relaciones categ贸ricas\n\n\nsns.histplot(data=divorce, x='marriage_duration', binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data=divorce, x='marriage_duration', hue='education_man', binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\nKernel Desnsity Estimate (KDE) plots\n\n\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man')\nplt.show()\n\n\n\n\n\n\n\n\nLos gr谩ficos KDE nos permiten visualizar las distribuciones. Los KDE son m谩s interpretables, especialmente cuando se muestran varias distribuciones.\nLa distribuci贸n con KDE parece sugerir que algunas parejas tuvieron duraciones menores a cero.\nPara solucionar esto, podempos utilizar el argumento de la palabra clave cut.\n\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man', cut=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nGr谩ficos KDE acumulativos\n\n\nimport seaborn as sns\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man', cut=0, cumulative=True)\nplt.show()\n\n\n\n\n\n\n\n\nEste gr谩fico describe la probabilidad de que la duraci贸n del matrimonio sea menor o igual al valor del eje x para cada nivel de educaci贸n de la pareja masculina.\n\nRelaci贸n entre la edad del matrimonio y la educaci贸n\n\nHay una relaci贸n entre la edad al momento del matrimonio y el nivel de educaci贸n?\n\n\n\ndivorce['man_age_marriage'] = divorce['marriage_year'] - divorce['dob_man'].dt.year\ndivorce['woman_age_marriage'] = divorce['marriage_year'] - divorce['dob_woman'].dt.year\n\n\nScatter plot con las variables categ贸ricas\n\n\nsns.catplot(data=divorce, x='woman_age_marriage', y='man_age_marriage')\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.catplot(data=divorce, x='woman_age_marriage', y='man_age_marriage', hue='education_man')\nplt.show()\n\n\n\n\n\n\n\n\n\nDatos categ贸ricos en gr谩ficos de dispersi贸n\nEn el video se exploro c贸mo se relacionan el nivel educativo de los hombres y la edad al casarse con otras variables de nuestro conjunto de datos, el DataFrame divorce. Ahora ver谩s c贸mo se relacionan la formaci贸n de las mujeres y la edad al casarse con otras variables.\nTu tarea consiste en crear un diagrama de dispersi贸n de la edad y los ingresos de cada mujer, incorporando la variable categ贸rica del nivel educativo para obtener un contexto adicional.\n\nInstrucciones\n\nCrea un gr谩fico de dispersi贸n que muestre woman_age_marriage en el eje de abcisas y income_woman en el eje de las ordenadas, cada punto de datos debe colorearse en funci贸n del nivel educativo de la mujer, representado por education_woman.\n\n\n# Create a scatter plot\nsns.scatterplot(data=divorce, x='woman_age_marriage', y='income_woman', hue='education_woman')\nplt.show()\n\n\n\n\n\n\n\n\nParece que hay una correlaci贸n positiva entre la educaci贸n profesional y los salarios m谩s altos, como cabr铆a esperar. La relaci贸n entre la edad de las mujeres al casarse y el nivel educativo es un poco menos clara.\n\n\n\nExplorando con gr谩ficos KDE\nLos gr谩ficos de Estimaci贸n de Densidad del N煤cleo (KDE) son una gran alternativa a los histogramas cuando quieres mostrar varias distribuciones en el mismo gr谩fico.\nSupongamos que te interesa la relaci贸n entre la duraci贸n del matrimonio y el n煤mero de hijos que tiene una pareja. Como los valores de la columna num_kids s贸lo van de uno a cinco, puedes graficar el KDE de cada valor en la misma gr谩fica.\nRecuerda que la columna num_kids de divorce solo muestra los valores N/A de las parejas sin hijos, por lo que solo ver谩s las distribuciones de las parejas divorciadas con al menos un hijo.\n\nInstrucciones\n\nCree un gr谩fico KDE que muestre marriage_duration en el eje x y una l铆nea de color diferente para cada posible n煤mero de hijos que pueda tener una pareja, representada por num_kids.\n\n\n# Create the KDE plot\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\n\nObserva que actualmente el gr谩fico muestra duraciones del matrimonio inferiores a cero; actualiza el grafico KDE para que la duraci贸n del matrimonio no pueda suavizarse m谩s all谩 de los puntos de datos extremos.\n\n\n# Update the KDE plot so that marriage durantion can't be smoothed too far\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids', cut=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nActualiza el c贸digo del gr谩fico KDE del paso anterior para que muestre una funci贸n de distribuci贸n acumulativo para cada n煤mero de hijos que tiene una pareja.\n\n\n# Update the KDE plot to show a cumulative distribution function\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids', cut=0, cumulative=True)\nplt.show()\n\n\n\n\n\n\n\n\nParece que hay una correlaci贸n positiva entre matrimonios m谩s largos y m谩s hijos, pero por supuesto, esto no indica causalidad. Tambi茅n puedes ver que hay muchos menos datos sobre parejas con m谩s de dos hijos; esto nos ayuda a entender cuan confiables son nuestros hallazgos.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>19</span> <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html",
    "title": "Convertir el an谩lisis exploratorio en acci贸n",
    "section": "",
    "text": "Consideraciones para datos categ贸ricos\nEl an谩lisis exploratorio de datos es un paso crucial en el flujo de trabajo de la ciencia de datos, 隆por no esl el final! Ahora es el momento de aprender t茅cnicas y consideraciones que puedes utilizar para avanzar con 茅xito en tus proyectos una vez que hayas terminado de explorar.\nprint(planes('Destination').value_counts())\nplanes['Destination'].value_counts(normalize=True)\nEs nuestra muestra representativa de la poblaci贸n? (Vuelos internos de India)\npd.crosstab(planes['Source'], planes['Destination'])\npd.crosstab(planes['Source'], planes['Destination'],\n           values=planes['Price'], aggfunc='median')\nLos resultados muestran valores de la mediana para todas las rutas posibles en el conjunto de datos.",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>20</span> <span class='chapter-title'>Convertir el an谩lisis exploratorio en acci贸n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#consideraciones-para-datos-categ贸ricos",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#consideraciones-para-datos-categ贸ricos",
    "title": "Convertir el an谩lisis exploratorio en acci贸n",
    "section": "",
    "text": "Por qu茅 ejecutar EDA?\n\nDetectar patrones y relaciones.\nGenerar preguntas o hip贸tesis.\nPreparar datos para modelos de machine learning.\n\nRepresentatividad de los datos\n\nLa muestra debe representar la poblaci贸n.\nPor ejemplo:\n\nEducaci贸n versus ingresos en USA\n\nNo se pueden usar datos de Francia\n\n\n\nClases Categ贸ricas\n\nClases = etiquetas\nEjemplo, actitudes de las personas hacia el matrimonio.\n\nEstado civil\n\nSoltero\nCasado\nDivorciado\n\n\n\nDesbalance de Clases\n\n\n\nFrecuencia de Clases\n\n\n\n\nFrecuencia relativa de clases\n\n40% de los vuelos internos de la India van hacia Delhi.\n\n\n\n\n\n\nTabulaci贸n Cruzada\n\nEs otro m茅todo para observar la frecuencia de clase, que permite examinar la frecuencia de combinaciones de clases\n\n\n\n\n\n\nExtendiendo la tabulaci贸n cruzada\n\n\n\n\nSource\nDestination\nMedian Price (IDR)\n\n\n\n\nBanglore\nDelhi\n4232.21\n\n\nBanglore\nNew Delhi\n12114.56\n\n\nChennai\nKolkata\n3859.76\n\n\nDelhi\nCochin\n9987.63\n\n\nKolkata\nBanglore\n9654.21\n\n\nMumbai\nHyderabad\n3431.97\n\n\n\n\nAgregaci贸n de valores con pd.crosstab()\n\n\n\n\n\nComparando la muestra con la poblaci贸n\n\n\n\n\nSource\nDesitnation\nMedian Price (IDR)\nMedian Price (dataset)\n\n\n\n\nBanglore\nDelhi\n4232.21\n4823.0\n\n\nBanglore\nNew Delhi\n12114.56\n10976.50\n\n\nChennai\nKolkata\n3859.76\n3850.0\n\n\nDelhi\nCochin\n9987.63\n10260.0\n\n\nKolkata\nBanglore\n9654.21\n9345.0\n\n\nMumbai\nHyderabad\n3431.97\n3342.0\n\n\n\n\nComprobaci贸n del desequilibrio de clases\nLa Encuesta Kaggle 2022 recoge la informaci贸n sobre la formaci贸n de los cient铆ficos de datos, sus tecnolog铆as y t茅cnicas preferidas. Se considera una visi贸n precisa de lo que est谩 ocurriendo en la ciencia de datos, basada en el volumen y el perfil de los que responden.\nUna vez examinados los t铆tulos de los puestos y categorizados para alinearlos con nuestro salaries DataFrame`, puedes ver la siguiente proporci贸n de categor铆as laborales en la encuesta Kaggle:\n\n\n\nCategor铆a laboral\nFrecuencia relativa\n\n\n\n\nCiencia de datos\n0,281236\n\n\nAn谩lisis de datos\n0,224231\n\n\nOtros\n0,214609\n\n\nDirecci贸n\n0,121300\n\n\nMachine Learning\n0,083248\n\n\nIngenier铆a de datos\n0,075375\n\n\n\nPensando en los resultados de la encuesta Kaggle como poblaci贸n, tu tarea consiste en averiguar si el DataFrame salaries es representativo comparando la frecuencia relativa de las categor铆as laborales.\n\nimport pandas as pd\nruta = './data/salaries.csv'\nsalaries = pd.read_csv(ruta)\nsalaries.head()\n\n\n\n\n\n\n\n\nWorking_Year\nDesignation\nExperience\nEmployment_Status\nSalary_In_Rupees\nEmployee_Location\nCompany_Location\nCompany_Size\nRemote_Working_Ratio\nSalary_USD\nJob_Category\n\n\n\n\n0\n2020\nMachine Learning Scientist\nSE\nFT\n20688070.0\nJP\nJP\nS\n0.0\n248256.840\nMachine Learning\n\n\n1\n2020\nBig Data Engineer\nSE\nFT\n8674985.0\nGB\nGB\nM\n50.0\n104099.820\nData Engineering\n\n\n2\n2020\nProduct Data Analyst\nMI\nFT\n1591390.0\nHN\nHN\nS\n0.0\n19096.680\nData Analytics\n\n\n3\n2020\nMachine Learning Engineer\nSE\nFT\n11935425.0\nUS\nUS\nL\n50.0\n143225.100\nMachine Learning\n\n\n4\n2020\nData Analyst\nEN\nFT\n5729004.0\nUS\nUS\nL\n100.0\n68748.048\nData Analytics\n\n\n\n\n\n\n\n\nInstrucciones\n\nImprime la frecuencia relativa de la columna Job_Category de salaries DataFrame\n\n\n\n\n\n\n\nNote\n\n\n\nPara exportar el dataset en formato CSV dentro de DataCamp y luego copiarlo:\nprint(salaries.to_csv(index=False))\n\n\n\n# Print the relative frequency of Job_Category\nprint(salaries['Job_Category'].value_counts(normalize=True))\n\nJob_Category\nData Science        0.277641\nData Engineering    0.272727\nData Analytics      0.226044\nMachine Learning    0.120393\nOther               0.068796\nManagerial          0.034398\nName: proportion, dtype: float64\n\n\nParece que Data Science es la clase m谩s popular y tiene una representaci贸n similar. A煤n as铆, las otras categor铆as tienen frecuencias relativas bastante diferentes, lo cual pordr铆a no ser sorprendente dado que el p煤blico objetivo son cient铆fico de datos. Dada la diferencia en las frecuencias relativas, 驴puedes confiar en que el DataFrame salaries representa con precisi贸n los roles gerenciales?\n\n\n\nTabulaci贸n cruzada\nLa tabulaci贸n cruzada puede ayudar a identificar c贸mo se combinan las observaciones.\nUtilizando el conjunto de datos salaries, que se ha importado como un DataFrame pandas, realizar谩s una tabulaci贸n cruzada de m煤ltiples variables, incluyendo el uso de la agregaci贸n, para ver la relaci贸n entre Company_Size y otras variables.\n\nInstrucciones\n\nRealiza una tabulaci贸n cruzada, estableciendo Company_Size como 铆ndice, y las columnas a las clases en Experience.\n\n\n# Cross-tabulate Company_Size and Experience\nprint(pd.crosstab(salaries['Company_Size'], salaries['Experience']))\n\nExperience    EN  EX  MI   SE\nCompany_Size                 \nL             24   7  49   44\nM             25   9  58  136\nS             18   1  21   15\n\n\n\nCruza Job_Category y las clases de Company_Size como nombres de columna.\n\n\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size']))\n\nCompany_Size       L   M   S\nJob_Category                \nData Analytics    23  61   8\nData Engineering  28  72  11\nData Science      38  59  16\nMachine Learning  17  19  13\nManagerial         5   8   1\nOther             13   9   6\n\n\n\nActualiza pd.crosstab() para que devuelva los valores medios de Salary_USD.\n\n\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size'], values= salaries['Salary_USD'], aggfunc='mean'))\n\nCompany_Size                  L              M             S\nJob_Category                                                \nData Analytics    112851.749217   95912.685246  53741.877000\nData Engineering  118939.035000  121287.060500  86927.136000\nData Science       96489.520105  116044.455864  62241.749250\nMachine Learning  140779.491529  100794.236842  78812.586462\nManagerial        190551.448800  150713.628000  31484.700000\nOther              92873.911385   89750.578667  69871.248000\n\n\nsta es una funci贸n 煤til para examinar la combinaci贸n de frecuencias, as铆 como para encontrar estad铆sticas agregadas. 隆Parece que el salario medio m谩s alto es para roles de datos gerenciales en grandes empresas!",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>20</span> <span class='chapter-title'>Convertir el an谩lisis exploratorio en acci贸n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-nuevas-caracter铆sticas",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-nuevas-caracter铆sticas",
    "title": "Convertir el an谩lisis exploratorio en acci贸n",
    "section": "Generar nuevas Caracter铆sticas",
    "text": "Generar nuevas Caracter铆sticas\n\nCorrelaci贸n\n\n\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\nViendo el tipo de datos\n\n\nprint(planes.dtypes)\n\n\n\nTotal Stops\n\n\nprint(planes['Total_Stops'].value_counts())\n\n\nSe observa que es necesario eliminar algunos caracteres.\n\nLimpiando Total Stops\n\n\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stops', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stop', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace('non-stop', '0')\nplanes['Total_Stops'] = planes['Total_Stops'].astype(int)\n\n\nCorrelaci贸n\n\n\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\nFechas\n\n\nprint(planes.dtypes)\n\n\n\nExtrayendo el mes y el d铆a de la semana\n\n\nplanes['month'] = planes['Date_of_Journey'].dt.month\nplanes['weekday'] = planes['Date_of_Journey'].dt.weekday\nprint(planes[['month', 'weekday', 'Date_of_Journey']].head())\n\n\n\nTiempos de salidas y llegadas\n\n\nplanes['Dep_Hour'] = planes['Dep_Time'].dt.hour\nplanes['Arrival_Hour'] = planes['Arrival_Time'].dt.hour\n\n\nCorrelaci贸n\n\n\nNo hay correlaciones, pero no lo sabr铆amos si no se hubieran generado nuevas caracter铆sticas.\n\nCreando caracter铆sticas\n\n\nprint(planes['Price'].describe())\n\n\n\n\n\nRango\nTipo de tiquete\n\n\n\n\n&lt;= 5228\nEconomy\n\n\n&gt; 5528 &lt;= 8355\nPremium Economy\n\n\n&gt; 8355 &lt;= 12373\nBusiness Class\n\n\n&gt; 12373\nFirst Class\n\n\n\n\nEstad铆stica descriptiva\n\n\ntwenty_fifth = planes['Price'].quantile(0.25)\nmedian = planes['Price'].median()\nseventy_fifth = planes['Price'].quantile(0.75)\nmaximum = planes['Price'].max()\n\n\nEtiquetas y bins\n\n\nlabels = ['Economy', 'Premium Economy', 'Business Class', 'First Class']\nbins = [0, twenty_fifth, median, seventy_fifth, maximum]\n\n\npd.cut()\n\n\n\nplanes['Price_Category'] = pd.cut(planes['Price'], labels=labels, bins=bins)\n\n\nCategor铆a de precios\n\n\nprint(planes[['Price', 'Price_Category']].head())\n\n\n\nCategor铆a de precio por aerol铆nea\n\n\nsns.countplot(data=planes, x='Airline', hue='Price_Category')\nplt.show()\n\n\n\nExtraer caracter铆sticas para la correlaci贸n\nEn este ejercicio trabajar谩s con una versi贸n del conjunto de datos salaries que contiene una nueva columna llamada `date_of_response.\nEl conjunto de datos se ha le铆do comjo un DataFrame de pandas, con date_of_response como tipo de datos datetime.\nTu tarea consiste en extraer los atributos fecha-hora de esta columna y, a continuaci贸n, crear un mapa de calor para visualizar los coeficientes de correlaci贸n entre las variables.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nPara realizar el ejercicio fue necesario bajar el DataFrame de Datacamp teniendo en cuenta la nueva columna, y cambiando el tipo de formato de la columna date_of_response usando los comandos:\n\nprint(salaries.to_csv(index=false))\n\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nruta = './data/salaries_2.csv'\nsalaries = pd.read_csv(ruta)\n\n# Cambia el tipo de datos de date_of_response\nsalaries['date_of_response'] = pd.to_datetime(salaries['date_of_response'])\nsalaries.head()\n\n\n\n\n\n\n\n\nDesignation\ndate_of_response\nExperience\nEmployment_Status\nSalary_In_Rupees\nEmployee_Location\nCompany_Location\nCompany_Size\nRemote_Working_Ratio\nSalary_USD\nJob_Category\n\n\n\n\n0\nMachine Learning Scientist\n2020-01-07\nSE\nFT\n20688070.0\nJP\nJP\nS\n0.0\n248256.840\nMachine Learning\n\n\n1\nBig Data Engineer\n2020-09-19\nSE\nFT\n8674985.0\nGB\nGB\nM\n50.0\n104099.820\nData Engineering\n\n\n2\nProduct Data Analyst\n2020-11-21\nMI\nFT\n1591390.0\nHN\nHN\nS\n0.0\n19096.680\nData Analytics\n\n\n3\nMachine Learning Engineer\n2020-11-29\nSE\nFT\n11935425.0\nUS\nUS\nL\n50.0\n143225.100\nMachine Learning\n\n\n4\nData Analyst\n2020-09-07\nEN\nFT\n5729004.0\nUS\nUS\nL\n100.0\n68748.048\nData Analytics\n\n\n\n\n\n\n\n\nInstrucciones\n\nExtrae el mes de date_of_response, almacen谩ndolo como una columna llamada month.\nCrea la columna weekday, que contiene el d铆a de la semana en que los participantes completaron la encuesta.\nTraza un mapa de calor, incluyendo las puntuaciones del coeficiente de correlaci贸n de Pearson.\n\n\n# Get the month of the response\nsalaries['month'] = salaries['date_of_response'].dt.month\n\n# Extract the weekday of the response\nsalaries['weekday'] = salaries['date_of_response'].dt.weekday\n\n# Create a heatmap\nsns.heatmap(salaries.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n隆Fant谩stica creaci贸n de caracter铆sticas! Parece que no hay relaciones significativas entre nuestras variables num茅ricas, as铆 que veamos si convertir los datos num茅ricos en clases ofrece informaci贸n adicional.\n\n\n\nC谩lculo de los percentiles salariales\nTu tarea consiste en convertir la columna Salary_USD en categor铆as basadas en sus percentiles . Primero tienes que encontrar los percentiles y almacenarlos como variables.\n\nInstrucciones\n\nHalla el percentil 25 de Salary_USD\nGuarda la mediana de Salary_USD como salaries_median.\nObt茅n el percentil 75 de los salaries\n\n\n# Find the 25th percentile \ntwenty_fifth = salaries['Salary_USD'].quantile(0.25)\n\n# Save the median\nsalaries_median = salaries['Salary_USD'].median()\n\n# Gather the 75th percentile\nseventy_fifth = salaries['Salary_USD'].quantile(0.75)\n\nprint(twenty_fifth, salaries_median, seventy_fifth)\n\n60880.691999999995 97488.552 143225.1\n\n\n隆Parece que el rango intercuartil est谩 entre 60881 y 143225 d贸lares! 隆Ahora usemos estas variables para agregar una columna categ贸rica de salario en el DataFrame\n\n\n\nCategorizar los salarios\n隆Ahora es el momento de crear una nueva categor铆a! Utilizar谩s las variables twenty_fifth, salaries_median y seventy_fifth, que creaste en el ejercicio anterior, para dividir los salarios en diferentes etiquetas.\nEl resultado ser谩 una nueva columna llamada salary_level, que incorporar谩s a una visualizaci贸n para analizar el salario de los encuestados y en empresas de distintos tama帽os.\n\nInstrucciones\n\nCrea salaries_labels, una lista que contenga entry, mid, senior y exec.\n\n\n# Create salary labels\nsalary_labels = ['entry', 'mid', 'senior', 'exec']\n\n\nTermina salary_ranges, a帽adiendo el percentil 25, la mediana, el percentil 75 y el valor m谩s grande de Salary_USD\n\n\n# Create the salary ranges list\nsalary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries['Salary_USD'].max()]\n\n\nDivide Salary_USD en funci贸n de las etiquetas y rangos que hayas creado.\n\n\n# Create salary_level\nsalaries['salary_level'] = pd.cut(salaries['Salary_USD'], bins=salary_ranges, labels=salary_labels)\n\n\nUtiliza sns.countplot() para visualizar el reconteo de Company_Size, factrorizando las etiquetas de nivel salarial.\n\n\n# Plot the count of salary levels at companies of different sizes\nsns.countplot(data=salaries, x='Company_Size', hue='salary_level')\nplt.show()\n\n\n\n\n\n\n\n\nAl usar pd.cut() para dividir los datos num茅ricos en categor铆as, se puede ver que una gran proporci贸n de trabajadores en empresas peque帽as reciben salarios de nivel de entrada, mientras que m谩s personal en empresas medianas son recompensados con salarios de nivel senior. 隆Ahora vamos a ver c贸mo generar hip贸tesis a medida que se llega al final de la fase de EDA!",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>20</span> <span class='chapter-title'>Convertir el an谩lisis exploratorio en acci贸n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-hip贸tesis",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-hip贸tesis",
    "title": "Convertir el an谩lisis exploratorio en acci贸n",
    "section": "Generar hip贸tesis",
    "text": "Generar hip贸tesis\nGenerar hip贸tesis es una tarea fundamental para los cient铆ficos de datos.\nAl realizar EDA, la pregunta que debemos hacernos es 驴C贸mo sabemos que lo que estamos observando es verdadero?\nPor ejemplo:\n\nSi recopilamos nuevos datos sobre vuelos de un per铆odo de tiempo diferente 驴observar铆amos los mismos resultados?\nDetectar relaciones, diferencias y patrones:\n\nUsamos Prueba de hip贸tesis\n\nLa prueba de hip贸tesis requiere previo a la recolecci贸n de datos:\n\nGenerar una hip贸tesis o pregunta.\nUna decisi贸n en la se pueda usar una prueba estad铆stica\n\nData snooping\n\nLos an谩lisis de datos excesivos, la generaci贸n de m煤ltiples hip贸tesis y la ejecuci贸n de m煤ltiples pruebas estad铆sticas\n\nGeneraci贸n de Hip贸tesis\n\nSe realiza usando an谩lisis exploratorio de datos\n\nPr贸ximos pasos\n\nDise帽ar nuestro experimento.\nEnvuelve pasos como:\n\nElegir una muestra\nCalcular cu谩ntos puntos de datos necesitamos\nDecidir que prueba estad铆stica ejecutar.\n\n\n\n\nComparar salarios\n隆El an谩lisis exploratorio de datos es un paso crucial en la generaci贸n de hip贸tesis!\nSe te ha ocurrido una idea que te gustar铆a investigar: 驴los profesionales de los datos cobran m谩s en Estados Unidos que en Gran Breta帽a?\nTendr谩s que subconjuntar los datos en Employee_Location y elaborar un gr谩fico que muestre el salario medio entre los dos grupos.\n\nInstrucciones\n\nFiltra salaries donde Employee_Location es US o GB, guardando como usa_and_gb.\nUtiliza usa_and_gb para crear un gr谩fico de barras que visualice Salary_USD frete a Employee_Location.\n\n\n# Filter for employees in the US or GB\nusa_and_gb = salaries[salaries['Employee_Location'].isin(['US', 'GB'])]\n\n# Create a barplot of salaries by location\nsns.barplot(data=usa_and_gb, x='Employee_Location', y='Salary_USD')\nplt.show()\n\n\n\n\n\n\n\n\nAl subconfigurar los datos, pudiste comparar directamente los salarios entre EE.UU. y Gran Breta帽a. La visualizaci贸n sugiere que has generado una hip贸tesis que vale la pena investigar formalmente para determinar si existe una diferencia real o no.\n\n\n\nElegir una hip贸tesis\nHas visto c贸mo las visualizaciones pueden utilizarse para generar hip贸tesis, 隆lo que las convierte en una parte crucial del an谩lisis exploratorio de datos!\nEn este ejercicio, generar谩s un diagrama de barras para inspeccionar c贸mo difieren los salarios seg煤n el tama帽o de la empresa y la situaci贸n laboral.\nComo referencia, hay cuatro valores:\n\n\n\nValor\nSignificado\n\n\n\n\nCT\nContratista\n\n\nFL\nAut贸nomo\n\n\nPT\nA tiempo parcial\n\n\nFT\nA tiempo completo\n\n\n\n\nInstrucciones\n\nElabora un diagrama de barras comparando Salary_USD por Company_Size, factorizando Employment_Status.\n\n\n# Create a bar plot  of salary versus company size, factoring in employment status\nsns.barplot(data=salaries, x='Company_Size', y='Salary_USD', hue='Employment_Status')\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta 驴 Cu谩l es una hip贸tesis razonable que se puede generar a partir de esta trama?\n\nRespuestas Posibles\n\nPor t茅rmino medio, las peque帽as empresas pagan menos a los empleados a tiempo parcial que las grandes empresas.\nLos aut贸nomos ganan m谩s en las empresas medianas que en las peque帽as o grandes.\nPor t茅rmino medio, las grandes empresas pagan m谩s a los contratistas que las medianas.\nNo se puede generar ninguna hip贸tesis a partir de este gr谩fico.\n\nLos contratistas parecen se mejor pagados por las grandes empresas en promedio seg煤n los datos, 隆as铆 que esta es una hip贸tesis razonable!",
    "crumbs": [
      "An谩lisis Exploratorio de Datos",
      "<span class='chapter-number'>20</span> <span class='chapter-title'>Convertir el an谩lisis exploratorio en acci贸n</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/index.html",
    "href": "08_Muestreo_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\n Nivel: Intermedio\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nEl muestreo en Python es la piedra angular de la estad铆stica de inferencia y las pruebas de hip贸tesis. Es una poderosa habilidad utilizada en el an谩lisis de encuestas y el dise帽o experimental para sacar conclusiones sin encuestar a toda una poblaci贸n. En este curso de Muestreo en Python, descubrir谩s cu谩ndo utilizar el muestreo y c贸mo realizar tipos comunes de muestreo, desde el muestreo aleatorio simple hasta m茅todos m谩s complejos como el muestreo estratificado y por cl煤steres. Utilizando conjuntos de datos del mundo real, como valoraciones de caf茅, canciones de Spotify y bajas de empleados, aprender谩s a estimar estad铆sticas de poblaci贸n y a cuantificar la incertidumbre en tus estimaciones generando distribuciones de muestreo y distribuciones bootstrap.",
    "crumbs": [
      "Muestreo en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/index.html#m贸dulos-del-curso",
    "href": "08_Muestreo_en_python/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nIntroducci贸n al muestreo\nM茅todos de muestreo\nDistribuciones muestrales\nDistribuciones Bootstrap",
    "crumbs": [
      "Muestreo en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html",
    "title": "Introducci贸n al Muestreo",
    "section": "",
    "text": "Muestreo y estimaciones puntuales\nAprende qu茅 es el muestreo y por qu茅 es tan poderoso. Tambi茅n aprender谩s sobre los problemas causados por el muestreo de conveniencia y las diferencias entre la verdadera aleatoriedad y la pseudoaleatoriedad.\nLa t茅cnica de trabajar con un subconjunto de toda la poblaci贸n se le llama muestreo.\nLa muestra es el subconjunto de datos con el que estamos trabajando.\npts_vs_flavor_pop = coffee_ratings[[\"total_points\", \"flavor\"]]\npts_vs_flavor_samp = pts_vs_flavor_pop.sample(n=10)\nEl m茅todo .sample() de pandas devuelve un subconjunto aleatorio de filas. Establecer n en 10 significa que devuelve 10 filas aleatorias. En la muestra aparecen 10 muestras 煤nicas.\ncup_points_samp = coffe_ratings['total_cup_points'].sample(n=10)\nimport numpy as np\nnp.mean(pts_vs_flavor_pop['total_cup_points'])\nUna estimaci贸n puntual o estad铆stica de muestra, es un c谩lculo basado en el conjunto de datos de muestra.\nnp.mean(cup_points_samp)\npts_vs_flavor_pop['flavor'].mean()\npts_vs_flavor_samp['flavor'].mean()",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span> <span class='chapter-title'>Introducci贸n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-y-estimaciones-puntuales",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-y-estimaciones-puntuales",
    "title": "Introducci贸n al Muestreo",
    "section": "",
    "text": "Poblaci贸n vs Muestreo La poblaci贸n es el conjunto completo de datos que nos interesan.\n\nNo se refiere a personas.\nT铆picamente, no sabremos c贸mo es toda la poblaci贸n.\n\n\n\n\nCoffee rating dataset\n\n\nCada fila representa 1 caf茅.\nHay 1338 filas\nAl caf茅 se le asigna una puntuaci贸n de cero a cien, que se almacena en la columna total_cup_points.\nOtras columnas contienen informaci贸n contextual como la variedad y el pa铆s de origen.\nPuntuaciones entre 0 y 10 para atributos del caf茅 como el aroma y el cuerpo.\nNo contiene todos los caf茅s del mundo, por lo que no sabemos exactamente cu谩l es la poblaci贸n de caf茅s.\nHay suficientes para considerarla como la poblaci贸n de inter茅s.\n\nPoints vs.Flavor: Poblaci贸n\n\n\n\n\nPoints vs.Flavor: 10 filas de muestra\n\n\n\n\n\nMuestreo en Python para Series\n\nUse .sample() en pandas para DataFrames y Series.\n\n\n\n\n\nPar谩metros de Poblaci贸n & Puntos Estimados\nUn par谩metro de poblaci贸n es un c谩lculo realizado sobre el conjunto de datos de poblaci贸n.\n\n\n\n\n\n\n\nPuntos estimados con pandas\nTrabajar con pandas puede ser m谩s f谩cil que trabajar con Numpy. Estos c谩lculos de media se pueden realizar utilizando el m茅todo de pandas .mean()\n\n\n\n\n\n\nMotivos del muestreo\nEl muestreo es una t茅cnica importante en tu arsenal estad铆sico. Sin embargo, no siempre es adecuado: hay que saber cu谩ndo utilizarlo y cu谩ndo trabajar con todo el conjunto de datos.\n驴Cu谩l de los siguientes no es un buen escenario para utilizar el muestreo?\nRespuestas posibles\n\nTe han agregado un terabyte de datos sobre registros de errores del dispositivo de tu empresa.\nDeseas conocer los h谩bitos de viaje de todos los ciudadanos adultos paquistan铆es.\nHas terminado de recoger los datos de un peque帽o estudio sobre las medidas de las alas de 10 mariposas.\nHas estado trabajando para predecir la rotaci贸n de clientes en un proyecto de big data para tu empresa de marketing.\n\nDiez mariposas es un conjunto de datos peque帽o, por lo que el muestreo no es 煤til aqu铆.\n\n\nMuestreo simple con pandas\nA lo largo de este cap铆tulo , explorar谩s los datos de canciones de Spotify. Cada fila de este conjunto de datos de poblaci贸n representa una canci贸n, y hay m谩s de 40000 filas. Las columnas incluyen el nombre de la canci贸n, los artistas que la interpretaron, al a帽o de lanzamiento y atributos de la canci贸n como su duraci贸n, tempo y bailabilidad. Empezar谩s por fijarte en las duraciones.\nTu primera tarea es tomar una muestra del conjunto de datos de Spotify y comparar la duraci贸n media de la poblaci贸n con la de la muestra.\n\nimport pandas as pd\nruta = './data/spotify_2000_2020.feather'\nspotify_population = pd.read_feather(ruta)\nspotify_population.head()\n\n\n\n\n\n\n\n\nacousticness\nartists\ndanceability\nduration_ms\nduration_minutes\nenergy\nexplicit\nid\ninstrumentalness\nkey\nliveness\nloudness\nmode\nname\npopularity\nrelease_date\nspeechiness\ntempo\nvalence\nyear\n\n\n\n\n0\n0.97200\n['David Bauer']\n0.567\n313293.0\n5.221550\n0.227\n0.0\n0w0D8H1ubRerCXHWYJkinO\n0.601000\n10.0\n0.110\n-13.441\n1.0\nShout to the Lord\n47.0\n2000\n0.0290\n136.123\n0.0396\n2000.0\n\n\n1\n0.32100\n['Etta James']\n0.821\n360240.0\n6.004000\n0.418\n0.0\n4JVeqfE2tpi7Pv63LJZtPh\n0.000372\n9.0\n0.222\n-9.841\n0.0\nMiss You\n51.0\n2000-12-12\n0.0407\n117.382\n0.8030\n2000.0\n\n\n2\n0.00659\n['Quasimoto']\n0.706\n202507.0\n3.375117\n0.602\n1.0\n5pxtdhLAi0RTh1gNqhGMNA\n0.000138\n11.0\n0.400\n-8.306\n0.0\nReal Eyes\n44.0\n2000-06-13\n0.3420\n89.692\n0.4790\n2000.0\n\n\n3\n0.00390\n['Millencolin']\n0.368\n173360.0\n2.889333\n0.977\n0.0\n3jRsoe4Vkxa4BMYqGHX8L0\n0.000000\n11.0\n0.350\n-2.757\n0.0\nPenguins & Polarbears\n52.0\n2000-02-22\n0.1270\n165.889\n0.5480\n2000.0\n\n\n4\n0.12200\n['Steve Chou']\n0.501\n344200.0\n5.736667\n0.511\n0.0\n4mronxcllhfyhBRqyZi8kU\n0.000000\n7.0\n0.279\n-9.836\n0.0\n榛\n53.0\n2000-12-25\n0.0291\n78.045\n0.1130\n2000.0\n\n\n\n\n\n\n\n\nInstrucciones\n\nMuestra 1000 filas de spotify_population, asign谩ndolas a spotify_sample.\n\n\n# Sample 1000 rows from spotify_population\nspotify_sample = spotify_population.sample(n=1000)\n\n# print sample\nprint(spotify_sample)\n\n       acousticness                                            artists  \\\n24420       0.00205                                      ['Bleachers']   \n8211        0.00223                                    ['Tame Impala']   \n27654       0.03400                                            ['Sia']   \n41072       0.00254                                          ['Ghost']   \n2053        0.46600  ['YoungBoy Never Broke Again', 'Sherhonda Gaul...   \n...             ...                                                ...   \n23516       0.22500                                    ['KT Tunstall']   \n16026       0.11900                               ['Childish Gambino']   \n18643       0.97300                                         ['O.A.S.']   \n13041       0.99100             ['Scott Joplin', 'Alexander Peskanov']   \n15041       0.70500                                ['Black Eyed Peas']   \n\n       danceability  duration_ms  duration_minutes  energy  explicit  \\\n24420         0.421     188867.0          3.147783  0.7900       0.0   \n8211          0.546     292267.0          4.871117  0.8590       0.0   \n27654         0.544     274933.0          4.582217  0.6300       0.0   \n41072         0.555     362093.0          6.034883  0.7980       0.0   \n2053          0.579     187141.0          3.119017  0.5650       1.0   \n...             ...          ...               ...     ...       ...   \n23516         0.587     201707.0          3.361783  0.7670       0.0   \n16026         0.676     234215.0          3.903583  0.4460       0.0   \n18643         0.111     206997.0          3.449950  0.0597       0.0   \n13041         0.406     189907.0          3.165117  0.2260       0.0   \n15041         0.853     174907.0          2.915117  0.3920       0.0   \n\n                           id  instrumentalness   key  liveness  loudness  \\\n24420  5L95vS64rG1YMIFm1hLjyZ          0.000309  10.0    0.1480    -6.227   \n8211   2drEUEg0TYQR6dDEHkpuPE          0.000947   1.0    0.0529    -5.966   \n27654  6hrgeEo1WQOHVeF8QMv68S          0.573000   0.0    0.0961    -7.523   \n41072  3ZXZ9RMsznqgyHnyq0K5FL          0.000015   3.0    0.1710    -5.658   \n2053   6vXJljkoTUWjPXFRfuBbgZ          0.000000  11.0    0.2260    -6.901   \n...                       ...               ...   ...       ...       ...   \n23516  5p9XWUdvbUzmPCukOmwoU3          0.000000   0.0    0.1120    -5.713   \n16026  1rfJQpYr0clcyXssjQjk4T          0.000000   6.0    0.1120    -7.153   \n18643  1I217X8W4dL6niEzXOf2nQ          0.964000   0.0    0.1050   -28.951   \n13041  4AE032Y0x1WPOi5CsmggnU          0.882000   8.0    0.2450   -22.866   \n15041  48FtJnNrSYrxZOh6Ktf9Zf          0.002830   4.0    0.5960    -5.819   \n\n       mode                                        name  popularity  \\\n24420   1.0                               Rollercoaster        66.0   \n8211    1.0                                    Patience        66.0   \n27654   1.0                                  Breathe Me        52.0   \n41072   1.0                                      Cirice        56.0   \n2053    1.0  Bout My Business (feat. Sherhonda Gaulden)        63.0   \n...     ...                                         ...         ...   \n23516   1.0                              Suddenly I See        68.0   \n16026   0.0                                     V. 3005        48.0   \n18643   1.0                                Jupiter Song        60.0   \n13041   1.0                              Maple Leaf Rag        44.0   \n15041   0.0                                The Apl Song        41.0   \n\n      release_date  speechiness    tempo  valence    year  \n24420   2014-07-14       0.0538  162.024    0.279  2014.0  \n8211    2019-03-22       0.0306   99.965    0.645  2019.0  \n27654   2005-01-01       0.0335  120.064    0.202  2005.0  \n41072   2015-01-01       0.0279   89.987    0.284  2015.0  \n2053    2020-04-24       0.4180   83.973    0.631  2020.0  \n...            ...          ...      ...      ...     ...  \n23516   2005-01-01       0.0449  100.380    0.664  2005.0  \n16026   2013-12-10       0.3290   82.912    0.655  2013.0  \n18643   2019-11-08       0.0414   73.632    0.036  2019.0  \n13041   2004-07-28       0.0477  116.267    0.937  2004.0  \n15041         2003       0.1750   89.028    0.719  2003.0  \n\n[1000 rows x 20 columns]\n\n\n\n\n\n\nCalcula la duraci贸n media en minutos de spotify_population utilizando pandas.\nCalcula la duraci贸n media en minutos de spotify_sample utilizando pandas.\n\n\n# Calculate the mean duration in mins from spotify_population\nmean_dur_pop = spotify_population['duration_minutes'].mean()\n\n# Calculate the mean duration in mins from spotify_sample\nmean_dur_sample = spotify_sample['duration_minutes'].mean()\n\n# print the means\nprint(mean_dur_pop)\nprint(mean_dur_sample)\n\n3.8521519140900073\n3.8374306\n\n\nSe observa que la duraci贸n media de las canciones en la muestra es similar, pero no id茅ntica a la duraci贸n media de las canciones en toda la poblacici贸n.\n\n\n\nMuestreos y c谩lculos sencillos con Numpy\nTambi茅n puedes utilizar numpy para calcular par谩metros o estad铆sticas partir de una lista o de la serie pandas.\n\n\nInstrucciones\n\n\n\n\nCrea una serie pandas, loudness_pop, subdividiendo la columna loudness de spotify_population.\nMuestra loudness_pop para obtener 100 valores aleatorios, asign谩ndolos a loudness_samp.\n\n\n# Create a pandas Series from de loudness column of spotify_population\nloudness_pop = spotify_population['loudness']\n\n# Sample 100 values of loudness_pop\nloudness_samp = loudness_pop.sample(n=100)\n\nprint(loudness_samp)\n\n12196   -5.811\n12266   -6.305\n18808   -9.401\n26149   -8.207\n23917   -8.401\n         ...  \n9844    -6.698\n31465   -4.029\n11254   -3.772\n36897   -8.229\n31000   -4.378\nName: loudness, Length: 100, dtype: float64\n\n\n\n\n\n\nCalcula la media de loudness_pop utilizando numpy.\nCalcula la media de loudness_samp utilizando numpy.\n\n\nimport numpy as np\n\n# Calculate the mean of loudness_pop\nmean_loudness_pop = np.mean(loudness_pop)\n\n# Calculate the mean of loudness_samp\nmean_loudness_samp = np.mean(loudness_samp)\n\nprint(mean_loudness_pop)\nprint(mean_loudness_samp)\n\n-7.366856851353947\n-7.606940000000002\n\n\nNuevamente, observe que el valor calculado (la media) es cercano pero no id茅ntico en cada caso.",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span> <span class='chapter-title'>Introducci贸n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-de-conveniencia",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-de-conveniencia",
    "title": "Introducci贸n al Muestreo",
    "section": "Muestreo de conveniencia",
    "text": "Muestreo de conveniencia\n\n驴Son generalizables las conclusiones de la muestra?\n\n\n驴Son generalizables estos resultados?",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span> <span class='chapter-title'>Introducci贸n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#generaci贸n-de-n煤meros-pseudoaleatorios",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#generaci贸n-de-n煤meros-pseudoaleatorios",
    "title": "Introducci贸n al Muestreo",
    "section": "Generaci贸n de n煤meros pseudoaleatorios",
    "text": "Generaci贸n de n煤meros pseudoaleatorios\n\nGenerar n煤meros aleatorios\n\n\nComprender los valores de iniciaclizaci贸n aleatorios",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span> <span class='chapter-title'>Introducci贸n al Muestreo</span>"
    ]
  },
  {
    "objectID": "09_Pruebas_de_hipotesis_en_python/index.html",
    "href": "09_Pruebas_de_hipotesis_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci贸n\n Nivel: Intermedio\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nLas pruebas de hip贸tesis te permiten responder a preguntas sobre tus conjuntos de datos de forma estad铆sticamente rigurosa. En este curso, desarrollar谩s tus competencias anal铆ticas en Python aprendiendo c贸mo y cu谩ndo utilizar pruebas comunes como las pruebas t, las pruebas de proporci贸n y las pruebas 虏. Trabajando con datos del mundo real, incluidos datos de cadena de suministro y comentarios de usuarios de Stack Overflow sobre env铆os de suministros m茅dicos, comprender谩s en profundidad c贸mo funcionan estas pruebas y los supuestos clave que las sustentan. Tambi茅n descubrir谩s c贸mo pueden utilizarse pruebas no param茅tricas para superar las limitaciones de las pruebas de hip贸tesis tradicionales.",
    "crumbs": [
      "Pruebas de Hip贸tesis en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "09_Pruebas_de_hipotesis_en_python/index.html#m贸dulos-del-curso",
    "href": "09_Pruebas_de_hipotesis_en_python/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nFundamentos de las pruebas de hip贸tesis\nPruebas de dos muestras y ANOVA\nPruebas de proporci贸n\nPruebas no param茅tricas",
    "crumbs": [
      "Pruebas de Hip贸tesis en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html",
    "href": "01_Introduccion_a_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\n Nivel: Principiante\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nPython es un lenguaje de programaci贸n de uso general cada vez m谩s popular para la ciencia de datos. Empresas de todo el mundo utilizan Python para extraer informaci贸n de sus datos y obtener una ventaja competitiva. A diferencia de otros tutoriales de Python, este curso se centra en Python espec铆ficamente para la ciencia de datos. En nuestro curso de Introducci贸n a Python aprender谩s potentes formas de almacenar y manipular datos y conocer谩s 煤tiles herramientas de ciencias de datos para empezar a realizar tus propios an谩lisis.",
    "crumbs": [
      "Introducci贸n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html#lo-que-aprender谩s",
    "href": "01_Introduccion_a_python/index.html#lo-que-aprender谩s",
    "title": "Bienvenida",
    "section": "Lo que aprender谩s",
    "text": "Lo que aprender谩s\n\nIdentificar los tipos de datos de Python (int, float, str, bool) y utilizarlos en c谩lculos y variables.\nReconocer c贸mo crear, subconjuntar y modificar listas, inclu铆das las listas anidadas.\nDiferenciar entre funciones , m茅todos y paquetes, y aplicarlos para resolver tareas.\nIdentificar los arreglos Numpy, distinguirlas de las listas y evaluar su funci贸n en el an谩lisis de datos.\nEval煤a las herramientas estad铆sticas de Numpy (media, mediana, desviaci贸n est谩ndar, correlaci贸n) para obtener informaci贸n sobre los datos.",
    "crumbs": [
      "Introducci贸n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html#m贸dulos-del-curso",
    "href": "01_Introduccion_a_python/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nConceptos B谩sicos de Python\nListas Python\nFunciones y Paquetes\nNumpy",
    "crumbs": [
      "Introducci贸n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html",
    "href": "02_Python_intermedio/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\n Nivel: Principiante\n Duraci贸n estimada: 4 horas\n Incluye c贸digo, visualizaciones y ejercicios\nAprender Python es crucial para cualquier aspirante a profesional de ciencia de datos. Aprende a visualizar datos reales con las funciones de Matplotlib y familizarizarte con estructuras de datos como el diccionario y el DataFrame de pandas. Este curso intermedio de 4 horas te ayudar谩 a mejorar tus conocimientos de Python y a explorar nuevas aplicaciones y funciones de Python que amplien tu repertorio y te ayuden a trabajar con m谩s eficacia.\nDescubrir谩s c贸mo los diccionarios ofrecen una alternativa a las listas de Python, y por qu茅 el marco de datos de pandas es la forma m谩s popular de trabajar con datos tabulares. En el segundo cap铆tulo de este curso, descubrir谩s c贸mo puedes crear y manipular conjuntos de datos, y c贸mo acceder a ellos utilizando estas estructuras. La pr谩ctica a lo largo del curso aumentar谩 tu confianza en cada 谩rea.\nA medida que avances, estudiar谩s la l贸gica, el flujo de control, el filtrado y los bucles. Estas funciones sirven para controlar la toma de decisiones en los programas Python y te ayudan a realizar m谩s operaciones con tus datos, incluidas las declaraciones repetidas. Terminar谩s el curso aplicando todas tus nuevas habilidades con estad铆sticas de hacker para calcular tus posibilidades de ganar una apuesta.\nUna vez que hayas completado todos los cap铆tulos, estar谩s listo para aplicar tus nuevas habilidades en tu trabajo, nueva carrera o proyecto personal, y estar谩s preparado para pasar a un aprendizaje m谩s avanzado de Python.",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html#lo-que-aprender谩s",
    "href": "02_Python_intermedio/index.html#lo-que-aprender谩s",
    "title": "Bienvenida",
    "section": "Lo que aprender谩s",
    "text": "Lo que aprender谩s\n\nIdentificar y aplicar funciones de Matplotlib para crear gr谩ficos de l铆neas, dispersi贸n e histogramas.\nAprende a crear, actualizar y manipular diccionarios y DataFrames de pandas.\nDistinguir entre operadores de comparaci贸n, booleanos y l贸gicos, y evaluar su uso en el filtrado de datos.\nIdentifica el uso de blucles (for, while) y apl铆calos para iterar sobre listas, diccionarios, arreglos Numpy y DataFrame de pandas.\nEval煤a la generaci贸n de n煤meros aleatorios y las simulaciones (paseos aleatorios, distribuciones) para analizar probabilidades y resultados.",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html#m贸dulos-del-curso",
    "href": "02_Python_intermedio/index.html#m贸dulos-del-curso",
    "title": "Bienvenida",
    "section": "M贸dulos del curso",
    "text": "M贸dulos del curso\n\nMatplotlib\nDiccionarios y Pandas\nL贸gica, Flujo de Control y Filtrado\nBucles\nCaso Pr谩ctico: Estad铆stica de hacker",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  }
]
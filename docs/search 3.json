[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Anal√≠sta de Datos en Python",
    "section": "",
    "text": "Bienvenida",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.html#descripci√≥n-del-programa",
    "href": "index.html#descripci√≥n-del-programa",
    "title": "Anal√≠sta de Datos en Python",
    "section": "Descripci√≥n del programa",
    "text": "Descripci√≥n del programa\nDesarrolla tus habilidades de an√°nlisis de datos en Python. Adquiere las habilidades de analista de datos para manipular, analizar y visualizar datos. No necesitas experiencia en programac√≥n.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html",
    "href": "01_Introduccion_a_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\nüìä Nivel: Principiante\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nPython es un lenguaje de programaci√≥n de uso general cada vez m√°s popular para la ciencia de datos. Empresas de todo el mundo utilizan Python para extraer informaci√≥n de sus datos y obtener una ventaja competitiva. A diferencia de otros tutoriales de Python, este curso se centra en Python espec√≠ficamente para la ciencia de datos. En nuestro curso de Introducci√≥n a Python aprender√°s potentes formas de almacenar y manipular datos y conocer√°s √∫tiles herramientas de ciencias de datos para empezar a realizar tus propios an√°lisis.",
    "crumbs": [
      "Introducci√≥n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html#lo-que-aprender√°s",
    "href": "01_Introduccion_a_python/index.html#lo-que-aprender√°s",
    "title": "Bienvenida",
    "section": "Lo que aprender√°s",
    "text": "Lo que aprender√°s\n\nIdentificar los tipos de datos de Python (int, float, str, bool) y utilizarlos en c√°lculos y variables.\nReconocer c√≥mo crear, subconjuntar y modificar listas, inclu√≠das las listas anidadas.\nDiferenciar entre funciones , m√©todos y paquetes, y aplicarlos para resolver tareas.\nIdentificar los arreglos Numpy, distinguirlas de las listas y evaluar su funci√≥n en el an√°lisis de datos.\nEval√∫a las herramientas estad√≠sticas de Numpy (media, mediana, desviaci√≥n est√°ndar, correlaci√≥n) para obtener informaci√≥n sobre los datos.",
    "crumbs": [
      "Introducci√≥n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "01_Introduccion_a_python/index.html#m√≥dulos-del-curso",
    "href": "01_Introduccion_a_python/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nConceptos B√°sicos de Python\nListas Python\nFunciones y Paquetes\nNumpy",
    "crumbs": [
      "Introducci√≥n a Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html",
    "href": "02_Python_intermedio/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\nüìä Nivel: Principiante\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nAprender Python es crucial para cualquier aspirante a profesional de ciencia de datos. Aprende a visualizar datos reales con las funciones de Matplotlib y familizarizarte con estructuras de datos como el diccionario y el DataFrame de pandas. Este curso intermedio de 4 horas te ayudar√° a mejorar tus conocimientos de Python y a explorar nuevas aplicaciones y funciones de Python que amplien tu repertorio y te ayuden a trabajar con m√°s eficacia.\nDescubrir√°s c√≥mo los diccionarios ofrecen una alternativa a las listas de Python, y por qu√© el marco de datos de pandas es la forma m√°s popular de trabajar con datos tabulares. En el segundo cap√≠tulo de este curso, descubrir√°s c√≥mo puedes crear y manipular conjuntos de datos, y c√≥mo acceder a ellos utilizando estas estructuras. La pr√°ctica a lo largo del curso aumentar√° tu confianza en cada √°rea.\nA medida que avances, estudiar√°s la l√≥gica, el flujo de control, el filtrado y los bucles. Estas funciones sirven para controlar la toma de decisiones en los programas Python y te ayudan a realizar m√°s operaciones con tus datos, incluidas las declaraciones repetidas. Terminar√°s el curso aplicando todas tus nuevas habilidades con estad√≠sticas de hacker para calcular tus posibilidades de ganar una apuesta.\nUna vez que hayas completado todos los cap√≠tulos, estar√°s listo para aplicar tus nuevas habilidades en tu trabajo, nueva carrera o proyecto personal, y estar√°s preparado para pasar a un aprendizaje m√°s avanzado de Python.",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html#lo-que-aprender√°s",
    "href": "02_Python_intermedio/index.html#lo-que-aprender√°s",
    "title": "Bienvenida",
    "section": "Lo que aprender√°s",
    "text": "Lo que aprender√°s\n\nIdentificar y aplicar funciones de Matplotlib para crear gr√°ficos de l√≠neas, dispersi√≥n e histogramas.\nAprende a crear, actualizar y manipular diccionarios y DataFrames de pandas.\nDistinguir entre operadores de comparaci√≥n, booleanos y l√≥gicos, y evaluar su uso en el filtrado de datos.\nIdentifica el uso de blucles (for, while) y apl√≠calos para iterar sobre listas, diccionarios, arreglos Numpy y DataFrame de pandas.\nEval√∫a la generaci√≥n de n√∫meros aleatorios y las simulaciones (paseos aleatorios, distribuciones) para analizar probabilidades y resultados.",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  },
  {
    "objectID": "02_Python_intermedio/index.html#m√≥dulos-del-curso",
    "href": "02_Python_intermedio/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nMatplotlib\nDiccionarios y Pandas\nL√≥gica, Flujo de Control y Filtrado\nBucles\nCaso Pr√°ctico: Estad√≠stica de hacker",
    "crumbs": [
      "Python Intermedio",
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/index.html",
    "href": "03_Manipulacion_de_datos_con_pandas/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripcion\nüìä Nivel: Principiante\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nPandas es la biblioteca de Python m√°s popular del mundo, utilizada para todo, desde la manipulaci√≥n de datos hasta el an√°lisis de datos. En este curso, aprender√°s a manipular los DataFrames, mientras extraes, filtras y transformas conjuntos de datos del mundo real para su an√°lisis. Utilizando pandas explorar√°s todos los conceptos b√°sicos de la ciencia de datos. Utilizando datos del mundo real, como cifras de ventas de Walmart y series temporales de temperatura global, aprender√°s a importar, limpiar, calcular estad√≠sticas y crear visualizaciones, ¬°utilizando pandas para aumentar la potencia de Python!",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/index.html#m√≥dulos-del-curso",
    "href": "03_Manipulacion_de_datos_con_pandas/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nTransformaci√≥n de DataFrames\nAgregar DataFrames\nSegmentar e indexar DataFrames\nCrear y visualizar DataFrames",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/01_Transformacion_de_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/01_Transformacion_de_dataframes.html",
    "title": "Transformaci√≥n de DataFrames",
    "section": "",
    "text": "Vamos a tratar los fundamentos de pandas. Aprende a inspeccionar los DataFrames y a realizar manipulaciones b√°sicas, como ordenar filas, hacer subconjuntos y a√±adir nuevas columnas.",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Transformaci√≥n de DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/02_Agregar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/02_Agregar_dataframes.html",
    "title": "Agregar DataFrames",
    "section": "",
    "text": "En este cap√≠tulo, calcular√°s estad√≠sticas sumarias en columnas del DataFrame y dominar√°s las estad√≠sticas sumarias agrupadas y las tablas din√°micas.",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Agregar DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/03_Segmentar_e_indexar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/03_Segmentar_e_indexar_dataframes.html",
    "title": "Segmentar e indexar DataFrames",
    "section": "",
    "text": "Los √≠ndices son nombres de filas y columnas sobrecargados. Aprende c√≥mo pueden combinarse con la segmentaci√≥n para obtener un potente subconjunto del DataFrame.",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Segmentar e indexar DataFrames</span>"
    ]
  },
  {
    "objectID": "03_Manipulacion_de_datos_con_pandas/04_Crear_y_visualizar_dataframes.html",
    "href": "03_Manipulacion_de_datos_con_pandas/04_Crear_y_visualizar_dataframes.html",
    "title": "Crear y visualizar DataFrames",
    "section": "",
    "text": "Aprende a visualizar el contenido de tus DataFrames, a tratar los valores de datos que faltan y a importar y exportar datos a archivos CSV.",
    "crumbs": [
      "Manipulaci√≥n de Datos con Pandas",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Crear y visualizar DataFrames</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html",
    "href": "04_Unir_datos_con_pandas/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nüìä Nivel: Intermedio\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nSer capaz de combinar y trabajar con m√∫ltiples conjuntos de datos es una habilidad esencial para cualquier aspirante a cient√≠fico de datos. pandas es una piedra angular crucial del ecosistema de ciencia de datos de Python, y Stack Overflow registra 5 millones de visitas a preguntas sobre pandas. Aprende a manejar m√∫ltiples DataFrames combin√°ndolos, organiz√°ndolos, uni√©ndolos y remodel√°ndolos mediante pandas. Trabajar√°s con conjuntos de datos del Banco Mundial y de la ciudad de Chicago. Terminar√°s el curso con un s√≥lido conjunto de habilidades para unir datos en pandas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html#m√≥dulos-del-curso",
    "href": "04_Unir_datos_con_pandas/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nConceptos b√°sicos de la fusi√≥n de datos\nFusionar tablas con distintos tipos de uni√≥n\nFusi√≥n y concatenaci√≥n avanzadas\nFusionar datos ordenados y series temporales",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/index.html#datasets",
    "href": "04_Unir_datos_con_pandas/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:",
    "crumbs": [
      "Unir Datos con Pandas",
      "Bienvenida"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html",
    "title": "Conceptos B√°sicos de la fusi√≥n de datos",
    "section": "",
    "text": "Uni√≥n interna\nAprende a fusionar datos dispares mediante uniones internas. Combinando informaci√≥n de m√∫ltiples fuentes, descubrir√°s perspectivas convincentes que antes pod√≠an estar ocultas. Tambi√©n aprender√°s c√≥mo la relaci√≥n entre esas fuentes, de uno a uno o de uno a muchos, puede afectar a tu resultado.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Conceptos B√°sicos de la fusi√≥n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#uni√≥n-interna",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#uni√≥n-interna",
    "title": "Conceptos B√°sicos de la fusi√≥n de datos",
    "section": "",
    "text": "Qu√© columna elegiremos para fusionar?\nChicago proporciona una lista de propietarios de taxis y veh√≠culos con licencia para operar en la ciudad, por seguridad p√∫blica. Tu objetivo es unir dos tablas. Una tabla se llama taxi_owners y contiene informaci√≥n sobre los propietarios de las empresas de taxis, mientras que la otra se Ô£øllama taxi_vehe incluye informaci√≥n sobre cada veh√≠culÔ£øo de taxi.\n\nimport pandas as pd\n\n\ntaxi_owners = pd.read_pickle('./data/taxi_owners.p')\ntaxi_owners.head()\n\n\n\n\n\n\n\n\nrid\nvid\nowner\naddress\nzip\n\n\n\n\n0\nT6285\n6285\nAGEAN TAXI LLC\n4536 N. ELSTON AVE.\n60630\n\n\n1\nT4862\n4862\nMANGIB CORP.\n5717 N. WASHTENAW AVE.\n60659\n\n\n2\nT1495\n1495\nFUNRIDE, INC.\n3351 W. ADDISON ST.\n60618\n\n\n3\nT4231\n4231\nALQUSH CORP.\n6611 N. CAMPBELL AVE.\n60645\n\n\n4\nT5971\n5971\nEUNIFFORD INC.\n3351 W. ADDISON ST.\n60618\n\n\n\n\n\n\n\n\ntaxi_veh = pd.read_pickle('./data/taxi_vehicles.p')\ntaxi_veh.head()\n\n\n\n\n\n\n\n\nvid\nmake\nmodel\nyear\nfuel_type\nowner\n\n\n\n\n0\n2767\nTOYOTA\nCAMRY\n2013\nHYBRID\nSEYED M. BADRI\n\n\n1\n1411\nTOYOTA\nRAV4\n2017\nHYBRID\nDESZY CORP.\n\n\n2\n6500\nNISSAN\nSENTRA\n2019\nGASOLINE\nAGAPH CAB CORP\n\n\n3\n2746\nTOYOTA\nCAMRY\n2013\nHYBRID\nMIDWEST CAB CO, INC\n\n\n4\n5922\nTOYOTA\nCAMRY\n2013\nHYBRID\nSUMETTI CAB CO\n\n\n\n\n\n\n\n\nInstrucciones:\nElige una columna que utilizar√≠as para fusionar las dos tablas utilizando el m√©todo .merge().\nRespuestas posibles\n\non=‚Äòrid‚Äô\non=‚Äòvid‚Äô\non=‚Äòyear‚Äô\non=‚Äòzip‚Äô\n\n\n\n\nTu primera uni√≥n interna\nTe han encargado que averig√ºes cu√°les son los tipos de combustibles m√°s utlizados en los taxis de Chicago. Para completar el an√°lisis, tienes que fusionar las tablas taxi_owners y taxi_veh en la columna vid. A continuaci√≥n, puedes utilizar la tabla combinada junto con el m√©todo .values_counts() para encontrar el fuel_type m√°s com√∫n.\n\nInstrucciones:\n\nFusiona taxi_owners con taxi_veh en la columna vid y guarda el resultado en taxi_own_veh.\n\n\n# Merge the taxi_owners and taxi_veh tables\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid')\ntaxi_own_veh.head()\n\n# Print the column names of taxi_own_veh\nprint(taxi_own_veh.columns)\n\nIndex(['rid', 'vid', 'owner_x', 'address', 'zip', 'make', 'model', 'year',\n       'fuel_type', 'owner_y'],\n      dtype='object')\n\n\n\nEstablece los sufijos izquierdo y derecho de la tabla para las columnas solapadas de la fusi√≥n en _own y _veh, respectivamente.\n\n\n# Merge the taxi_owners and taxi_veh tables setting a suffix\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\ntaxi_own_veh.head()\n\n# Print the column names of taxi_own_veh\nprint(taxi_own_veh.columns)\n\nIndex(['rid', 'vid', 'owner_own', 'address', 'zip', 'make', 'model', 'year',\n       'fuel_type', 'owner_veh'],\n      dtype='object')\n\n\n\nSelecciona la columna fuel_type de taxi_own_veh e imprime value_counts() para encontrar los fuel_type m√°s utilizados.\n\n\n# Merge the taxi_owners and taxi_veh tables setting a suffix\ntaxi_own_veh = taxi_owners.merge(taxi_veh, on='vid', suffixes=('_own', '_veh'))\n\n# Print the value_counts to find the most popular fuel_type\nprint(taxi_own_veh['fuel_type'].value_counts())\n\nfuel_type\nHYBRID                    2792\nGASOLINE                   611\nFLEX FUEL                   89\nCOMPRESSED NATURAL GAS      27\nName: count, dtype: int64\n\n\n\n\n\nUniones internas y n√∫mero de filas devueltas\nTodas las fusiones que has estudiado hasta ahora se llaman uniones internas. Es necesario comprender que las uniones internas solo devuelven las filas con valores coincidentes en ambas tablas. Explorar√°s esto m√°s a fondo revisando la fusi√≥n entre las tablas wards y census, y compar√°ndola despu√©s con fusiones de copias de estas tablas ligeramente alteradas, denominadas wards_altered y census_altered. La primera fila de la columna wards se ha modificado en las tablas alteradas. Examinar√°s c√≥mo afecta esto a la fusi√≥n entre ellos.\n\nwards = pd.read_pickle('./data/ward.p')\nwards.head()\n\n\n\n\n\n\n\n\nward\nalderman\naddress\nzip\n\n\n\n\n0\n1\nProco \"Joe\" Moreno\n2058 NORTH WESTERN AVENUE\n60647\n\n\n1\n2\nBrian Hopkins\n1400 NORTH ASHLAND AVENUE\n60622\n\n\n2\n3\nPat Dowell\n5046 SOUTH STATE STREET\n60609\n\n\n3\n4\nWilliam D. Burns\n435 EAST 35TH STREET, 1ST FLOOR\n60616\n\n\n4\n5\nLeslie A. Hairston\n2325 EAST 71ST STREET\n60649\n\n\n\n\n\n\n\n\ncensus = pd.read_pickle('./data/census.p')\ncensus.head()\n\n\n\n\n\n\n\n\nward\npop_2000\npop_2010\nchange\naddress\nzip\n\n\n\n\n0\n1\n52951\n56149\n6%\n2765 WEST SAINT MARY STREET\n60647\n\n\n1\n2\n54361\n55805\n3%\nWM WASTE MANAGEMENT 1500\n60622\n\n\n2\n3\n40385\n53039\n31%\n17 EAST 38TH STREET\n60653\n\n\n3\n4\n51953\n54589\n5%\n31ST ST HARBOR BUILDING LAKEFRONT TRAIL\n60653\n\n\n4\n5\n55302\n51455\n-7%\nJACKSON PARK LAGOON SOUTH CORNELL DRIVE\n60637\n\n\n\n\n\n\n\n\nwards_altered = wards.copy()\nwards_altered.loc[0, 'ward'] = 61\nwards_altered.head()\n\n\n\n\n\n\n\n\nward\nalderman\naddress\nzip\n\n\n\n\n0\n61\nProco \"Joe\" Moreno\n2058 NORTH WESTERN AVENUE\n60647\n\n\n1\n2\nBrian Hopkins\n1400 NORTH ASHLAND AVENUE\n60622\n\n\n2\n3\nPat Dowell\n5046 SOUTH STATE STREET\n60609\n\n\n3\n4\nWilliam D. Burns\n435 EAST 35TH STREET, 1ST FLOOR\n60616\n\n\n4\n5\nLeslie A. Hairston\n2325 EAST 71ST STREET\n60649\n\n\n\n\n\n\n\n\ncensus_altered = census.copy()\ncensus_altered.loc[0, 'ward'] = None\ncensus_altered.head()\n\n\n\n\n\n\n\n\nward\npop_2000\npop_2010\nchange\naddress\nzip\n\n\n\n\n0\nNone\n52951\n56149\n6%\n2765 WEST SAINT MARY STREET\n60647\n\n\n1\n2\n54361\n55805\n3%\nWM WASTE MANAGEMENT 1500\n60622\n\n\n2\n3\n40385\n53039\n31%\n17 EAST 38TH STREET\n60653\n\n\n3\n4\n51953\n54589\n5%\n31ST ST HARBOR BUILDING LAKEFRONT TRAIL\n60653\n\n\n4\n5\n55302\n51455\n-7%\nJACKSON PARK LAGOON SOUTH CORNELL DRIVE\n60637\n\n\n\n\n\n\n\n\nInstrucciones:\n\nFusiona wards y census en la columna ward y guarda el resultado en ward_census.\n\n\n# Merge the wards and census tables on the ward column\nward_census = wards.merge(census, on='ward')\n\n# Print the shape of wards_census\nprint(f'ward_census table shape: {ward_census.shape}')\n\nward_census table shape: (50, 9)\n\n\n\nFusiona las tablas merge_altered y census en la columna ward y observa la diferencia en las filas devueltas.\n\n\n# Print the first few rows of the wards_altered table to view the change\nprint(wards_altered[['ward']].head())\n\n# Merge the wards_altered and census tables on the ward column\nwards_altered_census =  wards_altered.merge(census, on='ward')\n\n# Print the shape of wards_altered_census\nprint(f'wards_altered_census table shape: {wards_altered_census.shape}')\n\n  ward\n0   61\n1    2\n2    3\n3    4\n4    5\nwards_altered_census table shape: (49, 9)\n\n\n\nFusiona las tablas wards y census_altered en la columna ward y observa la diferencia en las filas devueltas.\n\n\n# Print the first few rows of the wards_altered table to view the change\nprint(census_altered[['ward']].head())\n\n# Merge the wards_altered and census tables on the ward column\nwards_altered_census =  wards.merge(census_altered, on='ward')\n\n# Print the shape of wards_altered_census\nprint(f'wards_altered_census table shape: {wards_altered_census.shape}')\n\n   ward\n0  None\n1     2\n2     3\n3     4\n4     5\nwards_altered_census table shape: (49, 9)\n\n\nEn el paso 1, el .merge() devolvi√≥ una tabla con el mismo n√∫mero de filas que la tabla original wards. Sin embargo, en los pasos 2 y 3, al usar las tablas alteradas con la primera fila alterada de la columna ward, el n√∫mero de filas devueltas fue menor. No hab√≠a un valor coincidente en la columna ward de la otra tabla. Recuerda que .merge() solo devuelve filas donde los valores coinciden en ambas tablas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Conceptos B√°sicos de la fusi√≥n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#relaciones-de-uno-a-muchos",
    "href": "04_Unir_datos_con_pandas/01_Conceptos_basicos_de_la_fusion_de_datos.html#relaciones-de-uno-a-muchos",
    "title": "Conceptos B√°sicos de la fusi√≥n de datos",
    "section": "Relaciones de uno a muchos",
    "text": "Relaciones de uno a muchos\nEn una relaci√≥n de uno a muchos cada fila de la tabla izquierda esta relacionada con una o varias filas de la tabla derecha.\nA continuaci√≥n se muestran algunos ejemplos de relaci√≥n uno a uno y relaci√≥n uno a muchos:\n\n\n\n\n\n\n\nUno a uno\nUno a muchos\n\n\n\n\nLa relaci√≥n entre products y inventory\nLa relaci√≥n entre products y orders\n\n\nLa relaci√≥n entre customery cust_tax_info\nLa relaci√≥n entre customersy orders\n\n\n\n\nFusi√≥n de uno a muchos\nUna empresa puede tener uno o varios propietarios. En este ejercicio, seguir√°s adquiriendo experiencia con las uniones de uno a muchos fusionando una tabla de propietarios de empresas, llamada biz_owners, con la tabla licenses. Recuerda de la lecci√≥n de video que, con una relaci√≥n de uno a muchos, una fila de la tabla izquierda puede repetirse si est√° relacionada con varias filas de la tabla de la derecha. En esta lecci√≥n, profundizar√°s en este tema averiguando cu√°l es el t√≠tulo de propietario de empresa m√°s habitual (por ejemplo, secretario, CEO, o vicepresidente).\n\nlicenses = pd.read_pickle('./data/licenses.p')\nlicenses.head()\n\n\n\n\n\n\n\n\naccount\nward\naid\nbusiness\naddress\nzip\n\n\n\n\n0\n307071\n3\n743\nREGGIE'S BAR & GRILL\n2105 S STATE ST\n60616\n\n\n1\n10\n10\n829\nHONEYBEERS\n13200 S HOUSTON AVE\n60633\n\n\n2\n10002\n14\n775\nCELINA DELI\n5089 S ARCHER AVE\n60632\n\n\n3\n10005\n12\nNaN\nKRAFT FOODS NORTH AMERICA\n2005 W 43RD ST\n60609\n\n\n4\n10044\n44\n638\nNEYBOUR'S TAVERN & GRILLE\n3651 N SOUTHPORT AVE\n60613\n\n\n\n\n\n\n\n\nbiz_owners = pd.read_pickle('./data/business_owners.p')\nbiz_owners.head()\n\n\n\n\n\n\n\n\naccount\nfirst_name\nlast_name\ntitle\n\n\n\n\n0\n10\nPEARL\nSHERMAN\nPRESIDENT\n\n\n1\n10\nPEARL\nSHERMAN\nSECRETARY\n\n\n2\n10002\nWALTER\nMROZEK\nPARTNER\n\n\n3\n10002\nCELINA\nBYRDAK\nPARTNER\n\n\n4\n10005\nIRENE\nROSENFELD\nPRESIDENT\n\n\n\n\n\n\n\n\nInstrucciones:",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Conceptos B√°sicos de la fusi√≥n de datos</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/02_Fusionar_tablas_distintos_tipos.html",
    "href": "04_Unir_datos_con_pandas/02_Fusionar_tablas_distintos_tipos.html",
    "title": "Fusionar tablas con distintos tipos de uni√≥n",
    "section": "",
    "text": "Lleva tu conocimiento de las uniones al siguiente nivel. En este cap√≠tulo, trabajar√°s con datos de pel√≠culas de TMDb mientras aprendes sobre las uniones izquierda, derecha y externa. Tambi√©n descubrir√°s c√≥mo fusionar una tabla consigo misma y c√≥mo fusionar en un √≠ndice DataFrame.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Fusionar tablas con distintos tipos de uni√≥n</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/03_Fusion_y_concatenacion_avanzadas.html",
    "href": "04_Unir_datos_con_pandas/03_Fusion_y_concatenacion_avanzadas.html",
    "title": "Fusi√≥n y concatenaci√≥n avanzadas",
    "section": "",
    "text": "En este cap√≠tulo, aprovechar√°s potentes t√©cnicas de filtrado, incluidas las semiuniones y las antiuniones. Tambi√©n aprender√°s a pegar DataFrames combin√°ndolos verticalmente y a utilizar la funci√≥n pandas.concat para crear nuevos conjuntos de datos. Por √∫ltimo, como los datos rara vez est√°n limpios, tambi√©n aprender√°s a validar tus estructuras de datos reci√©n combinadas.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fusi√≥n y concatenaci√≥n avanzadas</span>"
    ]
  },
  {
    "objectID": "04_Unir_datos_con_pandas/04_Fusionar_datos_ordenados_y_series_temporales.html",
    "href": "04_Unir_datos_con_pandas/04_Fusionar_datos_ordenados_y_series_temporales.html",
    "title": "Fusionar datos ordenados y series temporales",
    "section": "",
    "text": "En este cap√≠tulo final, dar√°s un paso adelante y aprender√°s a aplicar los m√©todos especializados de pandas para fusionar series temporales y datos ordenados con datos financieros y econ√≥micos del mundo real de la ciudad de Chicago. Tambi√©n aprender√°s a consultar las tablas resultantes utilizando un formato tipo SQL, y a desagrupar los datos utilizando el m√©todo de fusi√≥n.",
    "crumbs": [
      "Unir Datos con Pandas",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Fusionar datos ordenados y series temporales</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nüìä Nivel: Intermedio\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nLa estad√≠stica es el estudio de c√≥mo recopilar, analizar y extraer conclusiones a partir de los datos. Es una herramienta enormemente valiosa que puedes utilizar para enfocar el futuro e inferir la respuesta a montones de preguntas. Por ejemplo, ¬øcu√°l es la probabilidad de que alguien compre tu producto, cu√°ntas llamadas recibir√° tu equipo de asistencia y cu√°ntas tallas de vaqueros deber√≠as fabricar para que le queden bien al 95 % de la poblaci√≥n? En este curso, descubrir√°s c√≥mo responder a preguntas como estas a medida que aumentas tus competencias estad√≠sticas y aprendes a calcular medias, utilizar diagramas de dispersi√≥n para mostrar la relaci√≥n entre valores num√©ricos y calcular la correlaci√≥n. Tambi√©n abordar√°s la probabilidad, columna vertebral del razonamiento estad√≠stico, y aprender√°s a utilizar Python para realizar un estudio bien dise√±ado que te permita extraer tus propias conclusiones a partir de los datos.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html#m√≥dulos-del-curso",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nS√≠ntesis estad√≠stica\nN√∫meros aleatorios y probabilidad\nM√°s distribuciones y el teorema del l√≠mite central\nCorrelaci√≥n y dise√±o de experimentos",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/index.html#datasets",
    "href": "05_Introduccion_a_la_estadistica_en_python/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\namir_deals.csv\nfood_consumption.csv\nworld_happiness_add_sugar.csv\nworld_happiness.csv",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html",
    "title": "S√≠ntesis estad√≠stica",
    "section": "",
    "text": "Qu√© es la estad√≠stica?\nLa s√≠ntesis estad√≠stica te proporciona las herramientas que necesitas para condensar conjuntos de datos masivos y revelar lo m√°s destacado. En este cap√≠tulo explorar√°s la s√≠ntesis estad√≠stica, lo que incluye la media, la mediana y la desviaci√≥n t√≠pica, y aprender√°s a realizar una interpretaci√≥n exacta. Tambi√©n desarrollar√°s tus competencias de pensamiento cr√≠tico, lo que te permitir√° elegir la mejor s√≠ntesis estad√≠stica para tus datos.\nTipos de estad√≠stica:\nTipos de datos:",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>S√≠ntesis estad√≠stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#qu√©-es-la-estad√≠stica",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#qu√©-es-la-estad√≠stica",
    "title": "S√≠ntesis estad√≠stica",
    "section": "",
    "text": "Campo de la estad√≠stica: Es la pr√°ctica y studio de la recogida y an√°lisis de datos.\nUn res√∫men estad√≠stico: Un dato o resumen de algunos datos.\n\n\n\n\n\n\n\n\n\nEstad√≠stica Descriptiva\nEstad√≠stica Inferencial\n\n\n\n\n\nDescribe y resume los datos.\n\n\nUsa una muestra de datos para hacer inferencias acerca de una gran poblaci√≥n.\n\n\n\nEjemplos:\n\n50% de los amigos conducen al trabajo.\n25% toman el bus.\n25% bicicleta\n\nEjemplo:\n\nQu√© porcentaje de personas manejan al trabajo?\n\n\n\n\n\n\n\n\n\n\n\n\nNum√©rico (Cuantitativo)\nCateg√≥rico (Cualitativo)\n\n\n\n\n\nContinuos (se pueden medir)\n\nVelocidad de un avi√≥n.\nTiempo de espera en una fila\n\n\n\nNominal (Sin orden)\n\nCasado / Divorciado.\nPa√≠s de residencia.\n\n\n\n\n\nDiscretos (de recuento)\n\nN√∫mero de mascotas.\nN√∫mero de paquetes enviados.\n\n\n\nOrdinal (Ordenado)\n\nPreguntas de encuesta\n\n\n\n\n\n\nEstad√≠stica descriptiva e inferencial\nLa estad√≠stica puede utilizarse para responder a muchos tipos de preguntas, pero saber identificar qu√© tipo de estad√≠stica se necesita es esencial para sacar conclusiones exactas. En este ejercicio, afinar√°s tus competencias identificando qu√© tipo se necesita para responder a cada pregunta.\n\n\n\n\n\n\n\nDescriptiva\nInferencial\n\n\n\n\n\nDados los datos de cada solicitud de atenci√≥n al cliente realizada, ¬øcu√°l es el tiempo medio que se tard√≥ en responder?\n\n\nDespu√©s de entrevistar a 100 clientes, ¬øqu√© porcentaje de todos tus clientes est√°n satisfechos con tu producto?\n\n\n\n\nDados los datos de las 100 000 personas que vieron un anuncio, ¬øqu√© porcentaje de personas hicieron clic en √©l?\n\n\nDados los datos de 20 peces capturados en un lago, ¬øcu√°l es el peso medio de todos los peces del lago?\n\n\n\n\n\n\nClasificaci√≥n de los tipos de datos\nEn el v√≠deo, aprendiste sobre dos tipos principales de datos: num√©ricos y categ√≥ricos. Las variables num√©ricas pueden clasificarse como discretas o continuas, y las variables categ√≥ricas, como nominales u ordinales. Estas caracter√≠sticas de una variable determinan qu√© formas de resumir tus datos funcionar√°n mejor.\n\n\n\n\n\n\n\n\nNum√©rica continua\nNum√©rica discreta\nCateg√≥rica\n\n\n\n\nTemperatura del aire\nN√∫mero de art√≠culos en stock\nC√≥digo postal\n\n\nKilovatios de electricidad consumidos\nN√∫mero de cursos de Datacamp realizados\nMarca de un producto",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>S√≠ntesis estad√≠stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-tendencia-central",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-tendencia-central",
    "title": "S√≠ntesis estad√≠stica",
    "section": "Medidas de tendencia central",
    "text": "Medidas de tendencia central\n\nMedia: Funciona mejor para datos sim√©tricos.\nMediana: Funciona mejor para datos sesgados a izquierda y derecha.\nModa: Principalmente para datos categ√≥ricos.\n\n\nMedia y mediana\nEn este cap√≠tulo, trabajar√°s con el conjunto de datos food_consumption del 2018 Food Carbon Footprint Index, de nu3. El conjunto de datos food_consumption contiene el n√∫mero de kilogramos de alimentos consumidos por persona y a√±o en cada country y categor√≠a de alimentos (consumption), y su huella de carbono (co2_emissions) medida en kilogramos de di√≥xido de carbono, o CO2.\nEn este ejercicio, calcular√°s medidas de tendencia central para comparar el consumo de alimentos en US y B√©lgica utilizando tus competencias en pandas y numpy.\n\nimport pandas as pd\n\n\nfood_consumption = pd.read_csv('../datasets/food_consumption.csv')\nprint(food_consumption.head())\n\n   Unnamed: 0    country food_category  consumption  co2_emission\n0           1  Argentina          pork        10.51         37.20\n1           2  Argentina       poultry        38.66         41.53\n2           3  Argentina          beef        55.48       1712.00\n3           4  Argentina     lamb_goat         1.56         54.63\n4           5  Argentina          fish         4.36          6.96\n\n\n\nInstrucciones:\n\nImporta las librer√≠as pandas y numpy.\nSubdivide food_consumption para obtener las filas en las que el country es‚ÄôUSA‚Äô\nCalcula la media del consumption de alimentos en el DataFrame usa_consumption.\nCalcula la mediana del consumption de alimentos en el DataFrame usa_consumption.\n\n\n# Import numpy with alias np\nimport numpy as np\n\n# Subset country for USA: usa_consumption\nusa_consumption = food_consumption[food_consumption['country'] == 'USA']\n\n# Calculate mean consumption in USA\nprint(np.mean(usa_consumption['consumption']))\n\n# Calculate median consumption in USA\nprint(np.median(usa_consumption['consumption']))\n\n44.650000000000006\n14.58\n\n\nLos c√°lculos muestran que la media y la mediana del consumo en los Estados Unidos son bastante diferentes.\n\n\n\nMedia frente a mediana\nEn el v√≠deo has aprendido que la media es la suma de todos los puntos de datos dividida entre el n√∫mero total de puntos de datos, y que la mediana es el valor central del conjunto de datos, donde el 50 % de los datos son menores que la mediana y el 50 % de los datos son mayores que la mediana. En este ejercicio, comparar√°s estas dos medidas de tendencia central.\n\nInstrucciones:\n\n\n\n\nImporta la librer√≠a matplotlib.pyplot con el alias plt.\nSubdivide food_consumption para obtener las filas en las que el food_category es rice.\nCrea un histograma de co2_emissions en el DataFrame rice_consumption y muestra el gr√°fico.\n\n\n# Import matplotlib.pyplot with alias plt\nimport matplotlib.pyplot as plt\n\n\n# Subset for food_category equals rice\nrice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\nprint(rice_consumption.head())\n\n    Unnamed: 0      country food_category  consumption  co2_emission\n8            9    Argentina          rice         8.77         11.22\n19          20    Australia          rice        11.03         14.12\n30          31      Albania          rice         7.78          9.96\n41          42      Iceland          rice         3.89          4.98\n52          53  New Zealand          rice         9.16         11.72\n\n\n\n# Histogram of co2_emissions for rice and show plot\nplt.hist(rice_consumption['co2_emission'])\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta\n\nEcha un vistazo al histograma que acabas de crear de las emisiones de CO2 de los distintos pa√≠ses para el arroz. Cu√°l de los siguientes t√©rminos describe mejor la forma de los datos?\nRespuestas posibles\n\nSin sesgo\nSesgado a la izquierda\nSesgado a la derecha\n\n\n\n\n\nUtiliza .agg() para calcular la media y la mediana de co2_emissions para el arroz.\n\n\n# Subset for food_category equals rice\nrice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\nprint(rice_consumption)\n\n      Unnamed: 0       country food_category  consumption  co2_emission\n8              9     Argentina          rice         8.77         11.22\n19            20     Australia          rice        11.03         14.12\n30            31       Albania          rice         7.78          9.96\n41            42       Iceland          rice         3.89          4.98\n52            53   New Zealand          rice         9.16         11.72\n...          ...           ...           ...          ...           ...\n1383        1384  Sierra Leone          rice       103.30        132.19\n1394        1395     Sri Lanka          rice       109.72        140.41\n1405        1406     Indonesia          rice       134.62        172.27\n1416        1417       Liberia          rice        94.75        121.25\n1427        1428    Bangladesh          rice       171.73        219.76\n\n[130 rows x 5 columns]\n\n\n\n# Calculate mean and median of co2_emission with .agg()\nprint(rice_consumption['co2_emission'].agg(['mean', 'median']))\n\nmean      37.591615\nmedian    15.200000\nName: co2_emission, dtype: float64\n\n\n\nPregunta\n\nDado el sesgo de estos datos, qu√© medida de tendencia central resume mejor los kilogramos de emisiones de CO2 por persona y a√±o para el arroz?\nRespuestas posibles\n\nMedia\nMediana\nMedia y mediana",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>S√≠ntesis estad√≠stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-dispersi√≥n",
    "href": "05_Introduccion_a_la_estadistica_en_python/01_Sintesis_estadistica.html#medidas-de-dispersi√≥n",
    "title": "S√≠ntesis estad√≠stica",
    "section": "Medidas de dispersi√≥n",
    "text": "Medidas de dispersi√≥n\nDescribe lo separado o juntos que se encuentran los grupos de datos.\n\nVarianza:\nMide la distancia media de cada punto de datos a la media de los datos. Se puede calcular usando np.var().\n\n\nDesviaci√≥n est√°ndar\nSe calcula tomando la ra√≠z cuadrada de la varianza. Se puede calcular usando np.sd().\n\n\nDesviaci√≥n est√°ndar absoluto\nToma el valor absoluto de las distancias a la media y luego toma la media de las diferencias.\n\n\nDesviaci√≥n estandar vs desviaci√≥n media absoluta\n\nEn la desviaci√≥n estandar los cuadrados de las distancias penaliza las largas distancias m√°s que las cortas.\nEn la desviaci√≥n media absoluta todas las distancias se penalizar de forma equitativa.\n\n\n\nVarianza y desviaci√≥n t√≠pica\n\n\nCuartiles, cuantiles y quintiles\n\n\nEncontrar valores at√≠picos mediante IQR",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>S√≠ntesis estad√≠stica</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html",
    "title": "Mas distribuciones y el teorema del l√≠mite central",
    "section": "",
    "text": "La distribuci√≥n normal",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Mas distribuciones y el teorema del l√≠mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci√≥n-normal",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci√≥n-normal",
    "title": "Mas distribuciones y el teorema del l√≠mite central",
    "section": "",
    "text": "Distribuci√≥n de las ventas de Amir\n\n\nProbabilidades de la distribuci√≥n normal\n\n\nSimulaci√≥n de ventas en nuevas condiciones de mercado\n\n\nQu√© mercado es el mejor?",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Mas distribuciones y el teorema del l√≠mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#teorema-del-l√≠mite-central",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#teorema-del-l√≠mite-central",
    "title": "Mas distribuciones y el teorema del l√≠mite central",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central\n\nVisualizar distribuciones muestrales\n\n\nCTL en acci√≥n\n\n\nLa media de las medias",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Mas distribuciones y el teorema del l√≠mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci√≥n-de-poisson",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#la-distribuci√≥n-de-poisson",
    "title": "Mas distribuciones y el teorema del l√≠mite central",
    "section": "La distribuci√≥n de Poisson",
    "text": "La distribuci√≥n de Poisson\n\nProceso de Poisson\n\nProcesos que parecen ocurrir a un ritmo determinado, pero completamente aleatorio.\nEjemplos:\n\nEl n√∫mero de animales adoptados de un refugio por semana.\nEl n√∫mero de personas que llegan a un restaurante cada hora.\nEl n√∫mero de terremotos al a√±o en California.\n\nLa unidad de tiempo, como, horas, semanas o a√±os es irrelevante siempre que sean coherentes.\n\nDistrubici√≥n de Poisson\n\nLa probabilidad de que ocurra un n√∫mero determinado de sucesos en un periodo de tiempo.\nEjemplos\n\nProbabilidad de &gt;= 5 animales adoptados en una semana.\nProbabilidad de que 12 personas lleguen a un restaurante en una hora.\nProbabilidad &lt; 20 terremotos en California en un a√±o.\n\n\nLambda (\\(\\lambda\\))\n\n\\(\\lambda\\): N√∫mero de eventos promedio por intervalo de tiempo.\n\nN√∫mero promedio de adopciones por semana = 8.\n\n\n\nLambda es el pico de la distribuci√≥n\n\nCTL contin√∫a aplicando\n\n\n\nIdentificar lambda\nAhora que has aprendido sobre la distribuci√≥n de Poisson, sabes que su forma se describe mediante un valor llamado lambda. En este ejercicio emparejar√°s histogramas con valores lambda.\n\n\n\n\n\n\n\n\nlambda = 1\nlambda = 4\nlambda = 8\n\n\n\n\n\n\n\n\n\n\nLa distribuci√≥n de Poisson es una familia de distribuciones, igual que las distribuciones uniforme, binomial o normal.\n\n\nSeguimiento de las respuestas de los clientes potenciales\nTu empresa utiliza un software de ventas para hacer un seguimiento de los nuevos clientes potenciales. Los organiza en una cola para que cualquiera pueda hacer el seguimiento de uno cuando tenga un poco de tiempo libre. Dado que el n√∫mero de respuestas de clientes potenciales es un resultado contable a lo largo de un periodo de tiempo, esta situaci√≥n corresponde a una distribuci√≥n de Poisson. De media, Amir responde a 4 clientes potenciales cada d√≠a. En este ejercicio, calcular√°s las probabilidades de que Amir responda a distintos n√∫meros de clientes potenciales.\n\nInstrucciones:\n\nImporta poisson de scipy.stats y calcula la problabilidad de que Amir responda a 5 clientes potenciales en un d√≠a, dado que responde a una media de 4.\n\n\n# Import poisson from scipy.stats\nfrom scipy.stats import poisson\n\n# Probability of 5 responses\nprob_5 = poisson.pmf(5, 4) # (deseado, media)\nprint(prob_5)\n\n0.1562934518505317\n\n\n\nEl compa√±ero de trabajo de Amir responde a una media de 5.5 clientes potenciales al d√≠a. Cu√°l es la probabilidad a que responda a 5 clientes potenciales en un d√≠a?\n\n\n# Probability of 5 responses\nprob_coworker = poisson.pmf(5, 5.5)  # (deseado, media)\nprint(prob_coworker)\n\n0.17140068409793663\n\n\n\nCu√°l es la probabilidad de que Amir responda a 2 o menos clientes potenciales en en un d√≠a?\n\n\n# Probability of 2 or fewer responses\nprob_2_or_less = poisson.cdf(2, 4) # &lt;= cdf(deseado, media)\nprint(prob_2_or_less)\n\n0.2381033055535443\n\n\n\nCu√°l es la probabilidad de que Amir responda a m√°s de 10 clientes potenciales en 1 d√≠a?\n\n\n# Probability of &gt; 10 responses\nprob_over_10 = 1 - poisson.cdf(10, 4)\nprint(prob_over_10)\n\n0.0028397661205137315\n\n\nTener en cuenta que si se proporciona poisson.pmf o poisson.cdf con un n√∫mero no entero , arroja un error ya que la distribuci√≥n de Poisson solo se aplica a enteros.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Mas distribuciones y el teorema del l√≠mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#m√°s-distribuciones-de-probabilidad",
    "href": "05_Introduccion_a_la_estadistica_en_python/03_Mas_distribuciones_y_teorema_limite_central.html#m√°s-distribuciones-de-probabilidad",
    "title": "Mas distribuciones y el teorema del l√≠mite central",
    "section": "M√°s distribuciones de probabilidad",
    "text": "M√°s distribuciones de probabilidad\n\nDistribuci√≥n exponencial\n\nProbabilidad en que transcurra cierto tiempo entre eventos de Poisson.\nEjemplos\n\nProbabilidad &gt; 1 d√≠a entre adopciones.\nProbabilidad &lt; 10 minutos entre llegadas a restaurantes.\nProbabilidad de 6 a 8 meses entre terremotos.\n\nTambi√©n usa lambda \\(\\lambda\\)\nContinua (tiempo)\nValor esperado de la distribuci√≥n exponencial\n\nMide la frecuencia en terminos de tiempo entre sucesos.\n\n\nDistribuci√≥n T (estudiante)\n\nForma similar a la distribuci√≥n normal.\n\n\nGrados de libertad (DoF)\n\nTiene un par√°metro de grados de libertad (df) que afecta el grosor de las colas de la distribuci√≥n.\n\n\nBajo df = Colas m√°s gruesas y mayor desviaci√≥n estandar.\nAlto df = Similar a la distribuci√≥n normal.\n\n\nDistribuci√≥n Log-normal\n\nLas variables que siguen una distribuci√≥n log-normal tiene un logaritmo que se distribuye normalmente. Da lugar a distribuciones sesgadas.\nEjemplos\n\nDuraci√≥n de las partidas de ajedrez.\nLa presi√≥n arterial en adultos.\nN√∫mero de hospitalizaciones en el brote de SARS en el 2003.\n\n\n\n\nArrastrar y colocar distribuciones\nLlegados a este punto, has aprendido sobre tantas distribuciones de probabilidad diferentes que puede ser dif√≠cil recordar cu√°l es cu√°l. En este ejercicio, practicar√°s la distinci√≥n entre distribuciones y la identificaci√≥n de la distribuci√≥n que mejor se ajusta a distintas situaciones.\n\n\n\n\n\n\n\n\nPoisson\nExponencial\nBinomial\n\n\n\n\nN√∫mero de clientes que entran a una tienda cada hora.\nTiempo que transcurre hasta que alguien paga su pr√©stamo.\nN√∫mero de personas de un grupo de 30 que aprueban el examen de conducir.\n\n\nN√∫mero de productos vendidos cada semana.\nTiempo que transcurre hasta que el siguiente cliente realiza su compra.\n\n\n\n\n\n\nTiempo de modelado entre clientes potenciales\nPara evaluar mejor el rendimiento de Amir, quieres saber cu√°nto tarda en responder a un cliente potencial despu√©s de abrirlo. De media, responde a 1 solicitud cada 2,5 horas. En este ejercicio, calcular√°s las probabilidades de que pasen diferentes cantidades de tiempo entre que Amir recibe un cliente potencial y env√≠a una respuesta.\n\nInstrucciones:\n\nImporta expon desde scipy.stats. Cu√°l es la probabilidad de que Amir tarde menos de una hora en responder a un cliente potencial.\n\n\n# Import expon from scipy.stats\nfrom scipy.stats import expon\n\n# Print probability response takes &lt; 1 hour\nprint(expon.cdf(1, scale=2.5))\n\n0.3296799539643607\n\n\n\nCu√°l es la probabilidad de que Amir tarde m√°s de 4 horas en responder a un cliente potencial?\n\n\n# Print probability response takes &gt; 4\nprint(1 - expon.cdf(4, scale=2.5))\n\n0.20189651799465536\n\n\n\nCu√°l es la probabilidad de que Amir tarde 3-4 horas en responder a un cliente potencial?\n\n\n# Print probability response takes 3-4 hours\nprint(expon.cdf(4, scale=2.5) - expon.cdf(3, scale=2.5))\n\n0.09929769391754684\n\n\nHay solo alrededor de un 20% de probabilidad de que Amir tarde m√°s de 4 horas en responder, as√≠ que es bastante r√°pido en sus respuestas.\n\n\n\nLa disttibuci√≥n t\nQu√© afirmaci√≥n no es cierta respecto a la distrubuci√≥n t?\n\nLa distribuci√≥n t tiene colas m√°s gruesas que la distribuci√≥n normal.\nUna distribuci√≥n t con altos grados de libertad se parece a la distribuci√≥n normal.\nEl n√∫mero de grados de libertad afecta a la varianza de la distribuci√≥n.\nLa distribuci√≥n t est√° sesgada.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Mas distribuciones y el teorema del l√≠mite central</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html",
    "title": "Correlaci√≥n y dise√±o de experimentos",
    "section": "",
    "text": "Correlaci√≥n\nEn este cap√≠tulo, aprender√°s a cuantificar la fuerza de una relaci√≥n lineal entre dos variables, y explorar√°s c√≥mo las variables de confusi√≥n pueden afectar a la relaci√≥n entre otras dos variables. Tambi√©n ver√°s c√≥mo el dise√±o de un estudio puede influir en sus resultados, cambiar la forma en que deben analizarse los datos y afectar potencialmente a la fiabilidad de tus conclusiones.\nimport seaborn as sns\nsns.scatterplot(x='sleep_total', y='sleep_rem', data=msleep)\nplt.show()\nimport seaborn as sns\nsns.lmplot(x='sleep_total', y='sleep_rem', data=msleep, ci=None)\nplt.show()\nmsleep['sleep_total'].corr(msleep['sleep_rem'])\nmsleep['sleep_rem'].corr(msleep['sleep_total'])",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Correlaci√≥n y dise√±o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#correlaci√≥n",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#correlaci√≥n",
    "title": "Correlaci√≥n y dise√±o de experimentos",
    "section": "",
    "text": "Realci√≥n entre dos variables\n\n\nx = variable explicativa o independiente.\ny = variable de respuesta o dependiente.\n\nCoeficiente de correlaci√≥n\n\nCuantifica la relaci√≥n lineal entre dos variables.\nEs un m√∫mero entre -1 y 1.\nLa magnitud corresponde a la fuerza de la relaci√≥n.\nSigno (+ o -) corresponde a la direcci√≥n de la relaci√≥n.\n\nMagnitud = Fuerza de la relaci√≥n\n\n\n\n\n\n\n\n\n\n0.99 (Muy fuerte relaci√≥n)\n\n0.75 (Fuerte relaci√≥n ) | 0.56 (moderada relaci√≥n) | |  |  |\n\n\n0.21 (d√©bil relaci√≥n)\n\n0.04 (sin relaci√≥n)\n\n\nConocer el valor de x no nos dice nada acerca de y.\n\n\n\n\n\nSigno = Direcci√≥n\n\n\n\n\n\n\n\n0.75: Como x incrementa y incrementa\n-0.75: Como x incrementa y decrece\n\n\n\n\n\n\n\n\n\nVisualizaci√≥n de relaciones\n\n\n\n\nA√±adir una linea de tendencia\n\n\n\n\nCalcular el coeficiente de correlaci√≥n entre dos series\n\n\n\n\nMuchas formas de calcular la correlaci√≥n\n\nLa usada en el curso: Correlaci√≥n producto momento de Pearson (\\(r\\))\n\nEs la m√°s com√∫n\n\\(\\bar{x} = \\text{media de } x \\\\\\)\n\\(\\sigma_x = \\text{desviaci√≥n estandar de } x\\)\n\\[\\begin{align*}\n    r &= \\sum_{i=1}^{n} \\frac{(x_i - \\bar{x})(y_i - \\bar{y})}{\\sigma_x \\times \\sigma_y}\n\\end{align*}\\]\n\nVariaciones en esta f√≥rmula:\n\nKendall‚Äôs tau\nSpearman‚Äôs rho\n\n\n\n\nAdivina la correlaci√≥n\n¬øCu√°l de las siguientes afirmaciones NOT es verdadera sobre la correlaci√≥n?\n\nSi la correlaci√≥n entre x y y tiene una magnitud elevada, los puntos de datos se agrupar√°n estrechamente alrededor de una l√≠nea.\nLa correlaci√≥n puede escribirse como r.\nSi x e y est√°n correlacionados negativamente, los valores de y disminuyen a medida que aumentan los de x.\nLa correlaci√≥n no puede ser 0.\n\n\n\nRelaciones entre variables\nEn este cap√≠tulo, trabajar√°s con un conjunto de datos world_happiness que contiene los resultados de 2019 World Happiness Report. El informe punt√∫a a diferentes pa√≠ses en funci√≥n de lo felices que son sus habitantes. Tambi√©n clasifica a cada pa√≠s en funci√≥n de diversos aspectos sociales, como el apoyo social, la libertad, la corrupci√≥n y otros. El conjunto de datos tambi√©n incluye el GDP per c√°pita y la esperanza de vida de cada pa√≠s.\nEn este ejercicio, examinar√°s la relaci√≥n entre la esperanza de vida de un pa√≠s (life_exp) y la puntuaci√≥n de felicidad (happiness_score) tanto visual como cuantitativamente. seaborn como sns, matplotlib.pyplot como plt y pandas como pd est√°n cargados y world_happiness est√° disponible.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nworld_happiness = pd.read_csv('./data/world_happiness.csv')\nprint(world_happiness.head())\n\n   Unnamed: 0      country  social_support  freedom  corruption  generosity  \\\n0           1      Finland             2.0      5.0         4.0        47.0   \n1           2      Denmark             4.0      6.0         3.0        22.0   \n2           3       Norway             3.0      3.0         8.0        11.0   \n3           4      Iceland             1.0      7.0        45.0         3.0   \n4           5  Netherlands            15.0     19.0        12.0         7.0   \n\n   gdp_per_cap  life_exp  happiness_score  \n0        42400      81.8              155  \n1        48300      81.0              154  \n2        66300      82.6              153  \n3        47900      83.0              152  \n4        50500      81.8              151  \n\n\n\nInstrucciones:\n\n\n\n\nCrea un diagrama de dispersi√≥n de happiness_score frente a life_exp (sin l√≠nea de tendencia) utilizando seaborn.\nMuestra el gr√°fico.\n\n\n# Create a scatterplot of happiness_score vs. life_exp ando show\nsns.scatterplot(x='life_exp', y='happiness_score', data=world_happiness)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nCrea un diagrama de dispersi√≥n de happiness_score frente a life_exp con una l√≠nea de tendencia lineal utilizando seaborn, estableciendo ci en None.\nMuestra el gr√°fico.\n\n\n# Create scatterplot of happiness_score vs life_exp with trendline\nsns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPregunta\nSeg√∫n el diagrama de dispersi√≥n, cu√°l es la correlaci√≥n m√°s probable entre life_exp y happiness_score?\nRespuestras posibles\n\n0.3\n-0.3\n0.8\n-0.8\n\n\nCalcula la correlaci√≥n entre life_exp y happiness_score. Gu√°rdala como cor.\n\n\n# Correlation between life_exp and happiness_score\ncor =  world_happiness['life_exp'].corr(world_happiness['happiness_score'])\n\nprint(cor)\n\n0.7802249053272065\n\n\nLos diagramas de dispersi√≥n con l√≠neas de tendencia son una excelente manera de verificar que una relaci√≥n estre dos variables es realmente lineal.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Correlaci√≥n y dise√±o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#advertencias-sobre-la-correlaci√≥n",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#advertencias-sobre-la-correlaci√≥n",
    "title": "Correlaci√≥n y dise√±o de experimentos",
    "section": "Advertencias sobre la correlaci√≥n",
    "text": "Advertencias sobre la correlaci√≥n\n\nRelaciones no lineales\n\nSiempre que sea posible visualizar los datos.\n\nTransformaci√≥n logaritmica\n\nEs posible usarla cuando hayan datos muy sesgados.\n\nOtras transformaciones\n\nTransformaci√≥n logar√≠tmica (log(x))\nTransformaci√≥n ra√≠z cuadrada (sqrt(x))\nTransformaci√≥n rec√≠proca (1 / x)\nCombinations de esteas, por ejemplo:\n\nlog(x) y log(y)\nsqrt(x) y 1 / y\n\n\nPor qu√© usar una transformaci√≥n?\n\nCiertos m√©todos estad√≠sticos se basan en que las variables tengan una relaci√≥n lineal.\n\nCoeficiente de correlaci√≥n\nRegresi√≥n lineal.\n\n\nLa correlaci√≥n no implica causalidad.\nSi x est√° correlacionada con y no significa que x cause y.\nConfusi√≥n\nEste fen√≥meno puede dar lugar a correlaciones espurias.\n\n\nQu√© no puede medir la correlaci√≥n?\nAunque el coeficiente de correlaci√≥n es una forma c√≥moda de cuantificar la fuerza de una relaci√≥n entre dos variables, dista mucho de ser perfecto. En este ejercicio, explorar√°s una de las advertencias sobre el coeficiente de correlaci√≥n examinando la relaci√≥n entre el GDP per c√°pita de un pa√≠s (gdp_per_cap) y la puntuaci√≥n de felicidad.\n\n\nInstrucciones:\n\n\n\n\nCrea un diagrama de dispersi√≥n seaborn (sin l√≠nea de tendencia) que muestre la relaci√≥n entre gdp_per_cap (en el eje X) y life_exp (en el eje Y).\nMuestra el gr√°fico.\n\n\n# Scatterplot of gdp_per_cap and life_exp\nsns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCalcula la correlaci√≥n entre gdp_per_cap y life_exp y gu√°rdala como cor.\n\n\n# Correlation between gdp_per_cap and life_exp\ncor = world_happiness['gdp_per_cap'].corr(world_happiness['life_exp'])\n\nprint(cor)\n\n0.7019547642148015\n\n\n\n\n\nPregunta\nLa correlaci√≥n entre GDP per c√°pita y esperanza de vida es de 0.7. Por qu√© la correlaci√≥n no es la mejor forma de medir la relaci√≥n entre estas dos variables?\nRespuestas posibles\n\nLa correlaci√≥n mide c√≥mo afecta una variable a otra.\nLa correlaci√≥n solo mide las correlaciones lineales.\nLa correlaci√≥n no puede medir adecuadamente las relaciones entre variables num√©ricas.\n\nEl coeficiente de correlaci√≥n no puede dar cuenta de ninguna relaci√≥n que no sea lineal, independientemente de su fuerza.\n\n\nTransformaci√≥n de variables\nCuando las variables tienen distribuciones sesgadas, a menudo requieren una transformaci√≥n para formar una relaci√≥n lineal con otra variable, de modo que pueda calcularse la correlaci√≥n. En este ejercicio realizar√°s una transformaci√≥n.\n\nInstrucciones:\n\nCrea un diagrama de dispersi√≥n de happiness_score frente a gdp_per_cap y calcula la correlaci√≥n entre ambos.\n\n\n# Scatterplot of happiness_score vs. gdp_per_cap\nsns.scatterplot(x='gdp_per_cap', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Calculate correlation\ncor = world_happiness['happiness_score'].corr(world_happiness['gdp_per_cap'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.7279733012222978\n\n\n\nA√±ade una nueva columna a world_happiness llamada log_gdp_per_cap que contenga el logaritmo de gdp_per_cap. Crea un diagrama de dispersi√≥n seaborn de happiness_score frente a log_gdp_per_cap y happiness_score. Calcula la correlaci√≥n enre log_gdp_per_cap y happiness_score.\n\n\n# Create log_gdp_per_cap column\nworld_happiness['log_gdp_per_cap'] = np.log(world_happiness['gdp_per_cap'])\n\n# Scatterplot of happiness_score vs. log_gdp_per_cap\nsns.scatterplot(x='log_gdp_per_cap', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Calculate correlation\ncor = world_happiness['log_gdp_per_cap'].corr(world_happiness['happiness_score'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.8043146004918288\n\n\nLa relaci√≥n entre el PIB per c√°pita y la felicidad se volvi√≥ m√°s lineal al aplicar una transformaci√≥n logar√≠tmica. Las transformaciones logar√≠tmicas son excelentes para usar en variables con una distribuci√≥n sesgada, como el PIB.\n\n\n\nEl az√∫car aumenta la felicidad?\nSe ha a√±adido una nueva columna a world_happiness llamada grams_sugar_per_day, que contiene la cantidad media de az√∫car ingerida por persona y d√≠a en cada pa√≠s. En este ejercicio, examinar√°s el efecto del consumo medio de az√∫car de un pa√≠s en su puntuaci√≥n de felicidad.\n\nworld_happiness = pd.read_csv('./data/world_happiness_add_sugar.csv', index_col=0)\nworld_happiness\n\n\n\n\n\n\n\n\ncountry\nsocial_support\nfreedom\ncorruption\ngenerosity\ngdp_per_cap\nlife_exp\nhappiness_score\ngrams_sugar_per_day\n\n\nUnnamed: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nFinland\n2\n5\n4.0\n47\n42400\n81.8\n155\n86.8\n\n\n2\nDenmark\n4\n6\n3.0\n22\n48300\n81.0\n154\n152.0\n\n\n3\nNorway\n3\n3\n8.0\n11\n66300\n82.6\n153\n120.0\n\n\n4\nIceland\n1\n7\n45.0\n3\n47900\n83.0\n152\n132.0\n\n\n5\nNetherlands\n15\n19\n12.0\n7\n50500\n81.8\n151\n122.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n129\nYemen\n100\n147\n83.0\n155\n2340\n68.1\n5\n77.9\n\n\n130\nRwanda\n144\n21\n2.0\n90\n2110\n69.1\n4\n14.1\n\n\n131\nTanzania\n131\n78\n34.0\n49\n2980\n67.7\n3\n28.0\n\n\n132\nAfghanistan\n151\n155\n136.0\n137\n1760\n64.1\n2\n24.5\n\n\n133\nCentral African Republic\n155\n133\n122.0\n113\n794\n52.9\n1\n22.4\n\n\n\n\n133 rows √ó 9 columns\n\n\n\n\nInstrucciones:\n\n\n\n\nCrea un diagrama de dispersi√≥n seaborn que muestre la relaci√≥n entre grams_sugar_per_day (en el eje X) y happiness_score (en el eje Y).\nCalcula la correlaci√≥n entre grams_sugar_per_day y happiness_score.\n\n\n# Scatterplot of grams_sugar_per_day and happiness_score\nsns.scatterplot(x='grams_sugar_per_day', y='happiness_score', data=world_happiness)\nplt.show()\n\n# Correlation between grams_sugar_per_day and happiness_score\ncor = world_happiness['grams_sugar_per_day'].corr(world_happiness['happiness_score'])\nprint(cor)\n\n\n\n\n\n\n\n\n0.6939100021829634\n\n\n\n\n\nPregunta\nSeg√∫n estos datos, qu√© afirmaci√≥n sobre el consumo de az√∫car y las puntuaciones de felicidad es cierta?\nRespuestas posibles\n\nUn mayor consumo de az√∫car conduce a una mayor puntuaci√≥n de felicidad.\nA menor consumo de az√∫car, menor puntuaci√≥n de felicidad.\nUn mayor consumo de az√∫car se asocia a una mayor puntuaci√≥n de felicidad.\nEl consumo de az√∫car no est√° relacionado con la felicidad.\n\nSi la correlaci√≥n siempre implicara que una cosa causa la otra, la gente podr√≠a hacer cosas son sentido, como comer m√°s az√∫car para se m√°s feliz.\n\n\n\nFactores de confusi√≥n\nUn estudio investiga la relaci√≥n entre la residencia en el vecindario y la capacidad pulmonar. Los investigadores miden la capacidad pulmonar de treinta personas del vecindario A, situado cerca de una autov√≠a, y de treinta personas del vecindario B, que no est√° cerca de una autov√≠a. Ambos grupos tienen unos h√°bitos de consumo de tabaco y un desglose por sexos similares.\n¬øCu√°l de los siguientes podr√≠a ser un factor de confusi√≥n en este estudio?\nRespuestas posibles\n\nCapacidad pulmonar\nVecindario\nContaminaci√≥n atmosf√©rica\nCondici√≥n de fumador\nSexo\n\nEs de esperar que haya m√°s contaminaci√≥n atmosf√©rica en el vecindario situado cerca de la autov√≠a, lo que puede provocar una menor capacidad pulmonar.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Correlaci√≥n y dise√±o de experimentos</span>"
    ]
  },
  {
    "objectID": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#dise√±o-de-experimentos",
    "href": "05_Introduccion_a_la_estadistica_en_python/04_Correlacion_y_diseno_de_experimentos.html#dise√±o-de-experimentos",
    "title": "Correlaci√≥n y dise√±o de experimentos",
    "section": "Dise√±o de experimentos",
    "text": "Dise√±o de experimentos\n\nVocabulario\n\nEl experimento responde a la prgunta: Cu√°l es el efecto del tratamiento sobre la respuesta?.\n\nTratamiento: Variable explicativa o independiente.\nRespuesta: Variable dependiente o de respuesta.\n\nEjemplo: Cu√°l es el efecto de un anuncio en el n√∫mero de productos comprados?\n\nTratamiento: Anuncio\nRespuesta: N√∫mero de productos comprados\n\n\nExperimentos Controlados\n\nLos participantes son asignados aleatoriamente a los grupos de tratamiento o al grupo de control. El grupo de tratamiento recibe el tratamiento y el de control no.\n\nGrupo de tratamiento ve los anuncios\nEl grupo de control no.\n\nLos grupos deben ser comparables de modo que la causalidad pueda ser inferida.\nSi los grupos no son comparables, esto podria llevar a confusi√≥n.\n\nGrupo de tratamiento con edad promedio de : 25\nGrupo de control con edad promedio de: 50\nLa edad es un un potencial factor de confusi√≥n.\n\n\nEl gold est√°ndar de los experimento usar√°‚Ä¶\n\nEnsayo controlado aleatorio.\n\nLos participantes son asignados al azar al grupo de tratamiento o de control. No basado en alguna caracter√≠stica.\nLa asignaci√≥n aleatoria ayuda a asegurar que los grupos sean comparables.\n\nPlacebo\n\nSe parace al tratamiento, pero no tiene efecto.\nLos participantes no sabr√°n a cual grupo ir√°n.\n\nDoble ciego\n\nLa persona que administra el tratamiento no conoce cual es el tratamiento real o el placebo.\nPreviene el sesgo en la respuesta y/o en el an√°lisis de resultados.\n\nMenos oportunidades de que haya sesgo = mas fiable sera la conclusi√≥n que el tratamiento afecta la respuesta.\n\nEstudios observacionales\n\nLos participantes no se asignan aleatoriamente a los grupos.\n\nLos participantes se asignan a si mismos, usualmente basado en caracter√≠sticas preexistentes.\n\nMuchas preguntas no son conducidas a un experimento controlado.\n\nNo puedes forzar a alguien a fumar o tener un deseso.\nNo puede hacer que alguien tengan cierto comportamiento.\n\nSe establece asociaci√≥n no causalidad.\n\nLos efectos del tratamiento pueden ser confundidos por factores que llevaron a ciertas personas al grupo de control o tratamiento.\nHay formas de controlar la confusi√≥n para obtener m√°s conclusiones fiabiles acerca de la asociaci√≥n.\n\n\nEstudios Longitudinales vs Estudios transversales\n\nEstudios Longitudinales\n\nSe sigue a los mismos participantes durante un periodo de tiempo para examinar el efecto del tratamiento en la respuesta.\nEl efecto de la edad en la altura no es confundida por generaci√≥n.\nSon m√°s costosos, los resultados toman tiempo.\n\nEstudio transversal\n\nLos datos de los participantes son recolectados de una sola camptura en el tiempo.\nEl efecto de la edad en la altura se confunde por generaci√≥n.\nSon m√°s baratos, r√°pidos y mas convenientes.\n\n\n\n\nTipos de estudio\nAunque los experimentos controlados son ideales, muchas situaciones y preguntas de investigaci√≥n no son propicias para un experimento controlado. En un experimento controlado, es probable que pueda inferirse la causalidad si los grupos de control y de prueba tienen caracter√≠sticas similares y no hay ninguna diferencia sistem√°tica entre ellos. Por otra parte , la causalidad no suele inferirse de los estudios observacionales, cuyos resultados suelen interpretarse err√≥neamente como consecuencia de ello.\n\nInstrucciones\n\nDetermina si cada estudio es un experimento controlado o un estudio observacional\n\n\n\n\n\n\n\n\nExperimento Controlado\nEstudio Observacional\n\n\n\n\nSe comparan los s√≠ntomas de asma entre ni√±os asignados aleatoriamente a recibir servicios profesionales de control de plagas a domicilio o educaci¬¥√∏n sobre el control de plagas.\nSe compara la prevalencia de enfermedades card√≠acas entre veteranos con PTSD y veteranos sin PTSD.\n\n\nSe comparan las tasas de compra entre los usuarios de un sitio de comercio electr√≥nico que son dirigidos aleatoriamente a una nueva versi√≥n de la p√°gina de inicio o a una versi√≥n antigua.\nHace una semana, se actualiz√≥ la p√°gina de inico de un sitio de comercio electr√≥nico. Las tasas de compra se comparan entre los usuarios que vieron las versiones antigua y nueva de la p√°gna de inicio.\n\n\nSe asigna aleatoriamente a los sujetos una dieta y se compara la p√©rdida de peso.\n\n\n\n\n\n\n\nEstudios longitudinales frente a estudios transversales\nUna empresa fabrica term√≥metros y quiere estudiar la relaci√≥n entre la antig√ºedad de un term√≥metro y su exactitud. Para ello, toman una muestra de 100 term√≥metros diferentes de distintas antig√ºedades y comprueban su exactitud. Son datos longitudinales o transversales?\nRespuestas posibles\nSelecciona una respuesta:\n\nLongitudinal\nTransversal\nAmbos\nNinguno\n\nSe trata de un estudio transversal, ya que los investigadores no est√°n siguiendo el mismo conjunto de term√≥metros a lo largo del tiempo y midiendo repetidamente su exactitud con diferentes antig√ºedades.",
    "crumbs": [
      "Introducci√≥n a la Estad√≠stica en Python",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Correlaci√≥n y dise√±o de experimentos</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nüìä Nivel: Principiante\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nSeaborn es una potente biblioteca de Python que facilita la creaci√≥n de visualizaciones de datos informativas y atractivas. Este curso de 4 horas proporciona una introducci√≥n a c√≥mo puedes utilizar Seaborn para crear diversos gr√°ficos, incluidos gr√°ficos de dispersi√≥n, de recuento, de barras y de cajas, y c√≥mo puedes personalizar tus visualizaciones.\nExplorar√°s esta biblioteca y crear√°s gr√°ficos Seaborn basados en diversos conjuntos de datos del mundo real, como la exploraci√≥n de c√≥mo cambia la contaminaci√≥n atmosf√©rica en una ciudad a lo largo del d√≠a y el estudio de lo que les gusta hacer a los j√≥venes en su tiempo libre. Estos datos te dar√°n la oportunidad de conocer de primera mano las ventajas de Seaborn, incluyendo c√≥mo puedes crear f√°cilmente subtramas en una sola figura y c√≥mo calcular autom√°ticamente los intervalos de confianza.\nAl final de este curso, ser√°s capaz de utilizar Seaborn en diversas situaciones para explorar tus datos y comunicar eficazmente a otros los resultados de tus an√°lisis de datos. Estas habilidades son muy solicitadas para analistas de datos, cient√≠ficos de datos y cualquier otro trabajo que pueda implicar la creaci√≥n de visualizaciones de datos. Si quieres continuar tu aprendizaje, este curso forma parte de varios programas, incluido el programa de visualizaci√≥n de datos, donde podr√°s a√±adir m√°s bibliotecas y t√©cnicas a tu conjunto de habilidades.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#m√≥dulos-del-curso",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nInstroducci√≥n a Seaborn\nVisualizar dos variables cuantitativas\nVisualizar variables categ√≥ricas y cuantativas\nPersonalizar gr√°ficos con seaborn",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#datasets",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\nunemployment.csv\ndata_science_salaries.csv\nbooks.csv\ndivorce.csv\nplanes.csv",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "Bienvenida"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html",
    "title": "Introducci√≥n a Seaborn",
    "section": "",
    "text": "Introducci√≥n a Seaborn\nQu√© es Seaborn y cu√°ndo debes utilizarlo? En este cap√≠tulo, ¬°Lo descubrir√°s! Adem√°s, aprender√°s a crear gr√°ficos de dispersi√≥n y de recuento tanto con listas de datos como con DataFrames de pandas. Tambi√©n conocer√°s una de las grandes ventajas de utilizar Seaborn: la posibilidad de a√±adir f√°cilmente una tercera varible a tus gr√°ficos utilizando el color para representar diferentes subgrupos.\nimport seaborn as sns  # Samuel Norman Seaborn (sns)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nheight = [62, 64, 69, 75, 66,\n          68, 65, 71, 76, 73]\nweight = [120, 136, 148, 175, 137,\n          165, 154, 172, 200, 187]\nsns.scatterplot(x=height, y=weight)\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ngender = ['Female', 'Female',\n          'Female', 'Female',\n          'Male', 'Male', 'Male',\n          'Male', 'Male', 'Male']\nsns.countplot(x=gender)",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Introducci√≥n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#introducci√≥n-a-seaborn",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#introducci√≥n-a-seaborn",
    "title": "Introducci√≥n a Seaborn",
    "section": "",
    "text": "Qu√© es Seaborn?\n\nPuthon es una librer√≠a de visualizaci√≥n de datos\nCrea facilmente los tipos m√°s comunes de gr√°ficos\n\nPor qu√© es √∫til Seaborn?\n\nExploraci√≥n de datos\nComunicaci√≥n de resultados\n\nVentajas de Seaborn\n\nF√°cil de usar\nTrabaja bien con estructuras de datos de pandas\nConstru√≠do sobre matplotlib\n\nC√≥mo iniciar?\n\n\n\nEjemplo 1: Scatter plot\n\n\n\nEjemplo 2: Crear un count plot\n\n\n\nHacer un gr√°fico de dispersi√≥n con listas\nEn este ejecicio, utilizaremos un conjunto de datos que contiene informaci√≥n sobre 227 pa√≠ses. Este conjunto de datos contiene mucha informaci√≥n interesante sobre cada pa√≠s, como sus tasas de natalidad y mortalidad y su producto interno bruto (GDP). GDP es el valor de todos los bienes y servicios producidas en un a√±o, expresado en d√≥lares por persona.\nHemos creado tres listas de datos a partir de este conjunto de datos para que puedas empezar. gdp es una lista que contiene el valor de GDP por pa√≠s, expresado en d√≥lares por persona. phones es una lista con el n√∫mero de tel√©fonos m√≥viles por cada 1000 personas en este pa√≠s. Por √∫ltimo percent_literate es una lista que contiene el porcentaje de la poblaci√≥n de cada pa√≠s que sabe leer y escribir.\n\nimport pandas as pd\n\nruta = './data/countries-of-the-world.csv'\ndf = pd.read_csv(ruta)\ndf.head()\n\n\n\n\n\n\n\n\nCountry\nRegion\nPopulation\nArea (sq. mi.)\nPop. Density (per sq. mi.)\nCoastline (coast/area ratio)\nNet migration\nInfant mortality (per 1000 births)\nGDP ($ per capita)\nLiteracy (%)\nPhones (per 1000)\nArable (%)\nCrops (%)\nOther (%)\nClimate\nBirthrate\nDeathrate\nAgriculture\nIndustry\nService\n\n\n\n\n0\nAfghanistan\nASIA (EX. NEAR EAST)\n31056997\n647500\n48,0\n0,00\n23,06\n163,07\n700.0\n36,0\n3,2\n12,13\n0,22\n87,65\n1\n46,6\n20,34\n0,38\n0,24\n0,38\n\n\n1\nAlbania\nEASTERN EUROPE\n3581655\n28748\n124,6\n1,26\n-4,93\n21,52\n4500.0\n86,5\n71,2\n21,09\n4,42\n74,49\n3\n15,11\n5,22\n0,232\n0,188\n0,579\n\n\n2\nAlgeria\nNORTHERN AFRICA\n32930091\n2381740\n13,8\n0,04\n-0,39\n31\n6000.0\n70,0\n78,1\n3,22\n0,25\n96,53\n1\n17,14\n4,61\n0,101\n0,6\n0,298\n\n\n3\nAmerican Samoa\nOCEANIA\n57794\n199\n290,4\n58,29\n-20,71\n9,27\n8000.0\n97,0\n259,5\n10\n15\n75\n2\n22,46\n3,27\nNaN\nNaN\nNaN\n\n\n4\nAndorra\nWESTERN EUROPE\n71201\n468\n152,1\n0,00\n6,6\n4,05\n19000.0\n100,0\n497,2\n2,22\n0\n97,78\n3\n8,71\n6,25\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n# Convertir a numerico los datos tipo object\ndf['Phones (per 1000)'] = df['Phones (per 1000)'].str.replace(',', '.').astype(float)\ndf['Literacy (%)'] = df['Literacy (%)'].str.replace(',', '.').astype(float)\n\n# Crear las listas\ngdp = df['GDP ($ per capita)'].tolist()\nphones = df['Phones (per 1000)'].tolist()\npercent_literate = df['Literacy (%)'].tolist()\n\n\nInstrucciones\n\nImporta Matplotlib y Seaborn utilizando la convenci√≥n de nomenclatura est√°ndar.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nCrea un gr√°fico de dispersi√≥n de GDP (gdp) frente al n√∫mero de tel√©fonos por cada 1000 personas (phones).\n\n\n# Create scatterplot with GDP on x-axis and number of phones on the y-axis\nsns.scatterplot(x=gdp, y=phones)\nplt.show()\n\n\n\n\n\n\n\n\n\nCombina el diagrama de dispersi√≥n para que muestre el porcentaje de la poblaci√≥n que sabe leer y escribir (percent_literate) en el eje y.\n\n\nsns.scatterplot(x=gdp, y=percent_literate)\nplt.show()\n\n\n\n\n\n\n\n\nAunque este gr√°fico no muestra una relaci√≥n lineal entre el PIB y el porcentaje de alfabetizaci√≥n, los pa√≠ses con un PIB m√°s bajo parecen tener m√°s probabilidades de tener un porcentaje menor de la poblaci√≥n que puede leer y escribir.\n\n\n\nHacer un gr√°fico de recuento con una lista\nEn el ejercicio anterior, exploramos un conjunto de datos que contienen informaci√≥n sobre 227 pa√≠ses. Exploremos m√°s a fondo estos dato: concretamente, ¬øcu√°ntos pa√≠ses hay en cada regi√≥n del mundo?\nPara ello, tendremos que utilizar un gr√°fico de recuento. Los gr√°ficos de recuento toman una lista categ√≥rica y devuelven barras que representan el n√∫mero de entradas de la lista por categor√≠a. Puedes crear una aqu√≠ utilizando una lista de regiones para cada pa√≠s, que es uva variable llamada region.\n\n# Se convierte la columna Region en lista y se quitan los espacios\nregion = df['Region'].tolist()\nregion = [item.strip() for item in region]\n\n\nInstrucciones\n\nImporta Matplotlib y Seaborn utilizando las convenciones de nomenclatura est√°ndar.\nUtiliza Seaborn para crear un gr√°fico de recuento con region en el eje y.\nVisualiza el gr√°fico\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create count plot with region on the y-axis\nsns.countplot(y=region)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n√Åfrica Subsahariana contiene la mayor√≠a de los pa√≠ses en esta lista.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Introducci√≥n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#utilizar-pandas-con-seaborn",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#utilizar-pandas-con-seaborn",
    "title": "Introducci√≥n a Seaborn",
    "section": "Utilizar pandas con Seaborn",
    "text": "Utilizar pandas con Seaborn\n\nQu√© es Pandas?\n\nLibrer√≠a de Python para an√°lisis de datos.\nPuede leer conjunto de datos de m√∫ltiples tipos de archivos. Por ejemplo csv, txt.\nEl conjunto de datos toma la forma de objeto DataFrame.\n\nTrabajando con DataFrames\n\n\nimport pandas as pd\ndf = pd.read_csv('masculinity.csv')\ndf.head()\n\n\nUsando DataFrames con countplot()\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('masculinity.csv')\nsns.countplot(x='how_masucline', data=df)\nplt.show()\n\n\nDatos ‚Äúordenados‚Äù frente a datos ‚Äúdesordenados‚Äù\nAqu√≠ tenemos un conjunto de datos que muestra de una encuesta a ni√±os sobre sus animales favoritos. Pros, ¬øPodemos utilizar este conjunto de datos tal cual con Seaborn? Vamos a utilizar pandas para importar el archivo csv con los datos recogidos en la encuestra y determinar si est√° ordenado, lo cual es esencial para que funcione bien con Seaborn.\nPara empezar, se ha asignado la tura del archivo csv a la variable csv_filepath.\n\nInstrucciones\n\n\n\n\nLee el archivo csv situado en csv_filepath en un DataFrame llamado df.\nImprime la cabecera de df para mostrar las cinco primeras filas.\n\n\ncsv_filepath = './data/1.2.1_example_csv.csv'\n\n\n# Import pandas\nimport pandas as pd\n\n# Create a DataFrame from csv file\ndf = pd.read_csv(csv_filepath)\n\n# Print the head of df\nprint(df.head())\n\n  Unnamed: 0               How old are you?\n0     Marion                             12\n1      Elroy                             16\n2        NaN  What is your favorite animal?\n3     Marion                            dog\n4      Elroy                            cat\n\n\n\nPregunta\n\nVisualiza las cinco primeras filas del DataFrame df. ¬øEst√° ordenado? ¬øPor qu√© si o por qu√© no?\nRespuestas posibles\n\nSi, porque no hay erratas ni faltan valores.\nSi, porque est√° vien organizado y es f√°cil de leer.\nNo, porque una misma columna contiene distintos tipos de formaci√≥n.\n\n\n\n\nHacer un gr√°fico de recuento con un DataFrame\nEn este ejercicio examinaremos las respuestas a una encuesta enviada a los j√≥venes. Nuestra pregunta principal aqu√≠ es: ¬øcu√°ntos j√≥venes encuestados afirman tener miedo a las ara√±as? Se pidi√≥ a los participantes en la encuesta que estuvieran de acuerdo o en desacuerdo con la afirmaci√≥n ‚ÄúTengo miedo a las ara√±as‚Äù. Las respuestas var√≠an de 1 a 5, donde 1 es ‚ÄúTotalmente en desacuerdo‚Äù y 5 es ‚ÄúTotalmente de acuerdo‚Äù.\nPara empezar, la ruta del archivo csv con los datos de la encuesta se ha asignado a la variable csv_filepath.\n\nInstrucciones\n\nImporta Matplotlib, pandas y Seaborn utilizando los nombres est√°ndar.\nCrea un DataFrame llamado df a partir del archivo csv situado en csv_filepath.\nUtilizando la funci√≥n countplot() con los argumentos x= y data= para crear un gr√°fico de recuento con los valores de la columna \"Spiders\" en el eje x.\nVisualiza el gr√°fico.\n\n\ncsv_filepath = './data/young-people-survey-responses.csv'\n\n\n# Import Matplotlib, pandas and Seaborn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a DataFrame from csv file\ndf = pd.read_csv(csv_filepath)\n\n# Create a countplot with \"Spiders\" on the x-axis\nsns.countplot(x='Spiders', data=df)\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nEste gr√°fico nos muestra que la gran mayor√≠a de los j√≥venes informaron no tener miedo a las ara√±as.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Introducci√≥n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#a√±adir-una-tercera-variable-con-el-tono",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/01_Introduccion_a_seaborn.html#a√±adir-una-tercera-variable-con-el-tono",
    "title": "Introducci√≥n a Seaborn",
    "section": "A√±adir una tercera variable con el tono",
    "text": "A√±adir una tercera variable con el tono\nPara probarlos usaremos el siguiente Dataset:\n\nDataset Tips\n\n\nimport pandas as pd\nimport seaborn as sns\ntips = pd.read_csv('./data/tips.csv')\ntips.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\nUn Scatter plot b√°sico\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nUn Scatter plot con hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nConfigurando el orden del hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker',\n                hue_order=['Yes',\n                            'No'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\nEspecificando los colores de hue\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {'Yes': 'black',\n              'No': 'red'}\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips,\n                hue='smoker',\n                palette=hue_colors)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nUsando hue con count plots\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.countplot(x='smoker',\n              data=tips,\n              hue='sex')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nGr√°ficos de tono y dispersi√≥n\nEn el video anterior aprendimos como hue nos permite hacer f√°cilmente subgrupos dentro de los gr√°ficos de Seaborn. Vamos a probarlo explorando los datos de los alumnos de secundaria. Tenemos mucha informaci√≥n sobre cada alumno, como su edad, d√≥nde vive, sus h√°bitos de estudio y sus actividades extraescolares.\nPor ahora, nos fijaremos en la relaci√≥n entgre el n√∫mero de faltas que tienen en la escuela y su calificaci√≥n final en el curso, segmentada por el lugar donde vive el alumno (zona rural frente a zona urbana).\n\nstudent_data = pd.read_csv('./data/student-alcohol-consumption.csv', index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows √ó 29 columns\n\n\n\n\nInstrucciones\n\nCrea un gr√°fico de dispersi√≥n con absensces en el eje x y la calificaci√≥n final (\"G3\") en el eje y utilizando el DataFrame student_data. Colorea los puntos del gr√°fico en funci√≥n de \"location\" (urbano vs.¬†rural)\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a scatter plot of absences vs. final grade\nsns.scatterplot(x='absences', \n                y='G3',\n                data=student_data,\n                hue='location')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nHaz que rural aparezca antes que urban en la leyenda del gr√°fico.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Change the legend order in the scatter plot\nsns.scatterplot(x='absences', \n                y='G3',\n                data=student_data,\n                hue='location',\n                hue_order=['Rural', 'Urban'])\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes con m√°s ausencias tienden a tener calificaciones m√°s bajas tanto en √°reas rurales como urbanas.\n\n\n\nGr√°ficos de tono y recuento\nSigamos explorando nuestro conjunto de datos de alumnos de secundaria examinando una nueva variable. La columna school indica las iniciales de la escuela a la que asisti√≥ al alumno: ‚ÄúGP‚Äù o ‚ÄúMS‚Äù.\nEn el √∫ltimo ejercicio, creamos un gr√°fico de dispersi√≥n en el que los puntos del gr√°fico se coloreaban en funci√≥n de si el alumno viv√≠a en zona urbana o rural. ¬øCu√°ntos alumnos viven en zonas urbanas frente a zonas rurales, y var√≠a esto en funci√≥n de la escuela a la que asiste el alumno? Hagamos un gr√°fico de recuento con subgrupos para averiguarlo.\n\nInstrucciones\n\nRellena el diccionario palette_colors para asignar el valor de ubicaci√≥n \"Rural\" al color \"green\" y el valor de ubicaci√≥n \"Urban\" al color \"blue\".\nCrea un gr√°fico de recuento con \"school\" en el eje x utilizando el DataFrame student_data.\n\nA√±ade subgrupos al gr√°fico, utilizando la variable \"location\"`` y utliliza el diccionariopalette_colors` para que los subgrupos de ubicaci√≥n sean verdes o azules.\n\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a dictionary mapping subgroup values to colors\npalette_colors = {'Rural': 'green',\n                  'Urban': 'blue'}\n\n# Create a count plot of school with location subgroups\nsns.countplot(x='school',\n              data=student_data,\n              hue='location',\n              palette=palette_colors)\n\n# Display plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes en GP tienden a venir de una ubicaci√≥n urbana, pero los estudiantes en MS est√°n m√°s equitativamente divididos.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Introducci√≥n a Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html",
    "title": "Visualizar dos variables cuantitativas",
    "section": "",
    "text": "Introducci√≥n a las plots (tramas) y subplots (subtramas) relacionales\nEn este cap√≠ulo, crear√°s y personalizar√°s gr√°ficos que visualizan la relaci√≥n entre dos variables cuantitativas. Para ello, utilizar√°s gr√°ficos se dispersi√≥n y de l√≠neas para explorar c√≥mo cambia el nivel de contaminaci√≥n atmosf√©rica en una ciudad a lo largo de un d√≠a y c√≥mo se relacionan los caballos de potencia con la eficiencia del combustible en los coches. Tambi√©n ver√°s otra gran ventaja de utilizar Seaborn: ¬°la posibilidad de crear f√°cilmente subtramas en una sola figura!\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='smoker')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            row='smoker')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='smoker',\n            row='time')\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day')\nplt.show()\nEl gr√°fico se ve peque√±o si todos estan en la misma fila\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day',\n            col_wrap=2)\nplt.show()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter',\n            col='day',\n            col_wrap=2,\n            col_order=['Thur',\n                       'Fri',\n                       'Sat',\n                       'Sun'])\nplt.show()",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci√≥n-a-las-plots-tramas-y-subplots-subtramas-relacionales",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci√≥n-a-las-plots-tramas-y-subplots-subtramas-relacionales",
    "title": "Visualizar dos variables cuantitativas",
    "section": "",
    "text": "Gr√°ficos relacionales\n\nAltura vs Peso\nN√∫mero de ausencias de un alumno vs Nota final\nGDP vs Personas que saben leer y escribir\n\nIntruducci√≥n a relplot()\n\nCrea gr√°ficos relacionales: scatterplots o line plots\n¬øPor qu√© usar relplot() en lugar de scatterplot()?\n\nrelplot() permite crear subgr√°ficos en una sola figura.\n\n\nScatterplot() vs relplot()\n\n# para poder mostrar el dataset en los ejemplos\nimport pandas as pd\ntips = pd.read_csv('./data/tips.csv')\n\n\nUsando scatterplot()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.scatterplot(x='total_bill',\n                y='tip',\n                data=tips)\nplt.show()\n\n\n\n\n\n\n\n\n\nUsando relplot()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill',\n            y='tip',\n            data=tips,\n            kind='scatter')\nplt.show()\n\n\n\n\n\n\n\n\nSubplots en columnas\n\n\n\nSubplots en filas\n\n\n\nSubplots en filas y columnas\n\n\n\nSubgrupos por d√≠a de la semana\n\n\n\n\nWrapping columns\n\nSe pueden establecer dos gr√°ficos por fila\n\n\n\n\nOrden de las columnas\n\n\n\nCrear subtramas con columna y fila\nHemos visto en ejercicios anteriores que los alumnos con m√°s faltas (\"absences\") tienden a tener notas finales m√°s bajas (\"G3\"). ¬øSe mantiene esta relaci√≥n independientemente de cu√°nto tiempo estudien los alumnos cada semana?\nPara responder a esto, observaremos la relaci√≥n entre el n√∫mero de faltas de asistencia a clase de un alumno y su calificaci√≥n final en el curso, creando subtramas separadas en funci√≥n del tiempo de estudio semanal de cada alumnos (\"study_time\").\n\nimport pandas as pd\nstudent_data = pd.read_csv('./data/student-alcohol-consumption.csv', index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows √ó 29 columns\n\n\n\n\nInstrucciones\n\nModifica el c√≥digo paora utilizar relplot() en lugar de scatterplot().\n\n\n# Change to use relplot() instead of scatterplot()\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nModifica el c√≥digo para crear un gr√°fico de dispersi√≥n para cada nivel de la variable \"study_time\", ordenado en columnas.\n\n\n# Change to make subplots based on study time\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='study_time')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nAdapta tu c√≥digo para crear un gr√°fico de dispersi√≥n para cada nivel del tiempo de estudio semanal de un alumno, esta vez ordenado en filas.\n\n\n# Change this scatter plot to arrange the plots in rows instead of columns\nsns.relplot(x='absences', y='G3',\n            data=student_data,\n            kind='scatter',\n            row='study_time')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDebido a que estos subgr√°ficos ten√≠an un gran rango de valores x, es m√°s f√°cil leerlos dispuestos en filas en lugar de columnas.\n\n\n\nCrear subtramas de dos factores\nSigamos examinando el conjunto de datos student_data de alumnos de secundaria. Aqu√≠ queremos responder a la siguiente pregunta: ¬øla nota del primer semestre de un alumno (\"G1\") tiende a correlacionarse con su nota final (\"G3\")?\nHay muchos aspectos de la vida de un alumno que pueden dar lugar a una nota final m√°s alta o m√°s baja en la clase. Por ejemplo, algunos alumnos reciben apoyo educativo adicional de su centro escolar (\"schoolsup\") o de su familia (\"famsup\"), lo que podr√≠a traducirse en mejores notas. Intentamos controlar estos dos factores creando subtramas en funci√≥n de si el alumno recibi√≥ apoyo educativo adicional de su escuela o de su familia.\n\nInstrucciones\n\nUtiliza relplot() para crear un gr√°fico de dispersi√≥n con \"G1\" en el eje x y \"G3\" en el eje y, utilizando el DataFrame student_data\n\n\n# Create a scatter plot fo G1 vs. G3\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            )\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCrea subtramas de columnas en funci√≥n de su el alumno recibi√≥ ayuda de la escuela (\"schoolsup\"), ordenadas de forma que ‚Äúsi‚Äù vaya antes que ‚Äúno‚Äù.\n\n\n# Adjust to add subplots based on school support\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='schoolsup',\n            col_order=['yes', 'no']\n            )\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA√±ade subgrupos de filas en funci√≥n de su el alumno recibi√≥ ayuda de la familia (\"famsup\"), ordenados de forma que ‚Äúsi‚Äù vaya antes que ‚Äúno‚Äù. Esto dar√° lugar a subtramas basadas en dos factores.\n\n\n# Adjust further to add subplots based on family support\nsns.relplot(x='G1', y='G3',\n            data=student_data,\n            kind='scatter',\n            col='schoolsup',\n            col_order=['yes', 'no'],\n            row='famsup',\n            row_order=['yes', 'no'])\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la nota del primer semestre si correlaciona con la nota final, independientemente dl tipo de apoyo que recibi√≥ el estudiante.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#personalizar-gr√°ficos-de-dispersi√≥n",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#personalizar-gr√°ficos-de-dispersi√≥n",
    "title": "Visualizar dos variables cuantitativas",
    "section": "Personalizar gr√°ficos de dispersi√≥n",
    "text": "Personalizar gr√°ficos de dispersi√≥n\n\nResumen Scatter plot\n\nMuestran la realci√≥n entre dos variables cuantitativas.\nHemos visto:\n\nSubplots (col y row)\nSubgrupos con color (hue)\n\nNuevas personalizaciones:\n\nSubgrupos con tama√±o de punto y estilo.\nCambio en la transparencia de los puntos.\n\nSe pueden utilizar en scatterplot() y relplot()\n\nSubgrupos con tama√±o de punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            size='size')\nplt.show()\n\n\n\n\n\n\n\n\nEl gr√°fico anterior es dif√≠cil de leer pues todos los puntos son del mismo color. Su visualizaci√≥n puede facilitarse utilizando lo siguiente:\n\nTama√±o de punto y hue\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            size='size',\n            hue='size')\nplt.show()\n\n\n\n\n\n\n\n\n\nSubbrupos con estilo de punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            hue='smoker',\n            size='smoker')\nplt.show()\n\n\n\n\n\n\n\n\n\nCambiando la transparencia del punto\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set alpha to be between 0 and 1\nsns.relplot(x='total_bill', y='tip',\n            data=tips,\n            kind='scatter',\n            alpha=0.4)\n\nplt.show()\n\n\n\n\n\n\n\n\nEste √∫ltimo gr√°fico es muy √∫til cuando hay gran concentraci√≥n de puntos\n\nCambiar el tama√±o de los puntos del diagrama del dispersi√≥n\nEn este ejercicio, exploraremos el conjunto de datos mpg de Seaborn, que contiene una fila por modelo de coche e incluye informaci√≥n como el a√±o de fabricaci√≥n del coche, el n√∫mero de millas por gal√≥n (‚ÄúM.P.G.‚Äù) que alcanza, la potencia de su motor (medida en ‚Äúcaballos‚Äù) y su pa√≠s de origen.\n¬øCu√°l es la relaci√≥n entre la potencia del motor de un coche (\"horsepower\") y su eficiencia de combustible (\"mpg\")? ¬øY c√≥mo var√≠a esta relaci√≥n seg√∫n el n√∫mero de cilindros (\"cylinders\") que tenga el coche? Averig√º√©moslo.\nSigamos utilizando relplot() en lugar de scatterplot() ya que ofrece m√°s flexibilidad.\n\nimport pandas as pd\nmpg = pd.read_csv('./data/mpg.csv')\nmpg.head()\n\n\n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nmodel_year\norigin\nname\n\n\n\n\n0\n18.0\n8\n307.0\n130.0\n3504\n12.0\n70\nusa\nchevrolet chevelle malibu\n\n\n1\n15.0\n8\n350.0\n165.0\n3693\n11.5\n70\nusa\nbuick skylark 320\n\n\n2\n18.0\n8\n318.0\n150.0\n3436\n11.0\n70\nusa\nplymouth satellite\n\n\n3\n16.0\n8\n304.0\n150.0\n3433\n12.0\n70\nusa\namc rebel sst\n\n\n4\n17.0\n8\n302.0\n140.0\n3449\n10.5\n70\nusa\nford torino\n\n\n\n\n\n\n\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr√°fico de dispersi√≥n con \"horsepower\" en el eje x y \"mpg\" en el eje y. Var√≠a el tama√±o de los puntos seg√∫n el n√∫mero de cilindros del coche (\"cylinders\").\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create scatter plot of horsepower vs. mpg\nsns.relplot(x='horsepower', y='mpg',\n            data=mpg,\n            kind='scatter',\n            size='cylinders')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPara que el gr√°fico se m√°s f√°cil de leer, utiliza hue para variar el color de los puntos seg√∫n el n√∫mero de cilindros del coche (\"cylinders\").\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='horsepower', y='mpg',\n            data=mpg,\n            kind='scatter',\n            size='cylinders',\n            hue='cylinders')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos coches con mayor potencia tienden a tener un menor n√∫mero de millas por gal√≥n. Tambi√©n tienden a tener un mayor n√∫mero de cilindros.\n\n\n\nCambiar el estilo de los puntos del gr√°fico de dispersi√≥n\nSigamos explorando el conjunto de datos mpg de Seaborn observando la relaci√≥n entre la velocidad a la que se puede acelerar un coche (\"acceleration\") y su eficiencia de combustible (\"mpg\"). ¬øVar√≠an estas propiedades seg√∫n el pa√≠s de origen (\"origin\")?\nObserva que la variable \"acceleration\" es el tiempo de aceleraci√≥n de 0 a 60 millas por hora, en segundos. Los valores m√°s altos indican una aceleraci√≥n m√°s lenta.\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr√°fico de dispersi√≥n con \"acceleration\" en el eje x y \"mpg\" en el eje y. Var√≠a el estilo y el color de los puntos de la trama seg√∫n el pa√≠s de origen (\"origin\").\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a scatter plot of acceleration vs. mpg\nsns.relplot(x='acceleration', y='mpg',\n            data=mpg,\n            kind='scatter',\n            style='origin',\n            hue='origin')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos coches de EE.UU tienden a acelerar m√°s r√°pido y obtener menos millas por gal√≥n en comparaci√≥n con los coches de Europa y Jap√≥n.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci√≥n-a-los-gr√°ficos-lineales",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/02_Visualizar_dos_variables_cuantitativas.html#introducci√≥n-a-los-gr√°ficos-lineales",
    "title": "Visualizar dos variables cuantitativas",
    "section": "Introducci√≥n a los gr√°ficos lineales",
    "text": "Introducci√≥n a los gr√°ficos lineales\n\nQu√© son los diagramas de lineas?\n\nHay dos tipos de gr√°ficos relacionales: scatterpltos y lineplots\nScatterplots\n\nCada punto en el gr√°fico es una observaci√≥n independiente.\n\nLineplots\n\nCada punto representa la misma cosa, t√≠picamente seguida por el tiempo.\n\n\nEjemplo de Scatterplot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='scatter')\nplt.show()\n\n\n\nEjemplot de lineplot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line')\nplt.show()\n\n\n\nSubgrupos por localizaci√≥n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location')\nplt.show()\n\n\n\nA√±adiendo marcadores\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location',\n            markers=True)\nplt.show()\n\n\n\nApagando los estilos de l√≠neas\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2_mean',\n            data=air_df_mean,\n            kind='Line',\n            style='location',\n            hue='location',\n            markers=True,\n            dashes=False)\nplt.show()\n\n\n\nM√∫ltiples observaciones por valor de x\n\nScatter plot\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='scatter')\n\nplt.show()\n\n\n\nLine plot\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='Line')\n\nplt.show()\n\n\n- La regi√≥n sombreada es el intervalo de confianza\n    - Asuma que el dataset es una muestra aleatoria\n    - Hay 95% de confianza que la media est√° dentro de este intervalo.\n    - Indicar la incertidumbre de nuestra estimaci√≥n.\n\nReemplzando el intervalo de confianza con la desviaci√≥n est√°ndar.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='line',\n            ci='sd')\nplt.show()\n\n\n\nDesactivando el intervalo de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.relplot(x='hour', y='NO_2',\n            data=air_df,\n            kind='line',\n            ci=None)\nplt.show()\n\n\n\nInterpretaci√≥n de gr√°ficos lineales\nEn este ejercicio, seguiremos explorando el conjunto de datos mpg de Seaborn, que contiene una fila por modelo de coche e incluye informaci√≥n como el a√±o de fabricaci√≥n del coche, su eficacia de combustible (medida en ‚Äúmillas por gal√≥n‚Äù o ‚ÄúM.P.G‚Äù) y su pa√≠s de origen (USA, Europa o Jap√≥n).\n¬øC√≥mo ha cambiado con el tiempo la media de millas por gal√≥n que alcanzan estos coches? ¬°Utilicemos gr√°ficos lineales para averiguarlo!\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr√°fico de l√≠neas con \"model_year\" en el eje x y \"mpg\" en el eje y.\n\n\n# Import Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a line plot\nsns.relplot(x='model_year', y='mpg',\n            data=mpg,\n            kind='line')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPreguntas\n\n¬øCu√°l de las siguientes no es una interpretaci√≥n correcta de este gr√°fico?\nRespuestas posibles\n\nEl promedio de millas por gal√≥n ha aumentado generalmente con el tiempo.\nLa distribuci√≥n de millas por gal√≥n es menor en 1973 que en 1977.\nEl intervalo de confianza del 95 % para la media de millas por gal√≥n en 1970 es de aproximadamente 16 - 19,5 millas por gal√≥n.\nEste gr√°fico supone nuestros datos son una muestra aleatoria de todos los coches de US, Europa y Jap√≥n.\n\nLa regi√≥n sombreada representa un intervalo de confianza para la media, no la distribuci√≥n de las observaciones.\n\n\n\nVisualizaci√≥n de la desviaci√≥n est√°ndar con gr√°fico de l√≠neas\nEn el √∫ltimo ejercicio, vimos c√≥mo ha cambiado a lo largo del tiempo la media de millas por gal√≥n que alcanzan los coches. Ahora utilicemos un gr√°fico lineal para visualizar c√≥mo ha cambiado la distribuci√≥n de millas por gal√≥n a lo largo del tiempo.\n\nInstrucciones\n\nCambia el gr√°fico para que el √°rea sombreada muestre la desviaci√≥n est√°ndar en lugar del intervalo de confianza para la media.\n\n\n# Make the shaded area show the standard deviation\nsns.relplot(x='model_year', y='mpg',\n            data=mpg,\n            kind='line',\n            errorbar='sd') # el par√°metro ci fue deprecado\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nA diferencia del gr√°fico en el √∫ltimo ejercicio, este gr√°fico nos muestra la distribuci√≥n de millas por gal√≥n para todos los coches en cada a√±o.\n\n\n\nTrazar subgrupos en gr√°ficos de l√≠neas\nSigamos examinando el conjunto de datos mpg. Hemos visto que la media de millas por gal√≥n de los coches ha aumentado con el tiempo, pero, ¬øc√≥mo ha cambiado la media de caballos de los coches con el tiempo? ¬øY difiere esta tendencia seg√∫n el pa√≠s de origen?\n\nInstrucciones\n\nUtiliza relplot() y el DataFrame mpg para crear un gr√°fico de l√≠neas con \"model_year\" en el eje x y \"horse_power\" en el eje y. Desactiva los intervalos de confianza en el gr√°fico.\n\n\n# Import matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create line plot of model year vs. horsepower\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None)\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCrea l√≠neas diferentes para cada pa√≠s (\"origin\") que var√≠en tanto en estilo de l√≠nea como en color.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create line plot of model year vs. horsepower\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None,\n            style='origin',\n            hue='origin')\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA√±ade marcadores para cada punto de datos a las l√≠neas.\n\n\nUtiliza el par√°metro dashes para utilizar l√≠neas continuas para todos los pa√≠ses, permitiendo al mismo tiempo diferentes estilos de marcador para cada l√≠nea.\n\n\nsns.relplot(x='model_year', y='horsepower',\n            data=mpg,\n            kind='line',\n            errorbar=None,\n            style='origin',\n            hue='origin',\n            markers=True,\n            dashes=False)\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nAhora hemos a√±adido subgrupos, podemos ver que esta tendencia a la baja en la potencia fue m√°s pronunciada entre los coches de EE.UU.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Visualizar dos variables cuantitativas</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html",
    "title": "Visualizar una variable categ√≥rica y una cuantitativa",
    "section": "",
    "text": "Gr√°ficos de recuento y de barras.\nLas variables categ√≥ricas est√°n presentes en casi todos los conjuntos de datos, pero destacan especialmente en los datos de encuestas. En este cap√≠tulo aprender√°s a crear y personalizar gr√°ficos categ√≥ricos, como gr√°ficos de caja, gr√°ficos de barras, gr√°ficos de recuentro y gr√°ficos de puntos. Por el camino, explorar√°s datos de encuestas a j√≥venes sobre sus intereses, a estudiantes sobre sus h√°bitos de estudio y a hombres adultos sobre sus sentimientos acerca de la masculinidad.\nimport matplotlib.pyplot as plt\nimport seaborn as from django.conf import settings\nsns.countplot(x='how_masculine',\n              data=maculinity_data)\n\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count')\n\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncategory_order=['No answer',\n                'Not at all',\n                'Not very',\n                'Somewhat',\n                'Very']\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count',\n            order=category_order)\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='day', y='total_bill',\n            data=tips,\n            kind='bar')\nplt.show()\nimport matplotlib.plyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='day', y='total_bill',\n            data=tips,\n            kind='bar',\n            ci=None)\nplt.show()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='total_bill', y='day',\n            data=tips,\n            kind='bar')\nEs com√∫n poner la variable categ√≥rica en el eje x",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Visualizar una variable categ√≥rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr√°ficos-de-recuento-y-de-barras.",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr√°ficos-de-recuento-y-de-barras.",
    "title": "Visualizar una variable categ√≥rica y una cuantitativa",
    "section": "",
    "text": "Gr√°ficos categ√≥ricos\n\nEjemplos: Gr√°ficos de recuento y de barras\nIncluyen variables categ√≥ricas.\nComparaciones entre grupos\n\n\ncatplot()\n\nUsado para crear gr√°ficos categ√≥ricos\nTiene las mismas ventajas de relplot()\nSe pueden crear facilmente subgr√°ficos con col= y row=\n\ncountplot() vs.¬†catplot()\n\n\n\n\nCambiando el orden\n\n\n\n\nGr√°fico de barras\n\nMuestran la media de una variable cuantitativa por categor√≠a\n\n\n\n\n\nIntervalos de confianza\n\nLas l√≠neas muestran los intervalos de confianza del 95% para la media.\nMuestran el nivel de incertidumbre sobre las estimaciones.\nAsumiendo que nuestros datos sean una muestra aleatoria.\n\nDesactivando los intervalos de confianza\n\n\n\n\nCambiando la orientaci√≥n de las barras\n\n\n\n\n\nGr√°ficos de recuento\nEn este ejercicio, volveremos a explorar nuestro conjunto de datos que contiene las respuestas a una encuesta enviada a los j√≥venes. Podr√≠amos sospechar que los j√≥venes pasan mucho tiempo en internet, pero ¬øCu√°nto declaran utilizar internet al d√≠a? Utilicemos un gr√°fico de recunto para desglosar el n√∫mero de respuestas de la encuesta en cada categor√≠a y luego exploremos si cambia en funci√≥n de la edad.\nComo recordatorio, para crear un gr√°fico de recuento, utilizaremos la funci√≥n catplot() y especificaremos el nombre de la variable categ√≥rica a contar (x=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr√°fico (kind=\"count\").\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = (10, 5)\n\nruta = './data/young-people-survey-responses.csv'\nsurvey_data = pd.read_csv(ruta, index_col=0)\nsurvey_data.head()\n\n\n\n\n\n\n\n\nMusic\nTechno\nMovies\nHistory\nMathematics\nPets\nSpiders\nLoneliness\nParents' advice\nInternet usage\nFinances\nAge\nSiblings\nGender\nVillage - town\nAge Category\nInterested in Math\n\n\n\n\n0\n5.0\n1.0\n5.0\n1.0\n3.0\n4.0\n1.0\n3.0\n4.0\nfew hours a day\n3.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n1\n4.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n2.0\n2.0\nfew hours a day\n3.0\n19.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n2\n5.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n5.0\n3.0\nfew hours a day\n2.0\n20.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n3\n5.0\n2.0\n5.0\n4.0\n4.0\n1.0\n5.0\n5.0\n2.0\nmost of the day\n2.0\n22.0\n1.0\nfemale\ncity\n21+\nTrue\n\n\n4\n5.0\n2.0\n5.0\n3.0\n2.0\n1.0\n1.0\n3.0\n3.0\nfew hours a day\n4.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n\n\n\n\n\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr√°fico de recuento utilizando el DataFrame survery_data con \"Internet usage\" en el eje x.\n\n\n# Create count plot of internet usage\nsns.catplot(x='Internet usage',\n            data=survey_data,\n            kind='count')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nHaz que las barras sean horizontales en lugar de verticales\n\n\n# Change the orientation of the plot\nsns.catplot(y='Internet usage',\n            data=survey_data,\n            kind='count')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nSepara este gr√°fico en dos subtramas de columnas contiguas en funci√≥n de \"Age Category\", que separa a los encuestados en menores de 21 a√±os y mayores de 21 a√±os. A partir de 21 a√±os.\n\n\n# Separate ubti cikynb subplots based on age category\nsns.catplot(y='Internet usage',\n            data=survey_data,\n            kind='count',\n            col='Age Category')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la mayor√≠a de los j√≥venes usan internet durante pocas horas todos los d√≠as, independientemente de su edad.\n\n\n\nDiagramas de barras con porcentajes\nSigamos explorando las respuestas a una encuesta enviada a los j√≥venes. La variable \"Interested in Math\" es True si la persona declar√≥ estar interesada o muy interesada en las matem√°ticas, y False en caso contrario. ¬øQu√© porcentaje de j√≥venes afirma estar interesado en las matem√°ticas, y var√≠a esto en funci√≥n del g√©nero? Utilicemos un diagrama de barras para averiguarlo.\nComo recordatorio, crearemos un gr√°fico de barras utilizando la funci√≥n catplot(), proporcionando el nombre de la varible categ√≥rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr√°fico categ√≥rico (kind=\"bar\").\n\nInstrucciones\n\nUtiliza el DataFrame survey_data y sns.catplot() para crear un gr√°fico de barras con \"Gender\" en el eje x y \"Interested in Math\" en el eje y.\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create a bar plot of interest in math, separated by gender \nsns.catplot(x='Gender', y='Interested in Math',\n            data=survey_data,\n            kind='bar')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nCuando la variable y es Verdadero/Falso, los gr√°ficos de barras mostrar√°n el porcentaje de respuestas que informan Verdadero. Este gr√°fico nos muestra que los hombres informan un inter√©s mucho mayor en las matem√°ticas en comparaci√≥n con las mujeres.\n\n\n\nPersonalizar gr√°ficos de barras\nEn este ejercicio, exploraremos datos de alumnos de secundaria. La variable \"study_time\" registra el tiempo de estudio semanal declarado por cada estudiante como una de las siguientes categor√≠as: \"&lt;2 hours\", \"2 to 5 hours\", \"5 to 10 hours\", o \"&gt;10 hours\". ¬øLos alumnos que declaran estudiar m√°s tienden a obtener mejores notas finales Comparemos la nota media final entre los alumnos de cada categor√≠a mediante un diagrama de barras.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/student-alcohol-consumption.csv'\nstudent_data = pd.read_csv(ruta, index_col=0)\nstudent_data.head()\n\n\n\n\n\n\n\n\nschool\nsex\nage\nfamsize\nPstatus\nMedu\nFedu\ntraveltime\nfailures\nschoolsup\n...\ngoout\nDalc\nWalc\nhealth\nabsences\nG1\nG2\nG3\nlocation\nstudy_time\n\n\n\n\n0\nGP\nF\n18\nGT3\nA\n4\n4\n2\n0\nyes\n...\n4\n1\n1\n3\n6\n5\n6\n6\nUrban\n2 to 5 hours\n\n\n1\nGP\nF\n17\nGT3\nT\n1\n1\n1\n0\nno\n...\n3\n1\n1\n3\n4\n5\n5\n6\nUrban\n2 to 5 hours\n\n\n2\nGP\nF\n15\nLE3\nT\n1\n1\n1\n3\nyes\n...\n2\n2\n3\n3\n10\n7\n8\n10\nUrban\n2 to 5 hours\n\n\n3\nGP\nF\n15\nGT3\nT\n4\n2\n1\n0\nno\n...\n2\n1\n1\n5\n2\n15\n14\n15\nUrban\n5 to 10 hours\n\n\n4\nGP\nF\n16\nGT3\nT\n3\n3\n1\n0\nno\n...\n2\n1\n2\n5\n4\n6\n10\n10\nUrban\n2 to 5 hours\n\n\n\n\n5 rows √ó 29 columns\n\n\n\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr√°fico de barras con \"study_time\" en el eje x y la calificaci√≥n final (\"G3\") en el eje y, utilizando el DataFrame student_data.\n\n\n# Create bar plot of average final grade in each study category\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nUtilizando el par√°metro order y la lista category_order que se proporciona, reorganiza las barras para que est√©n en orden de menor tiempo de estudio a mayor.\n\n\n# List of categories from lowest to highest\ncategory_order = ['&lt;2 hours',\n                  '2 to 5 hours',\n                  '5 to 10 hours',\n                  '&gt;10 hours']\n\n# Rearrange the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar',\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nActualiza el gr√°fico para que ya no muestre los intervalos de confianza.\n\n\n# List of categories from lowest to highest\ncategory_order = ['&lt;2 hours',\n                  '2 to 5 hours',\n                  '5 to 10 hours',\n                  '&gt;10 hours']\n\n# Rearrange the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='bar',\n            order=category_order,\n            errorbar=None) # ci=None deprecated\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLos estudiantes en nuestra muestra que estudiaron m√°s tienen un promedio de calificaciones ligeramente m√°s alto, pero no es una relaci√≥n fuerte.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Visualizar una variable categ√≥rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#diagramas-de-caja",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#diagramas-de-caja",
    "title": "Visualizar una variable categ√≥rica y una cuantitativa",
    "section": "Diagramas de caja",
    "text": "Diagramas de caja\n\n¬øQu√© es un diagrama de caja?\n\nMuestra la distribuci√≥n de datos cuantitativos.\nSe puede ver la mediana, la dispersi√≥n, la asimetr√≠a y los datos at√≠picos.\nFacilita la comparaci√≥n entre grupos.\n\n\n\n\nC√≥mo crear un diagrama de caja en Seaborn\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box')\nplt.show()\n\n\n\nCambiar el orden de las categor√≠as\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                order=['Dinner',\n                        'Lunch'])\nplt.show()\n\n\n\nOmitir los valores at√≠picos usando sym\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                sym='')\nplt.show()\n\n\n\nCambiando los bigotes usando whis\n\nPor defecto, los bigotes se extienden a 1.5 * el rango intercuartil.\nPuede ser extendido a 2.0 * IQR: whis=2.0\nMuestra los percentiles 5 y 95: whis=[5, 95]\nMuestra los valores m√≠nimo y m√°ximo: whis=[0, 100]\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ng = sns.catplot(x='time', y='total_bill',\n                data=tips,\n                kind='box',\n                whis=[0, 100])\nplt.show()\n\n\n\nCrea e interpreta un diagrama de cajas\nSigamos utilizando el conjunto de datos student_data. En un ejercicio anterior, exploramos la realci√≥n entre el estudio y la nota final utlizando un digrama de barras para comparar la nota final media (\"G3\") entre los estudiantes de diferentes categor√≠as de \"study_time\".\nEn este ejercicio, intentaremos utilizar un diagrama de cajas para ver esta relaci√≥n. Como recordatorio, para crear un gr√°fico de caja tendr√°s que utilizar la funci√≥n catplot() y especificar el nombre de la variable categ√≥rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrme de pandas a utilizar (data=____), y el timpo de gr√°fico (kind=\"box\").\n\nInstrucciones\n\nUtiliza sns.catplot(), y el DataFrame student_data para crear un gr√°fico de caja con \"study_time\" en el eje x y \"G3\" en el eje y. Establece el orden de las categor√≠as en study_time_order.\n\n\n# Specify the category ordering\nstudy_time_order = ['&lt;2 hours', '2 to 5 hours',\n                    '5 to 10 hours', '&gt;10 hours']\n\n# Create a box plot and set the order of the categories\nsns.catplot(x='study_time', y='G3',\n            data=student_data,\n            kind='box',\n            order=study_time_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta ¬ø Cu√°l de las siguientes es una interpretaci√≥n correcta de este diagrama de caja?\n\nRespuestas Posibles\n\nEl percentil 75 de las notas es m√°s alto entre los alumnos que estudian m√°s de 10 horas a la semana.\nNo hay valores at√≠picos en estos gr√°ficos de caja.\nEl percentil 5 de las notas entre los alumnos que estudian memnos de 2 horas es de 5,0.\nLa nota media entre los alumnos que estudian menos de 2 horas es de 10,0.\n\nLa l√≠nea del medio de cada caja representa la mediana.\n\n\n\nOmitir valores at√≠picos\nAhora vamos a utilizar el conjunto de datos student_data para ocmparar la distribuci√≥n de las calificaciones finales (\"G3\") entre los estudiantes que tienen acceso a internet en casa y los que no. Para ello, utilizaremos la variable `‚Äúinternet‚Äù, que es un indicador binario (si/no) de si un alumno tiene acceso a internet en casa.\nDado que internet puede ser menos accesible en las zonas rurales, a√±adiremos subgrupos en funci√≥n de d√≥nde viva el alumno. Pra ello, podemos utilizar la varible \"location\", que es un indicador de su un estudiante vive en una localidad urbana (‚ÄúUrban‚Äù) o rural (‚ÄúRural‚Äù).\nComo recordatorio, puedes omitir los valores at√≠picos en los gr√°ficos de caja estableciendo el par√°metro sym iguan a una cadena vac√≠a (\"\").\n\nInstrucciones\n\nUtiliza sns.catplot() para crear un gr√°fico de caja con el DataFrame student_data, poniendo internet en el eje x y \"G3\" en el eje y.\n\n\n# Create a box plot with subgroups and omit the outliers\nsns.catplot(x='internet', y='G3',\n            data=student_data,\n            kind='box',\n            col='location',\n            hue='location',\n            showfliers=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLas calificaciones medianas son bastante similares entre cada grupo, pero la dispersi√≥n de la distribuci√≥n parece mayor entre los estudiantes que tienen acceso a internet.\n\n\n\nAjustar los bigotes\nEn la lecci√≥n vimos que m√∫ltiples formas de definir los bigotes en un diagrama de caja. En esta serie de ejercicios, seguiermos utilizando el conjunto de datos student_data para comparar la distribuci√≥n de las calificaciones finales (\"G3\") entre los estudiantes que mantienen un relaci√≥n rom√°ntica y los que no. Utilizaremos la variable \"romantic\", que es un indicador si/no de si el alumno tiene una relaci√≥n rom√°ntica.\nVamos a crear un diagrama de cajas para ver esta relaci√≥n y probar distintas formas de definir los bigotes.\n\nInstrucciones\n\nAjusta el c√≥digo para que los bigotes del diagrama de caja se extiendan hata 0,5 * IQR. Recuerda: el IQR es el rango intercuart√≠lico.\n\n\n# Set the whiskers to 0.5 * IQR\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=0.5)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el c√≥digo para que los bigotes se extiendan hasta los percentiles 5 y 95\n\n\n# Extend the whiskers to the 5th and 95th percentile\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=[5, 95])\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el c√≥digo para que los bigotes se extiendan hsta los valores m√≠nimo y m√°ximo.\n\n\n# Set the wiskers at the min and max values\nsns.catplot(x='romantic', y='G3',\n            data=student_data,\n            kind='box',\n            whis=[0, 100])\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nLa nota media es la misma entre estos dos grupos, pero la nota m√°xima es m√°s alta entre los estudiantes que no est√°n en una relaci√≥n rom√°ntica.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Visualizar una variable categ√≥rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr√°fico-de-puntos",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/03_Visualizar_variable_categorica_cuantitativa.html#gr√°fico-de-puntos",
    "title": "Visualizar una variable categ√≥rica y una cuantitativa",
    "section": "Gr√°fico de puntos",
    "text": "Gr√°fico de puntos\n\n¬øQu√© son los gr√°ficos de puntos?\n\nLos puntos muestran la media de una variable cuantitativa.\nLas l√≠neas verticales muestran los intervalos de confianza del 95%.\n\nGr√°ficos de puntos vs Gr√°ficos de l√≠neas\n\nAmbos muestran:\n\nLa media de una variable cuantitativa.\nLos intervalos de confianza del 95% para la media\n\nDiferencias:\n\nLos gr√°ficos de l√≠nea tienen variables cuantitativas (usualmente tiempo) en el eje x.\nLos gr√°ficos de puntos son variables categ√≥ricas en el eje x.\n\n\nGr√°ficos de puntos vs Gr√°ficos de barras\n\nAmbos muestran:\n\nLa media de una variable cuantitativa.\nLos intervalos de confianza del 95% para la media\n\n\n\n\n\nCrear un Gr√°fico de puntos\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            kind='point',\n            hue='feel_masculine')\n            \nplt.show()\n\n\n\nDesconectando los puntos\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            kind='point',\n            hue='feel_masculine',\n            join=False)\n            \nplt.show()\n\n\n\nDesplegando la mediana\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import median\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            estimator=median)\n            \nplt.show()\n\n\n\nPersonalizar los intervalos de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            capsize=0.2)\n            \nplt.show()\n\n\n\nDesactivar los intervalos de confianza\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.catplot(x='smoker', y='total_bill',\n            data=tips,\n            kind='point',\n            ci=None)\n            \nplt.show()\n\n\n\nPersonalizar los gr√°ficos de puntos\nSigamos examinando datos de alumnos de secundaria, esta vez utilizando un gr√°fico de puntos para responder a la pregunta: ¬øInfluye la calidad de la realci√≥n familiar del alumno en el n√∫mero de faltas que tiene en la escuela? Aqu√≠ utilizaremos la variable \"famrel\", que describe la calidad de la relaci√≥n familiar de un alumno de 1 (muy mala) a 5 (muy buena).\nComo recordatorio, para crear un gr√°fico de puntos, utiliza la funci√≥n catplot() y especifica el nombre de la variable categ√≥rica a poner en el eje x (x=____), el nombre de la variable cuantitativa a resumir en el eje y (y=____), el DataFrame de pandas a utilizar (data=____), y el tipo de gr√°fico categ√≥rico (kind=\"point\").\n\nInstrucciones\n\nUtiliza sns.catplot() y el DataFrame student_data para crear un gr√°fico de puntos con \"famrel\" en el eje x y el n√∫mero de ausencias (\"absences\") en el eje y.\n\n\n# Create a point plot of family relationship vs. absences\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nA√±ade ‚Äúmay√∫sculas‚Äù al final de los intervalos de confianza con el tama√±o 0.2.\n\n\n# Add caps to the cofidence interval\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point',\n            capsize=0.2)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nElimina las l√≠neas que unen los puntos de cada categor√≠a.\n\n\n# Remove the lines joining the points\nsns.catplot(x='famrel', y='absences',\n            data=student_data,\n            kind='point',\n            capsize=0.2,\n            linestyle='none') # deprecated join=False\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nAunque el n√∫mero promedio de ausencias es ligeramente menor entre los estudiantes con relaciones familiares de mayor calidad, los grandes intervalos de confianza nos dicen que no podemos estar seguros de que haya una asociaci√≥n real aqu√≠.\n\n\n\nGr√°ficos de punto con subgrupos\nSigamos explorando el conjunto de datos de los alumnos de secundaria. Esta vez, formularemos la pregunta: ¬øestar en una relaci√≥n rom√°ntica est√° asociado a una mayor o menor asistencia a la escuela? ¬øY difiere esta asociaci√≥n en funci√≥n de la escuela a la que asisten los alumnos? Averig√º√©moslo mediante un gr√°fico de puntos.\n\nInstrucciones\n\nUtiliza sns.catplot() y el DataFrame student_data para crear un gr√°fico de puntos con el estado de la relaci√≥n (\"romantic\") en el eje x y el n√∫mero de ausencias (\"absences\") en el eje y. Colorea los puntos seg√∫n la escuela a la que asistan (\"school\").\n\n\n# Create a point plot that uses color to create subgroups\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nDesactiva los intervalos de confianza del gr√°fico.\n\n\n# Turn off the confidence intervals for this plot\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school',\n            errorbar=None) # deprecated ci=None)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nComo puede haber valores at√≠picos de alumnos con muchas ausencias, utiliza la funci√≥n median que hemos importado de numpy para mostar la mediana de n√∫mero de ausencias en lugar de la media.\n\n\n# Import median function from numpy\nfrom numpy import median\n\n# Plot the median number of absences instead of the mean\nsns.catplot(x='romantic', y='absences',\n            data=student_data,\n            kind='point',\n            hue='school',\n            errorbar=None,\n            estimator=median)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que los estudiantes en relaciones rom√°nticas tienen un promedio y una mediana m√°s altos de ausencias en la escuela GP, pero esta asociaci√≥n no se mantiene en la escuela MS.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Visualizar una variable categ√≥rica y una cuantitativa</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "",
    "text": "Cambiar el estilo y el color de la trama\nEn este √∫ltimo cap√≠tulo, aprender√°s a a√±adir t√≠tulos informativos a los gr√°ficos y etiquetas a los ejes, ¬°que son una de las partes m√°s importantes de cualquier visualizaci√≥n de datos! Tambi√©n aprender√°s a personalizar el estilo de tus visualizaciones para orientar m√°s r√°pidamente a tu audiencia hacia los puntos clave. Despu√©s, pondr√°s en com√∫n todo lo que has aprendido en los ejercicios finales del curso.\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\nplt.show()\nsns.set_style('whitegrid')\n\nsns.catplot(x='age', y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\nplt.show()\nsns.set_palette('RdBu')\n\ncategory_order = [\"No answer\",\n                  \"Not al all\",\n                  \"Not very\",\n                  \"Somewhat\",\n                  \"Very\"]\n\nsns.catplot(x='how_masculine',\n            data=masculinity_data,\n            kind='count',\n            order=category_order)\nplt.show()\ncustom_palette = [\"red\", \"green\", \"orange\", \"blue\",\n                  \"yellow\", \"purple\"]\n\nsns.set_palette(custom_palette)\ncustom_palette = [\"#FBB4AE\", \"#B3CDE3\", \"#CCEBC5\",\n                  \"#DECBE4\", \"#FED9A6\", \"#FFFFCC\",\n                  \"#E5B8BD\", \"#FDDAEC\", \"#F2F2F2\"]\n\nsns.set_palette(custom_palette)\nsns.catplot(x='age',\n            y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\n\nplt.show()\nsns.set_context('talk')\n\nsns.catplot(x='age',\n            y='masculinity_important',\n            data=masculinity_data,\n            hue='feel_masculine',\n            kind='point')\n\nplt.show()",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#cambiar-el-estilo-y-el-color-de-la-trama",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#cambiar-el-estilo-y-el-color-de-la-trama",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "",
    "text": "Por qu√© personalizar?\n\nRazones para cambiar de estilo:\n\nPreferencias personales\nMejorar la legibilidad\nGuiar la interpretaci√≥n\n\n\nCambiando los estilos de las figuras\n\nLos estilos de las figuras incluyen el fondo y los ejes\nOpciones: ‚Äúwhite‚Äù, ‚Äúdark‚Äù, ‚Äúwhitegrid‚Äù, ‚Äúdarkgrid‚Äù, ‚Äúticks‚Äù\nPara establecer uno de ellos como estilo global para todos los gr√°ficos se utiliza sns.set_style()\n\nEstilo de figura por defecto (‚Äúwhite‚Äù)\n\nSi solo nos interesa la tendencia general:\n\n\n\n\n\nEstilo de figura: ‚Äúwhitegrid‚Äù\n\nPara determinar valores espec√≠ficos:\n\n\n\n\n\nCambiando la paleta\n\nLos cambios en la paleta de la figura, cambia el color de los elementos principales del gr√°fico\nsns.set_palette()\nUse las paletas preestablecidas o personalizadas\n\nPaletas divergentes\n\n\n\nEjemplo (Paleta divergente)\n\n\n\n\nPaletas secuenciales\n\n\n\nEjemplo de paleta secuencial\n\n\n\nPaletas personalizadas\n\n\n\n\n\n\nCambiar la escala del gr√°fico\n\nEn las figuras ‚Äúcontext‚Äù cambia la escala de los elementos y etiquetas del gr√°fico\n`sns.set_context()`\nDel mas peque√±o al m√°s grande: ‚Äúpaper‚Äù, ‚Äúnotebook‚Äù, ‚Äútalk‚Äù, ‚Äúposter‚Äù.\n\nContexto por defecto: ‚Äúpaper‚Äù\n\n\n\n\nContexto grande: ‚Äútalk‚Äù\n\nPresentaciones donde el p√∫blico este mas alejado del gr√°fico\n\n\n\n\n\nCambiar de estilo y de paleta\nVamos a nuestro conjunto de datos que contiene los resultados de una encuestra realizada a j√≥venes sobre sus h√°bitos y preferencias. Hemos proportcionado el c√≥digo para crear un gr√°fico de recuento de sus respuestas a la pregunta ‚Äú¬øCon qu√© frecuencia escuchas los consejos de tus padres?‚Äù. Ahora vamos a cambiar el estilo y la paleta para que esta trama sea m√°s f√°cil de interpretar.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/young-people-survey-responses.csv'\nsurvey_data = pd.read_csv(ruta, index_col=0)\nsurvey_data.head()\n\n\n\n\n\n\n\n\nMusic\nTechno\nMovies\nHistory\nMathematics\nPets\nSpiders\nLoneliness\nParents' advice\nInternet usage\nFinances\nAge\nSiblings\nGender\nVillage - town\nAge Category\nInterested in Math\n\n\n\n\n0\n5.0\n1.0\n5.0\n1.0\n3.0\n4.0\n1.0\n3.0\n4.0\nfew hours a day\n3.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n1\n4.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n2.0\n2.0\nfew hours a day\n3.0\n19.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n2\n5.0\n1.0\n5.0\n1.0\n5.0\n5.0\n1.0\n5.0\n3.0\nfew hours a day\n2.0\n20.0\n2.0\nfemale\ncity\nLess than 21\nTrue\n\n\n3\n5.0\n2.0\n5.0\n4.0\n4.0\n1.0\n5.0\n5.0\n2.0\nmost of the day\n2.0\n22.0\n1.0\nfemale\ncity\n21+\nTrue\n\n\n4\n5.0\n2.0\n5.0\n3.0\n2.0\n1.0\n1.0\n3.0\n3.0\nfew hours a day\n4.0\n20.0\n1.0\nfemale\nvillage\nLess than 21\nFalse\n\n\n\n\n\n\n\nTransformaci√≥n de los datos de la columna \"Parents' advice\"\n\nsurvey_data[\"Parents' advice\"] = survey_data[\"Parents' advice\"].map({1: 'Never',\n                                                                     2: 'Rarely',\n                                                                     3: 'Sometimes',\n                                                                     4: 'Often',\n                                                                     5: 'Always'})\n\n\nInstrucciones\n\nConfigura el estilo en \"whitegrid\" para ayudar al p√∫blico a determinar el n√∫mero de respuestas de cada categor√≠a.\n\n\n# Set the style to \"whitegrid\"\nsns.set_style('whitegrid')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count',\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nEstablece la paleta de colores en la paleta secuencial denominada \"Purples.\n\n\n# Set the color palette to \"Purples\"\nsns.set_style('whitegrid')\nsns.set_palette('Purples')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count',\n            order=category_order,\n            hue=\"Parents' advice\", legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia la paleta de colores a la paleta divergente \"RdBu\"\n\n\n# Change the color palette to \"RdBu\"\nsns.set_style('whitegrid')\nsns.set_palette('RdBu')\n\n# Create a count plot or survey responses\ncategory_order = ['Never', 'Rarely', 'Sometimes',\n                  'Often', 'Always']\n\nsns.catplot(x=\"Parents' advice\",\n            data=survey_data,\n            kind='count', \n            hue=\"Parents' advice\", legend=False,\n            order=category_order)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nEste estilo y la paleta de colores divergente resaltan mejor la diferencia entre el n√∫mero de j√≥venes que suelen escuchar los consejos de sus padres frente a los que no lo hacen.\n\n\n\nCambiar la escala\nEn este ejercicio, seguiremos examinando el conjunto de datos que contienen las respuestas de una encuesta a j√≥venes. ¬øVar√≠a el porcentaje de personas que declaran sentirse solas en funci√≥n del n√∫mero de hermanos que tienen? Averig√º√©moslo utlizando un diagrama de barras, al tiempo que exploramos las cuatro escalas de diagrama diferentes de Seaborn. (‚Äúcontextos‚Äù).\n\nInstrucciones\n\nEstablece la escala (‚Äúcontexto‚Äù) en \"paper\", que es la m√°s pequie√±a de las opciones de escala.\n\n\n# Set the context to \"paper\"\nsns.set_context('paper')\n\n# Create bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"notebook\" para aumentar la escala.\n\n\n# Change the context to \"notebook\"\nsns.set_context(\"notebook\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"talk\" para aumentar la escala.\n\n\n# Change the context to \"notebook\"\nsns.set_context(\"talk\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nCambia el contexto a \"poster\", que es la mayor escala disponbible.\n\n\n# Change the context to \"poster\"\nsns.set_context(\"poster\")\n\n# Create a bar plot\nsns.catplot(x='Siblings', y='Loneliness',\n            data=survey_data, \n            kind='bar', \n            hue='Siblings', legend=False)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nCada nombre de contexto da la sugerencia de Seaborn sobre cu√°ndo usar una escala de gr√°fico dada (es un art√≠culo, en un cuadrno de iPythonm en una charla/presentaci√≥n o en una sesi√≥n de p√≥ster).\n\n\n\nUtilizar una paleta personalizada\nHasta ahora, hemos analizado varias cosas en el conjunto de datos de las respuestas a las encuestas de los j√≥venes, como el uso que hacen de internet, la frecuencia con que escuchan a sus padres y cu√°ntos de ellos dicen sentirse solos. Sin embargo, algo que no hemos hecho es un resumen b√°sico del tipo de personas que responden a esta encuesta, incluyendo su edad y g√©nero. Proporcionar estos res√∫menes b√°sicos es siempre una buena pr√°ctica cuando se trata de un conjunto de datos desconocido.\nEl c√≥digo proporcionado crear√° un diagrama de cajas que mostrar√° la distribuci√≥n de edades de los encuestados masculinos frente a los femeninos. Vamos a ajustar el c√≥digo para personalizar la apariencia , esta vez utilizando una paleta de colores personalizada.\n\nInstrucciones\n\nEstablece el estilo en \"darkgrid\".\nEstablece una paleta de colores personalizada con los c√≥digos hexadecimales de color \"#39A7D0\" y \"#36ADA4\".\n\n\nsns.set_context('notebook')\n\n# Set the style to \"darkgrid\"\nsns.set_style('darkgrid')\n\n# Set a custom color palette\nsns.set_palette(['#39A7D0', '#36ADA4'])\n\n# Create the box plot of age distribution by gender\nsns.catplot(x='Gender', y='Age',\n            data=survey_data, kind='box',\n            hue='Gender', legend=False)  # se agregan pues palette sera deprecated\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que la edad media es la misma para hombres y mujeres, pero la distribuci√≥n de las mujeres se inclina hacia edades m√°s j√≥venes que la de los hombres.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a√±adir-t√≠tulos-y-etiquetas-parte-1",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a√±adir-t√≠tulos-y-etiquetas-parte-1",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "A√±adir t√≠tulos y etiquetas: Parte 1",
    "text": "A√±adir t√≠tulos y etiquetas: Parte 1\n\nCreando visualizaciones informativas\n\nSe a√±ade un t√≠tulo.\nLas etiquetas de los ejes son informativas.\nLas etiquetas del eje x estan giradas para mayor claridad.\n\n\n\n\nObjetos FacetGrid vs.¬†AxesSubplot\n\nLos gr√°ficos de Seaborn creean dos diferentes tipos de objetos: FacetGrid y AxesSubplot.\n\n\n\ng = sns.scatterplot(x='height', y='weight', data=df)\ntype(g)\n\n\nmatplotlib.axes._subplots.AxesSubplot\n\n\nFacetGrid vac√≠o\n\nEsta formado por uno o varios AxesSuubplots\n\n\nObjetos FacetGrid vs.¬†AxesSubplot\n\n\n\n\n\n\n\n\nTipo de Objeto\nTipo de gr√°fico\nCaracter√≠sticas\n\n\n\n\nFacetGrid\nrelplot(), catplot()\nPuede crear subplots\n\n\nAxesSubplot\nscatterplot, countplot, etc.\nCrea un solo gr√°fico\n\n\n\nA√±adiendo un t√≠tulo al FacetGrid\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box')\n\ng.fig.suptitle('New Title',\n                y=1.03)\n\nplt.show()\n\n\n\nFacetGrids vs.¬†AxesSubplots\nEn la lecci√≥n reciente, aprendimos que las funciones de trazado de Seaborn crean dos tipos diferentes de objetos: objetos FacetGrid y objetos AxesSubplot. El m√©todo para a√±adir un t√≠tulo a tu gr√°fico variar√° en funci√≥n del tipo de objeto que sea.\nEn el c√≥digo proporcionadom hemos utilizado relplot() con el conjunto de datos de millas por gal√≥n para crear un gr√°fico de dispersi√≥n que muestra la realaci√≥n entre el peso de un coche y su potencia. Este gr√°fico de dispersi√≥n se asigna a la variable g. Identifiquemos de qu√© tipo de objeto se trata.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/mpg.csv'\nmpg = pd.read_csv(ruta)\nmpg.head()\n\n\n\n\n\n\n\n\nmpg\ncylinders\ndisplacement\nhorsepower\nweight\nacceleration\nmodel_year\norigin\nname\n\n\n\n\n0\n18.0\n8\n307.0\n130.0\n3504\n12.0\n70\nusa\nchevrolet chevelle malibu\n\n\n1\n15.0\n8\n350.0\n165.0\n3693\n11.5\n70\nusa\nbuick skylark 320\n\n\n2\n18.0\n8\n318.0\n150.0\n3436\n11.0\n70\nusa\nplymouth satellite\n\n\n3\n16.0\n8\n304.0\n150.0\n3433\n12.0\n70\nusa\namc rebel sst\n\n\n4\n17.0\n8\n302.0\n140.0\n3449\n10.5\n70\nusa\nford torino\n\n\n\n\n\n\n\n\nInstrucciones\n\nIdentifica qu√© tipo de objeto es el gr√°fico g y as√≠gnalo a la variable type_of_g\n\n\nsns.set_style('white')\n\n# Create a scatter plot\ng = sns.relplot(x='weight', y='horsepower',\n                    data=mpg, kind='scatter')\n\n# Identify plot type\ntype_of_g = type(g)\n\n# Print type\nprint(type_of_g)\n\n&lt;class 'seaborn.axisgrid.FacetGrid'&gt;\n\n\n\n\n\n\n\n\n\n\nPregunta\n\nAcabamos de ver que sns.relplot() crea objetos FacetGrid. ¬øQu√© otra funci√≥n Seaborn crea un objeto FacetGrid en lugar de un objeto AxesSubplot?\nRespuestas posibles\n\nsns.catplot()\nsns.scatterplot()\nsns.boxplot()\nsns.countplot()\n\ncatplot() admite la creaci√≥n de subgr√°ficos, por lo que crea un objeto FacetGrid.\n\n\n\nA√±adir un t√≠tulo a un objeto FacetGrid\nEn el ejercicio anterior, utilizamos relplot() con el conjunto de datos de millas por gal√≥n para crear un gr√°fico de dispersi√≥n que mostrara la relaci√≥n entre el peso de un coche y su potencia. Esto cre√≥ el objeto FacetGrid. Ahora que sabemos qu√© tipo de objeto es, vamos a a√±adir un t√≠tulo a esta trama.\n\nInstrucciones\n\nA√±ade un t√≠tulo a esta trama: \"Car Wight vs. Horsepower\".\n\n\n# Create a scatter plot\ng = sns.relplot(x='weight', y='horsepower',\n            data=mpg, kind='scatter')\n\n# Add a title \"Car Weight vs. Horsepower\"\ng.fig.suptitle('Car Weight vs. Horsepower')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nParece que el peso de un coche est√° correlacionado positivamente con su potencia.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a√±adir-t√≠tulos-y-etiquetas-parte-2",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#a√±adir-t√≠tulos-y-etiquetas-parte-2",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "A√±adir t√≠tulos y etiquetas: Parte 2",
    "text": "A√±adir t√≠tulos y etiquetas: Parte 2\n\nA√±adiendo un t√≠tulo a AxesSubplot\n\nFacetGrid\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data,\n                kind='box')\n\ng.fig.suptitle('New Title',\n               y=1.03)\n\n\nAxesSubplot\n\ng = sns.boxplot(x='Region', y='Birtrate',\n                data=gdp_data)\n\ng.set_title('New Title',\n            y=1.03)\n\n\nT√≠tulos para subgr√°ficos\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\n# T√≠tulo general\ng.fig.suptitle('New Title',\n                y=1.03)\n\n# T√≠tulo de cada gr√°fico\ng.set_title('This is {col_name}')\n\n\n\nA√±adir etiquetas a los ejes\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\ng.set(xlabel='New X Label',\n      ylabel='New Y Label')\n\nplt.show()\n\n\n\nRotando las etiquetas del eje x\n\n\ng = sns.catplot(x='Region', y='Birthrate',\n                data=gdp_data, kind='box',\n                col='Group')\n\nplt.xticks(rotation=90)\nplt.show()\n\n\n\nA√±adir un t√≠tulo y etiquetas de eje\nSigamos examinando el conjunto de datos de millas por gal√≥n. Esta vez crearemos un gr√°fico lineal para responder a la pregunta: ¬øC√≥mo cambia a lo largo del tiempo la media de millas por gal√≥n que alcanzan los coches en cada uno de los tres lugares de origen? Para mejorar la legibilidad de este gr√°fico, a√±adiremos un t√≠tulo y etiquetas de eje m√°s informativas.\nEn el c√≥digo proporcionado, creamos el gr√°fico de l√≠neas utilizando la funci√≥n lineplot(). Ten encuenta que lineplot() no admite la creaci√≥n de subtramas, por lo que devuelve un obejeto AxesSubplot en lugar d eun objeto FacetGrid.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nruta = './data/mpg_mean.csv'\nmpg_mean = pd.read_csv(ruta, index_col=0)\nmpg_mean.head()\n\n\n\n\n\n\n\n\nmodel_year\norigin\nmpg_mean\n\n\n\n\n0\n70\neurope\n25.200000\n\n\n1\n70\njapan\n25.500000\n\n\n2\n70\nusa\n15.272727\n\n\n3\n71\neurope\n28.750000\n\n\n4\n71\njapan\n29.500000\n\n\n\n\n\n\n\n\nInstrucciones\n\nA√±ade el siguiente t√≠tulo a la trama: \"Average MPG Over Time\".\n\n\n# Create a line plot\ng = sns.lineplot(x='model_year', y='mpg_mean',\n                 data=mpg_mean, hue='origin')\n\n# Add title \"Average MPG Over Time\"\ng.set_title('Average MPG Over Time')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\n\nEtiqueta el eje x como \"Car Model Year\" y el eje y como \"Average MPG\".\n\n\n# Create a line plot\ng = sns.lineplot(x='model_year', y='mpg_mean',\n                 data=mpg_mean, hue='origin')\n\n# Add title \"Average MPG Over Time\"\ng.set_title('Average MPG Over Time')\n\n# Add x-axis and y-axis labels\ng.set(xlabel='Car Model Year',\n      ylabel='Average MPG')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nEl promedio de millas por gal√≥n logrado est√° aumentando con el tiempo para los tres lugares de origen, pero EE.UU.j siempre es m√°s bajo que Europa y Jap√≥n.\n\n\n\nRotar etiquetas x-tick\nEn este ejercicio, seguiremos ecaminando el conjunto de datos de millas por gal√≥n. En el c√≥digo proporcionado, creamos un gr√°fico de puntos que muestra la aceleraci√≥n media de los coches en cada uno de los tres lugares de origen. Observa que la variable \"acceleration\" es el tiempo de aceleraci√≥n de 0 a 60 millas por hora, en segundos. Los valores m√°s altos indican una aceleraci√≥n m√°s lenta.\nUtilicemos este gr√°fico para practicar la rotaci√≥n de las etiquetas x-tick. Recuerda que la funci√≥n para rotar las etiquetas x-tick es una funci√≥n independiente de Matplotlib y no una funci√≥n aplicada al propio objeto gr√°fico.\n\nInstrucciones\n\nGira 90 grados las etiquetas x-tick.\n\n\n# Create point plot\nsns.catplot(x='origin', y='acceleration',\n            data=mpg, kind='point',\n            linestyle='none', capsize=0.1)  # join=False deprecated\n\n# Rotate x-tick labels\nplt.xticks(rotation=90)\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDado que los valores m√°s altos indican una aceleraci√≥n m√°s lenta, parece que los coches de Jap√≥n y Europa tienen una aceleraci√≥n significativamente m√°s lenta en comparaci√≥n con los de EE.UU.",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#unirlo-todo",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#unirlo-todo",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "Unirlo Todo",
    "text": "Unirlo Todo\n\nInicio Para importar Seaborn:\n\n\nimport seaborn as sns\n\nPara importar Matplotlib:\n\nimport matplotlib.pyplot as plt\n\nPara mostrar un gr√°fico:\n\nplt.show()\n\n\nGr√°ficos Relacionales\n\nMuestran la relaci√≥n entre dos variables cuantitativas.\nEjemplos: scatter plots, line plots\n\n\n\nsns.relplot(x='x_variable_name',\n            y='y_variable_name',\n            data=pandas_df,\n            kind='scatter')\n\n\nGr√°ficos Categ√≥ricos\n\nDescriben la distribuci√≥n de una variable cuantitativa dentro de categor√≠as definida por una variable categ√≥rica\nEjemplos: bar plots, count plots, box plots, pint plots\n\n\n\nsns.catplot(x='x_variable_name',\n            y='y_variable_name',\n            data=pandas_df,\n            kind='bar')\n\n\nA√±adiendo una tercer variable (hue)\n\nConfigurar hue creatra subgrupos que son desplegados como diferentes colores en un solo gr√°fico\n\n\nA√±adiendo una tercer variable (row/col)\n\nConfigurar row y/o col en relplot() o catplot() crear√° subgrupos que son desplegados en subgr√°ficos separados.\n\n\nPersonalizaci√≥n\n\nCambiar el fondo: sns.set_style()\nCambiar los colores de los elementos principales: sns.set_palette()\nCambiar la escala: sns.set_context()\nA√±adir un t√≠tulo\n\n\n\n\n\n\n\n\nTipo de Objeto\nTipo de gr√°fico\nC√≥mo a√±adir un t√≠tulo\n\n\n\n\nFacetGrid\nrelplot(), catplot()\ng.fig.suptitle()\n\n\nAxesSubplot\nscatterplot(), countplot(), etc.\ng.set_title()\n\n\n\n\nToques finales\n\nA√±adir etiquetas al eje x y eje y\n\n\n\ng.set(xlabel='new x-axis label',\n      ylabel='new y-axis label')\n\nRotar etiquetas el eje x\n\nplt.xticks(rotation=90)\n\n\nDiagrama de cajas con subgrupos\nEn este ejercicio, examinaremos el conjunto de datos que contiene las respuestas de una encuesta realizada a j√≥venes. Una de las preguntas que se hicieron a los j√≥venes fue: ‚Äú¬øTe interesa tener mascotas?‚Äù Exploraremos si la distribuci√≥n de edades de los que responden ‚Äúsi‚Äù tiende a ser mayor o menor que la de los que responden ‚Äúno‚Äù, distinguiendo seg√∫n el g√©nero.\n\nsurvey_data['Interested in Pets'] = survey_data['Pets'].apply(\n    lambda x: 'Yes' if x &gt;= 4.0 else 'No')\n\n\nInstrucciones\n\nConfigura la paleta de colores en \"Blues\".\nA√±ade subgrupos para colorear los gr√°ficos de caja en funci√≥n de \"Interested in Pets\".\nEstablece el t√≠tulo del objeto FacetGrid g en `‚ÄúAge of Those Interested in Pets vs.¬†Not‚Äù.\nRealiza la visualizaci√≥n del gr√°fico utlizando una funci√≥n Matplotlib.\n\n\n# Set palette to \"Blues\"\nsns.set_palette('Blues')\n\n# Adjust to add subgroups based on \"Interested in Pets\"\ng = sns.catplot(x='Gender', y='Age',\n                data=survey_data,\n                kind='box', hue='Interested in Pets')\n\n# Set title to \"Age of Those Interested in Pets vs. Not\"\ng.fig.suptitle('Age of Those Interested in Pets vs. Not')\n\n# Show plot\nplt.show()\n\n\n\n\n\n\n\n\nDespu√©s de controlar por g√©nero, parece que las distribuciones de edad de las personas est√°n interesadsas en las mascotas son similares a las de las que no lo est√°n\n\n\n\nDiagrama de barras con subgrupos y subtramas\nEn este ejercicio, volveremos a nuestro conjunto de datos de la encuesta a j√≥venes e investigaremos si la proporci√≥n de personas a las que les gusta la m√∫sica tecno (\"Likes Techno\") var√≠a seg√∫n su g√©nero. (\"Gender\") o su lugar de residencia (\"Village - town\"). ¬°Este ejercicio nos dar√° la oportunidad de practicar las muchas cosas que hemos aprendido a lo largo de este curso!\nAntes hay que transformar la columna ‚ÄòTechno‚Äô por ‚ÄòLikes Techno‚Äô\n\nsurvey_data['Likes Techno'] = survey_data['Techno'].apply(lambda x: True if x &gt;= 4.0 else False)\n\n\nInstrucciones\n\nEstablece el estilo de la figura en \"dark\".\nAjusta el c√≥digo del diagrama de barras para a√±adir subtramas basadas en \"Gender\", dispuestas en columnas.\nA√±ade el t√≠tulo \"Percentage of Young People Who Like Techno\" a esta trama FacetGrid.\nEtiqueta el eje x \"Location of Residence\" y el eje y \"% Who Like Techno\"\n\n\nplt.style.use('seaborn-v0_8')\n\n# Set the figure style to \"dark\"\nsns.set_style('dark')\n\n# Adjust to add subplots per gender\ng = sns.catplot(x='Village - town', y='Likes Techno',\n                data=survey_data, kind='bar',\n                col='Gender')\n\n# Add title and axix labels\ng.fig.suptitle('Percentage of Young People Who Like Techno',\n                y=1.02)\ng.set(xlabel='Location of Residence',\n      ylabel='% Who Like Techno')\n\n# Show plot\nplt.show()",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#bien-hecho-y-ahora-qu√©",
    "href": "06_Introduccion_a_la_visualizacion_de_datos_con_seaborn/04_Personalizar_graficos_seaborn.html#bien-hecho-y-ahora-qu√©",
    "title": "Personalizar los gr√°ficos de Seaborn",
    "section": "¬°Bien hecho! ¬øY ahora qu√©?",
    "text": "¬°Bien hecho! ¬øY ahora qu√©?\n\nExplorar y comunicar los resultados\n\n\n\nSeguientes pasos:\n\nVisualizaciones avanzadas con Seaborn\nMatplotlib avanzado personalizado",
    "crumbs": [
      "Introducci√≥n a la Visualizaci√≥n de Datos con Seaborn",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Personalizar los gr√°ficos de Seaborn</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html",
    "href": "07_Analisis_exploratorio_de_datos/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nEste curso interactivo cubre el proceso de exploraci√≥n y an√°lisis de datos en Python, desde entender un nuevo dataset hasta la limpieza e imputaci√≥n de valores.\nüìä Nivel: Intermedio\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nAs√≠ que tienes algunos datos interesantes, ¬øpor d√≥nde empiezas tu an√°lisis? Este curso cubrir√° el proceso de exploraci√≥n y an√°lisis de datos, desde la comprensi√≥n de lo que se incluye en un conjunto de datos hasta la incorporaci√≥n de los resultados de la exploraci√≥n a un flujo de trabajo de ciencia de datos.\nUtilizando datos sobre cifras de desempleo y precios de billetes de avi√≥n, aprovechar√°s Python para resumir y validar datos, calcular, identificar y reemplazar valores perdidos, y limpiar valores num√©ricos y categ√≥ricos. A lo largo del curso, crear√°s hermosas visualizaciones Seaborn para comprender las variables y sus relaciones.\nPor ejemplo, examinar√°s c√≥mo se relacionan el consumo de alcohol y el rendimiento de los alumnos. Por √∫ltimo, el curso mostrar√° c√≥mo los hallazgos exploratorios alimentan los flujos de trabajo de la ciencia de datos creando nuevas caracter√≠sticas, equilibrando caracter√≠sticas categ√≥ricas y generando hip√≥tesis a partir de los hallazgos.\nAl final de este curso, tendr√°s la confianza necesaria para realizar tu propio an√°lisis exploratorio de datos (EDA) en Python. ¬°Ser√°s capaz de explicar tus conclusiones visualmente a los dem√°s y sugerir los siguientes pasos para recopilar informaci√≥n a partir de tus datos!",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html#m√≥dulos-del-curso",
    "href": "07_Analisis_exploratorio_de_datos/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nConocer un conjunto de datos\nLimpieza e imputaci√≥n de datos\nRelaciones en los datos\nConvertir el an√°lisis exploratorio en acci√≥n",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/index.html#datasets",
    "href": "07_Analisis_exploratorio_de_datos/index.html#datasets",
    "title": "Bienvenida",
    "section": "Datasets",
    "text": "Datasets\nEste curso utiliza los siguientes archivos:\n\nunemployment.csv\ndata_science_salaries.csv\nbooks.csv\ndivorce.csv\nplanes.csv",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "Bienvenida"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html",
    "title": "Conocer un conjunto de datos",
    "section": "",
    "text": "Exploraci√≥n inicial\n¬øCu√°l el la mejor manera de abordar un nuevo conjunto de datos? Aprende a validar y resumir datos categ√≥ricos y num√©ricos y a crear visualizaciones Seaborn para comunicar tus conclusiones.\nbooks = pd.read_csv('books.csv')\nbooks.head()\nbooks.info()\nbooks.value_counts('genre')\nbooks.describe()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.histplot(data=books, x='rating')\nplt.show()\nsns.histplot(data=books, x='rating', binwidth=.1)\nplt.show()",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#exploraci√≥n-inicial",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#exploraci√≥n-inicial",
    "title": "Conocer un conjunto de datos",
    "section": "",
    "text": "An√°lisis Exploratorio de Datos\n\nEs el proceso de limpiar y revisar datos para:\n\nObterner informaci√≥n (Estad√≠stica descriptiva, correlaciones)\nGenrar hip√≥tesis\n\n\nUna primera mirada con .head()\n\n\n\n\nReuniendo m√°s .info()\n\n\n\n\nUna mirada cercana a las columnas categ√≥ricas\n\n\n\n\nColumnas num√©ricas con .describe()\n\n\n\n\nVisualizando datos num√©ricos\n\n\n\n\nAjustando la anchura del bin\n\n\n\n\nFunciones para la exploraci√≥n inicial\nEst√°s investigando las tasas de desempleo en todo el mundo y te han dado un nuevo conjunto de datos con el que trabajar. Los datos se han guardado y cargado para ti como un DataFrame de pandas llamado unemployment. Nunca antes hab√≠as visto los datos, as√≠ que tu primera tarea es utilizar unas cuantas funciones de pandas para conocer estos nuevos datos.\n\nimport pandas as pd\n\nruta = './data/clean_unemployment.csv'\nunemployment = pd.read_csv(ruta)\n\n\nInstrucciones\n\nUtiliza una funci√≥n de pandas para imprimir las cinco primeras filas del DataFrame unemployment.\n\n\n# Print the first five rows of unemployment\nprint(unemployment.head())\n\n  country_code          country_name      continent   2010   2011   2012  \\\n0          AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1          AGO                Angola         Africa   9.43   7.36   7.35   \n2          ALB               Albania         Europe  14.09  13.48  13.38   \n3          ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4          ARG             Argentina  South America   7.71   7.18   7.22   \n\n    2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0  11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1   7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2  15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3   2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4   7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n\n\n\nUtiliza una funci√≥n pandas para imprimir un resumen de los valores y tipos de datos de las columnas que no faltan del DataFrame unemployment.\n\n\n# Print a summary of non-missing values and data types in the unemployment DataFrame]\nprint(unemployment.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 182 entries, 0 to 181\nData columns (total 15 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   country_code  182 non-null    object \n 1   country_name  182 non-null    object \n 2   continent     177 non-null    object \n 3   2010          182 non-null    float64\n 4   2011          182 non-null    float64\n 5   2012          182 non-null    float64\n 6   2013          182 non-null    float64\n 7   2014          182 non-null    float64\n 8   2015          182 non-null    float64\n 9   2016          182 non-null    float64\n 10  2017          182 non-null    float64\n 11  2018          182 non-null    float64\n 12  2019          182 non-null    float64\n 13  2020          182 non-null    float64\n 14  2021          182 non-null    float64\ndtypes: float64(12), object(3)\nmemory usage: 21.5+ KB\nNone\n\n\n\nImprime las estad√≠sticas de resument (recuento, media, desviaci√≥n est√°ndar, valores m√≠nimo, m√°ximo y cuartil) de cada columna num√©rica en unemployment.\n\n\n# Print summary statistics for numerical columns in unemployment\nprint(unemployment.describe())\n\n             2010        2011        2012        2013        2014        2015  \\\ncount  182.000000  182.000000  182.000000  182.000000  182.000000  182.000000   \nmean     8.409286    8.315440    8.317967    8.344780    8.179670    8.058901   \nstd      6.248887    6.266795    6.367270    6.416041    6.284241    6.161170   \nmin      0.450000    0.320000    0.480000    0.250000    0.200000    0.170000   \n25%      4.015000    3.775000    3.742500    3.692500    3.625000    3.662500   \n50%      6.965000    6.805000    6.690000    6.395000    6.450000    6.170000   \n75%     10.957500   11.045000   11.285000   11.310000   10.695000   10.215000   \nmax     32.020000   31.380000   31.020000   29.000000   28.030000   27.690000   \n\n             2016        2017        2018        2019        2020        2021  \ncount  182.000000  182.000000  182.000000  182.000000  182.000000  182.000000  \nmean     7.925879    7.668626    7.426429    7.243736    8.420934    8.390879  \nstd      6.045439    5.902152    5.818915    5.696573    6.040915    6.067192  \nmin      0.150000    0.140000    0.110000    0.100000    0.210000    0.260000  \n25%      3.800000    3.690000    3.625000    3.487500    4.285000    4.335000  \n50%      5.925000    5.650000    5.375000    5.240000    6.695000    6.425000  \n75%     10.245000   10.315000    9.257500    9.445000   11.155000   10.840000  \nmax     26.540000   27.040000   26.910000   28.470000   29.220000   33.560000  \n\n\nAhora haz aprendido que unemployment contiene 182 filas de datos de pa√≠ses, incluyendo country_code, country_name, continent y porcentajes de desempleo desde 2010 hasta 2021. ¬°Si miraste muy de cerca, podr√≠as haber notado que a algunos pa√≠ses les falta informaci√≥n en la columna continent! Continuemos explorando estos datos en el pr√≥ximo ejercicio.\n\n\n\nContar valores categ√≥ricos\nRecordemos del ejercicio anterior que el DataFrame unemployment contiene 182 filas de datos de pa√≠ses que incluyen country_code, country_name, continent y porcentajes de desempleo de 2010 a 2021.\nAhora vas a explorar los datos categ√≥ricos contenidos en unemployment para comprender los datos que contiene relacionados con cada continente.\n\nInstrucciones\n\nUtiliza un m√©todo para contar los valores asociados a cada continent en el DataFrame unemployment.\n\n\n# Count the values associated with each continent in unemployment\nprint(unemployment['continent'].value_counts())\n\ncontinent\nAfrica           53\nAsia             47\nEurope           39\nNorth America    18\nSouth America    12\nOceania           8\nName: count, dtype: int64\n\n\n¬øSab√≠as que hay 23 pa√≠ses en Am√©rica del Norte, que incluye pa√≠ses en el Caribe y Am√©rica Central? Puede que hayas notado que Am√©rica del Norte tiene 18 puntos de datos en el DataFrame unemployment, por lo que nos falta informaci√≥n de algunos de los pa√≠ses en nuestro conjunto de datos.\n\n\n\nDesempleo mundial en 2021\n¬°Es hora de explorar algunos de los datos num√©ricos en unemployment! ¬øCu√°l fue el desempleo t√≠pico en un a√±o determinado? ¬øCu√°l era la tasa de desempleo m√≠nima y m√°xima, y c√≥mo era la distribuci√≥n de las tasas de desempleo en el mundo? Un histogrpama es una buena forma de hacerse una idea de las respuestas a estas preguntas.\nTu tarea en este ejercicio es crear un histograma que muestre la distribuci√≥n de las tasas de paro mundiales en 2021.\n\nInstrucciones\n\nImporta las bibliotecas de visualizaci√≥n necesarias\nCrea un histograma de la distribuci√≥n de los porcentajes de desempleo de 2021 en todos los pa√≠ses en unemployment; muestra un punto pocentual completo en cada casilla.\n\n\n# Import the required visualization libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a histogram of 2021 unemployment; show a full percent in each bin\nsns.histplot(x='2021', data=unemployment, binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\nParece que el desempleo en el 2021 se mantuvo alrededor del 3% al 8% para la mayor√≠a de los pa√≠ses en el conjunto de datos, pero algunos pa√≠ses experimentaron un desempleo muy alto del 20% al 35%.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#validaci√≥n-de-datos",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#validaci√≥n-de-datos",
    "title": "Conocer un conjunto de datos",
    "section": "Validaci√≥n de datos",
    "text": "Validaci√≥n de datos\n\nValidando los tipos de datos\n\n\nbooks.dtypes\n\n\n\nActualizando los tipos de datos\n\n\nbooks['year'] = books['year'].astype(int)\nbooks.dtypes\n\n\n\n\n\nTipo\nNombre Python\n\n\n\n\nString\nstr\n\n\nInteger\nint\n\n\nFloat\nfloat\n\n\nDictionary\ndict\n\n\nList\nlist\n\n\nBoolean\nbool\n\n\n\n\nValidando datos categ√≥ricos\n\n\nbooks['genre'].isin(['Fiction', 'Non Fiction'])\n\n\nPara validar los datos que no est√°n en la lista\n\n~books['genre'].isin(['Fiction', 'Non Fiction'])\n\n\nPara filtrar el DataFrame por los valores en nuestra lista\n\nbooks[books['genre'].isin(['Fiction', 'Non Fiction'])].head()\n\n\n\nValidando los datos num√©ricos\n\nPara ver solo las columnas num√©ricas en un DataFrame:\n\nbooks.select_dtypes('number').head()\n\nPara conocer un intervalo espec√≠fico:\n\nbooks['year'].min()\n\n\n\nbooks['year'].max()\n\n\nSe puede ver una imagen m√°s detallada de la distribuci√≥n de los datos, utilizando boxplot:\n\nsns.boxplot(data=books, x='year')\nplt.show()\n\n\nTambi√©n se puede ver los datos agrupados por una variable categ√≥rica.\n\nsns.boxplot(data=books, x='year', y='genre')\nplt.show()\n\n\n\nDetectar tipos de datos\n¬°Se ha modificado una columna en el DataFrame unemployment y ahora tiene un tipo de datos incorrecto! Este tipo de datos te impedir√° realizar una exploraci√≥n y un an√°lisis eficaces, por lo que tu tarea consiste en identificar qu√© columna tiene un tipo de datos incorrecto y, a continuaci√≥n, corregirlo.\n\nInstrucciones\nPregunta\n\n¬øCu√°l de las siguientes columnas requiere una actualizaci√≥n de su tipo de datos?\n\n\nprint(unemployment.dtypes)\n\ncountry_code     object\ncountry_name     object\ncontinent        object\n2010            float64\n2011            float64\n2012            float64\n2013            float64\n2014            float64\n2015            float64\n2016            float64\n2017            float64\n2018            float64\n2019             object\n2020            float64\n2021            float64\ndtype: object\n\n\nRespuestas posibles\n\ncountry_name\ncontinent\n2019\n2021\n\n\n\n\n\nActualiza el tipo de datos de la columna 2019 de unemployment a float.\n¬°Vuelve a imprimir el dtypes del DataFrame umemployment para comprobar que se ha actualizado el tipo de datos!\n\n\n# Update the data type of the 2019 column to a float\nunemployment['2019'] = unemployment['2019'].astype('float')\n\n# Print the dtypes to check your work\nprint(unemployment.dtypes)\n\ncountry_code     object\ncountry_name     object\ncontinent        object\n2010            float64\n2011            float64\n2012            float64\n2013            float64\n2014            float64\n2015            float64\n2016            float64\n2017            float64\n2018            float64\n2019            float64\n2020            float64\n2021            float64\ndtype: object\n\n\nCambiar el tipo de dato de la columna 2019 significa que ahora puedes realizar c√°lculos sobre ella, incluyendo validar su rango.\n\n\n\nValidar continentes\nTu colega te ha informado de que los datos sobre el desempleo de los pa√≠ses de Ocean√≠a no son fiables, y te gustar√≠a identificar y excluir a estos pa√≠ses de tus datos de unemployment. ¬°La funci√≥n .isin() puede ayudarte con eso!\nTu tarea consiste en utilizar isin() para identificar los pa√≠ses que no est√°n en Ocean√≠a. Estos pa√≠ses deber√≠an devolver True mientras que los pa√≠ses de Ocean√≠a deber√°n devolver False. Esto te permitir√° utilizar los resultados de isin() para filtrar r√°pidamente los pa√≠ses de Ocean√≠a utilizando la indexaci√≥n booleana.\n\n\nInstrucciones\n\nDefina una Serie Booleana que describan si cada continent est√° o no fuera de Ocean√≠a; llama a esta Serie not_oceania.\n\n\n# Define a Series describing whether each continent is outside of Oceania\nnot_oceania = ~unemployment['continent'].isin(['Oceania'])\n\n\nUtiliza la indexaci√≥n booleana para imprimir el DataFrame unemployment sin ninguno de los datos relacionados con los pa√≠ses de Ocean√≠a.\n\n\n# Define a Series describing whether each continent is outside of Oceania\nnot_oceania = ~unemployment['continent'].isin(['Oceania'])\n\n# Print unemployment without records related  to countries in Oceania\nprint(unemployment[not_oceania])\n\n    country_code          country_name      continent   2010   2011   2012  \\\n0            AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1            AGO                Angola         Africa   9.43   7.36   7.35   \n2            ALB               Albania         Europe  14.09  13.48  13.38   \n3            ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4            ARG             Argentina  South America   7.71   7.18   7.22   \n..           ...                   ...            ...    ...    ...    ...   \n175          VNM               Vietnam           Asia   1.11   1.00   1.03   \n178          YEM           Yemen, Rep.           Asia  12.83  13.23  13.17   \n179          ZAF          South Africa         Africa  24.68  24.64  24.73   \n180          ZMB                Zambia         Africa  13.19  10.55   7.85   \n181          ZWE              Zimbabwe         Africa   5.21   5.37   5.15   \n\n      2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0    11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1     7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2    15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3     2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4     7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n175   1.32   1.26   1.85   1.85   1.87   1.16   2.04   2.39   2.17  \n178  13.27  13.47  13.77  13.43  13.30  13.15  13.06  13.39  13.57  \n179  24.56  24.89  25.15  26.54  27.04  26.91  28.47  29.22  33.56  \n180   8.61   9.36  10.13  10.87  11.63  12.01  12.52  12.85  13.03  \n181   4.98   4.77   4.78   4.79   4.78   4.80   4.83   5.35   5.17  \n\n[174 rows x 15 columns]\n\n\nValidaste datos categ√≥ricos y usaste tu validaci√≥n .isin() para excluir datos en los que no estabas interesado. Filtrar los datos que no necesitas al comienzo de tu proceso de EDA es una excelente manera de organizarte para la exploraci√≥n que est√° por venir.\n\n\nRango de validaci√≥n\nAhora es el momento de validar nuestros datos num√©ricos. En la lecci√≥n anterior vimos, utilizando .describe(), que la mayor tasa de desempleo durante 2021 fue de casi el 34 %, mientras que la m√°s baja estuvo justo por encima de cero.\nTu tarea en este ejercicio es obtener informaci√≥n mucho m√°s detallada sobre el rango de los datos de unemployment utilizando el diagrama de caja de Seaborn, y tambi√©n visualizar√°s el rango de las tasas de desempleo en cada continente para comprender las diferencias de rango geogr√°fico.\n\nInstrucciones\n\nImprime las tasas de desempleo m√≠nima y m√°ximam en este orden, durante 2021.\nCrea un diagrama de caja de las tasas de desempleo de 2021 (en el eje x), desglosadas por continente (en el eje y).\n\n\n# Print the minimum an maximum unemployment rates during 2021\nprint(unemployment['2021'].min(), unemployment['2021'].max())\n\n# Create a boxplot of 2021 unemployment rates, broken down by continent\nsns.boxplot(data=unemployment, x='2021', y='continent', \n            hue='continent', legend=False)\nplt.show()\n\n0.26 33.56\n\n\n\n\n\n\n\n\n\nObserva c√≥mo var√≠an los rangos de desempleo entre continentes. Por ejemplo, el percentil 50 de √Åfrica es m√°s bajo que el de Am√©rica del Norte, pero el rango es mucho m√°s amplio.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#resumen-de-datos",
    "href": "07_Analisis_exploratorio_de_datos/01_Conocer_un_conjunto_de_datos.html#resumen-de-datos",
    "title": "Conocer un conjunto de datos",
    "section": "Resumen de datos",
    "text": "Resumen de datos\n\nExplorando grupo de datos\n\n.groupby() grupo de datos por categor√≠a.\nFunci√≥n de agregaci√≥n indica c√≥mo se resume un grupo de datos.\n\n\n\nbooks.groupby('genre').mean()\n\n\n\nFunciones de agregaci√≥n\n\nSuma: .sum()\nConteo: .cont\nM√≠nimo: .min()\nM√°ximo: .max()\nVarianza: .var()\nDesviaci√≥n est√°ndar: .std()\n\nAgregaci√≥n de datos no agrupados\n\n.agg() aplica funciones de agregaci√≥n a trav√©s de un DataFrame\nPor defecto agrega todas las filas de una columna determinada\nSe suele utilizar cuando queremos m√°s de una funci√≥n\nSolo lo aplica a las columnas num√©ricas\n\n\n\nbooks.agg(['mean', 'std'])\n\n\n\nEspecificando agregaciones para columnas\n\n\nbooks.agg({'rating': ['mean', 'std'], 'year': ['median']})\n\n\n\nNombrando columnas resumen\n\n\nbooks.groupby('genre').agg(\n    mean_rating = ('rating', 'mean'),\n    std_rating = ('rating', 'std'),\n    median_year = ('year', 'median')\n)\n\n\n\nVisualizando res√∫menes categoricos\n\nCalculan autom√°ticamente la media de una variable cuantitativa\n\n\n\nsns.barplot(data=books, x='genre', y='rating')\nplt.show()\n\n\n\nRes√∫menes con .groupby() y .agg()\nEn este ejercicio, explorar√°s las medias y desviaciones est√°ndar de los datos anuales de desempleo. En primer lugar, encontrar√°s las medias y desviaciones est√°ndar independientemente del continente para observar las tendencias mundiales del desempleo. Despu√©s, comprobar√°s las tendencias del desempleo desglosadas por continente.\n\nimport pandas as pd\n\nruta = './data/clean_unemployment.csv'\nunemployment = pd.read_csv(ruta)\nprint(unemployment.head())\n\n  country_code          country_name      continent   2010   2011   2012  \\\n0          AFG           Afghanistan           Asia  11.35  11.05  11.34   \n1          AGO                Angola         Africa   9.43   7.36   7.35   \n2          ALB               Albania         Europe  14.09  13.48  13.38   \n3          ARE  United Arab Emirates           Asia   2.48   2.30   2.18   \n4          ARG             Argentina  South America   7.71   7.18   7.22   \n\n    2013   2014   2015   2016   2017   2018   2019   2020   2021  \n0  11.19  11.14  11.13  11.16  11.18  11.15  11.22  11.71  13.28  \n1   7.37   7.37   7.39   7.41   7.41   7.42   7.42   8.33   8.53  \n2  15.87  18.05  17.19  15.42  13.62  12.30  11.47  13.33  11.82  \n3   2.04   1.91   1.77   1.64   2.46   2.35   2.23   3.19   3.36  \n4   7.10   7.27   7.52   8.11   8.35   9.22   9.84  11.46  10.90  \n\n\n\nInstrucciones\n\nImprime la media y las desviaci√≥n est√°ndar d elas tasas de paro de cada a√±o (en ese orden).\n\n\n# Print the mean and standard deviation of rates by year\nprint(unemployment[\n    ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n].agg(['mean', 'std']))\n\n          2010      2011      2012      2013      2014      2015      2016  \\\nmean  8.409286  8.315440  8.317967  8.344780  8.179670  8.058901  7.925879   \nstd   6.248887  6.266795  6.367270  6.416041  6.284241  6.161170  6.045439   \n\n          2017      2018      2019      2020  \nmean  7.668626  7.426429  7.243736  8.420934  \nstd   5.902152  5.818915  5.696573  6.040915  \n\n\n\nImprime la media y la desviaci√≥n est√°ndar (en ese orden) de las tasas de paro de cada a√±o agrupadas por continente.\n\n\n# Print yearly mean and standard deviation grouped by continent\nprint(unemployment[\n    ['continent', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n].groupby(\"continent\").agg(['mean', 'std']))\n\n                    2010                 2011                 2012            \\\n                    mean       std       mean       std       mean       std   \ncontinent                                                                      \nAfrica          9.343585  7.411259   9.369245  7.401556   9.240755  7.264542   \nAsia            6.240638  5.146175   5.942128  4.779575   5.835319  4.756904   \nEurope         11.008205  6.392063  10.947949  6.539538  11.325641  7.003527   \nNorth America   8.663333  5.115805   8.563333  5.377041   8.448889  5.495819   \nOceania         3.622500  2.054721   3.647500  2.008466   4.103750  2.723118   \nSouth America   6.870833  2.807058   6.518333  2.801577   6.410833  2.936508   \n\n                    2013                 2014            ...      2016  \\\n                    mean       std       mean       std  ...      mean   \ncontinent                                                ...             \nAfrica          9.132453  7.309285   9.121321  7.291359  ...  9.277547   \nAsia            5.852128  4.668405   5.853191  4.681301  ...  6.094894   \nEurope         11.466667  6.969209  10.971282  6.759765  ...  9.394615   \nNorth America   8.840556  6.081829   8.512222  5.801927  ...  7.941111   \nOceania         3.980000  2.640119   3.976250  2.659205  ...  3.877500   \nSouth America   6.335000  2.808780   6.347500  2.834332  ...  7.230833   \n\n                             2017                2018                2019  \\\n                    std      mean       std      mean       std      mean   \ncontinent                                                                   \nAfrica         7.459439  9.284528  7.407620  9.237925  7.358425  9.264340   \nAsia           5.051796  6.171277  5.277201  6.090213  5.409128  5.949149   \nEurope         5.822793  8.359744  5.177845  7.427436  4.738206  6.764359   \nNorth America  5.503090  7.391111  5.326446  7.281111  5.253180  7.095000   \nOceania        2.477866  3.872500  2.492834  3.851250  2.455893  3.773750   \nSouth America  3.052309  7.281667  3.398994  7.496667  3.408856  7.719167   \n\n                              2020            \n                    std       mean       std  \ncontinent                                     \nAfrica         7.455293  10.307736  7.928166  \nAsia           5.254008   7.012340  5.699609  \nEurope         4.124734   7.470513  4.071218  \nNorth America  4.770490   9.297778  4.963045  \nOceania        2.369068   4.273750  2.617490  \nSouth America  3.379845  10.275000  3.411263  \n\n[6 rows x 22 columns]\n\n\nEstos datos est√°n bien resumidos, pero es un poco largo. ¬øQu√© pasar√≠asi quisieras enfocarte en un resumen de solo un a√±o y hacerlo m√°s legible? ¬°Int√©ntalo en el siguiente ejercicio!\n\n\n\nAgregaciones con nombre\nYa has visto c√≥mo .groupby() y .agg() pueden combinarse para mostrar res√∫menes para categor√≠as. A veces, es √∫til nombrar nuevas columnas al agregar, para que se quede claro en la salida del c√≥digo qu√© agregaciones se est√°n aplicando y d√≥nde.\nTu tarea consiste en crear un DataFrame llamado continent_summary que muestre una fila por cada continente. Las columnas del DataFram,e contendr√°n la tasa de paro media de cada continente en 2021, as√≠ como la desviaci√≥n est√°ndar de la tasa de empleo del 2021. Y por supuesto, ¬°renombrar√°s las columnas para que su contenido quede claro!\n\nInstrucciones\n\nCrea una columna llamada mean_rate_2021 que muestre la tasa de paro media de 2021 para cada continente.\nCrea una columna llamada std_rate_2021 que muestre la desviaci√≥n est√°ndar de la tasa de paro de 2021 para cada continente.\n\n\ncontinent_sumary = unemployment[\n    ['continent', '2021']\n].groupby('continent').agg(\n    # Create the mean_rate_2021 column\n    mean_rate_2021 = ('2021', 'mean'),\n    # Create the std_rate_2021 column\n    std_rate_2021 = ('2021', 'std'),\n)\nprint(continent_sumary)\n\n               mean_rate_2021  std_rate_2021\ncontinent                                   \nAfrica              10.473585       8.131636\nAsia                 6.906170       5.414745\nEurope               7.414872       3.947825\nNorth America        9.155000       5.076482\nOceania              4.280000       2.671522\nSouth America        9.924167       3.611624\n\n\nEl desempleo promedio de 2021 vari√≥ ampliamente por continente, y tambi√©n lo hizo el desempleo dentro de esos continentes.\n\n\n\nVisualizar res√∫menes categ√≥ricos\nComo has aprendido en este cap√≠tulo, Seaborn tiene muchas visualizaciones estupendas para la exploraci√≥n, incluido un gr√°fico de barras para mostrar un valor medio agregado por categor√≠a de datos.\nEn Seaborn, los gr√°ficos de barras incluyen una barra vertical que indica el intervalo de confianza del 95 % para la media categ√≥rica. Como los intervalos de confianza se calculan utilizando tanto el n√∫mero de valores como la variabilidad de esos valores, dan una indicaci√≥n √∫til de hasta qu√© punto se puede confiar en los datos.\nTu tarea consiste en crear un diagrama de barras para visualizar las medias y los intervalos de confianza de las tasas de desempleo en los distintos continentes.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nInstrucciones\n\nCrea un diagrama de barras que muestre los continentes en el eje x y lsus respectivas tasas medias de desempleo en 2021 en el eje y.\n\n\n# Create a bar plot of continents and their average unemployment\nsns.barplot(data=unemployment, x='continent', y='2021',\n            hue='continent', legend=False)\nplt.show()\n\n\n\n\n\n\n\n\nAunque Europa tiene un mayor desempleo promedio que Asia, tambi√©n tiene un intervalo de confianza m√°s peque√±o para ese promedio, por lo que el valor promedio es m√°s confiable.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Conocer un conjunto de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html",
    "title": "Limpieza e imputaci√≥n de datos",
    "section": "",
    "text": "Tratar los datos que faltan\nExplorar y analizar datos a menudo significa tratar con valores perdidos, tipos de datos incorrectos y valores at√≠picos. En este cap√≠tulo, aprender√°s t√©cnicas para gestionar estos problemas y agilizar tus procesos en EDA.\nprint(salaries.isna().sum())\nthreshold = len(salaries) * 0.05\nprint(threhold)\ncols_to_drop = salaries.columns[salaries.isna().sum() &lt;= threshold]\nprint(cols_to_drop)\nsalaries.dropna(subset=cols_to_drop, inplace=True) # Para actualizar el DataFrame\ncols_with_missing_values = salaries.columns[salaries.isna().sum() &gt; 0]\nprint(cols_with_missing_values)\nfor col in cols_with_missing_values[:-1]:\n        salaries[col].fillna(salaries[col].mode()[0])\nprint(salaries.isna().sum())\nsalaries_dict = salaries.groupby('Experience')['Salary_USD'].median().to_dict()\nprint(salaries_dict)\nsalaries['Salary_USD'] = salaries['Salary_USD'].fillna(salaries['Experience'].map(salaries_dict))",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Limpieza e imputaci√≥n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#tratar-los-datos-que-faltan",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#tratar-los-datos-que-faltan",
    "title": "Limpieza e imputaci√≥n de datos",
    "section": "",
    "text": "Por qu√© un dato faltante es un problema?\n\nAfectan las distribuciones\nLos datos de la poblaci√≥n son menos repreesntativos\nPuede resultar en conclusiones incorrectas\n\nEjemplo datos de profesionales de datos\n\n\n\n\n\n\n\n\n\nColumn\nDescription\nData type\n\n\n\n\nWorking_Year\nYear the data was obtained\nFloat\n\n\nDesignation\nJob title\nString\n\n\nExperience\nExperience level e.g., \"Mid\", \"Senior\"\nString\n\n\nEmployment_Satus\nType of employment contract e.g., \"FT\", \"PT\"\nString\n\n\nEmployee_Location\nCountry of employment\nString\n\n\nCompany_Size\nLabels for company size e.g., \"S\", \"M\", \"L\"\nString\n\n\nRemote_Working_Ratio\nPorcentage of time working remotely\nInteger\n\n\nSalary_USD\nSalary in US dollars\nFloat\n\n\n\n\nRevisando los datos faltantes\n\n\n\n\nEstrategias para el manejo de datos faltantes\n\nEliminar los datos faltantes\n\n5 % o menos del total de valores\n\nImputar la media, mediana o la moda\n\nDepende de la distribuci√≥n y contexto\n\nImputar por sub-grupos\n\nDiferentes niveles de experiencia tienen diferente mediana en el salario\n\n\nEliminando valores faltantes\n\n\n\n\n\n\n\nImputando una estad√≠stica de resumen\n\n\n\n\n\nRevisando los valores faltantes que faltan\n\n\n\n\nImputando por subgrupo\n\n\n\n\n\n\nTratar los datos que faltan\nEs importante tratar los datos que faltan antes de empezar el an√°lisis.\nUn enfoque consiste en descartar los valores que faltan si representan una peque√±a proporci√≥n, normalmente el 5 %, de los datos.\nTrabajando con un conjunto de datos sobre precios de tiquetes de avi√≥n, almacenado como un DataFrame de pandas llamado planes, tendr√°s que contar el n√∫mero de valores perdidos en todas las columnas, calcular el cinco porciento de todos los valores, utilizar este umbral para eliminar observaciones y comprobar cu√°ntos valores perdidos quedan en el conjunto de datos.\n\nimport pandas as pd\n\nruta = './data/planes.csv'\nplanes = pd.read_csv(ruta)\nprint(planes.head)\n\n&lt;bound method NDFrame.head of            Airline Date_of_Journey    Source Destination  \\\n0      Jet Airways       9/06/2019     Delhi      Cochin   \n1           IndiGo      12/05/2019   Kolkata    Banglore   \n2           IndiGo      01/03/2019  Banglore   New Delhi   \n3         SpiceJet      24/06/2019   Kolkata    Banglore   \n4      Jet Airways      12/03/2019  Banglore   New Delhi   \n...            ...             ...       ...         ...   \n10655     Air Asia       9/04/2019   Kolkata    Banglore   \n10656    Air India      27/04/2019   Kolkata    Banglore   \n10657  Jet Airways      27/04/2019  Banglore       Delhi   \n10658      Vistara      01/03/2019  Banglore   New Delhi   \n10659    Air India       9/05/2019     Delhi      Cochin   \n\n                       Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n0      DEL ‚Üí LKO ‚Üí BOM ‚Üí COK    09:25  04:25 10 Jun      19h     2 stops   \n1            CCU ‚Üí NAG ‚Üí BLR    18:05         23:30   5h 25m      1 stop   \n2            BLR ‚Üí NAG ‚Üí DEL    16:50         21:35   4h 45m      1 stop   \n3                  CCU ‚Üí BLR    09:00         11:25   2h 25m    non-stop   \n4            BLR ‚Üí BOM ‚Üí DEL    18:55  10:25 13 Mar  15h 30m      1 stop   \n...                      ...      ...           ...      ...         ...   \n10655              CCU ‚Üí BLR    19:55         22:25   2h 30m    non-stop   \n10656              CCU ‚Üí BLR    20:45         23:20   2h 35m    non-stop   \n10657              BLR ‚Üí DEL      NaN         11:20       3h    non-stop   \n10658              BLR ‚Üí DEL    11:30         14:10   2h 40m    non-stop   \n10659  DEL ‚Üí GOI ‚Üí BOM ‚Üí COK    10:55         19:15   8h 20m     2 stops   \n\n                   Additional_Info    Price  \n0                          No info  13882.0  \n1                          No info   6218.0  \n2                          No info  13302.0  \n3                          No info   3873.0  \n4      In-flight meal not included  11087.0  \n...                            ...      ...  \n10655                      No info   4107.0  \n10656                      No info   4145.0  \n10657                          NaN   7229.0  \n10658                      No info  12648.0  \n10659                      No info  11753.0  \n\n[10660 rows x 11 columns]&gt;\n\n\n\nInstrucciones\n\nImprime el n√∫mero de valores perdidos en cada columna del DataFrame\n\n\n# Count the number of missing values in each column\nprint(planes.isna().sum())\n\nAirline            427\nDate_of_Journey    322\nSource             187\nDestination        347\nRoute              256\nDep_Time           260\nArrival_Time       194\nDuration           214\nTotal_Stops        212\nAdditional_Info    589\nPrice              616\ndtype: int64\n\n\n\nCalcula a cu√°ntas observaciones equivale el cinco porciento del DataFrame planes\n\n\n# Find the five percent threshold\nthreshold = len(planes) * 0.05\nprint(threshold)\n\n533.0\n\n\n\n\n\n\nCrea cols_to_drop aplicando una indexaci√≥n booleana a las columnas del DataFrame con valores perdidos menores o iguales que el umbral.\nUtiliza este filtro para eliminar los valores que faltan y guardar el DataFrame actualizado.\n\n\n# Create a filter\ncols_to_drop = planes.columns[planes.isna().sum() &lt;= threshold]\nprint(cols_to_drop)\n\n# Drop missing values for columns below the threshold\nplanes.dropna(subset=cols_to_drop, inplace=True)\n\nprint(planes.isna().sum())\n\nIndex(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops'],\n      dtype='object')\nAirline              0\nDate_of_Journey      0\nSource               0\nDestination          0\nRoute                0\nDep_Time             0\nArrival_Time         0\nDuration             0\nTotal_Stops          0\nAdditional_Info    300\nPrice              368\ndtype: int64\n\n\nAl crear un umbral de valores faltantes y usarlo para filtrar columnas, haz logrado eliminar los valores faltantes de todas las columnas excepto \"Additinal_Info\" y \"Price\".\n\n\n\nEstrategias para datos que faltan\nLa regla del cinco porciento ha funcionado muy bien en tu conjunto de dato planes, ¬°eliminando los valores perdidos de nueve de las 11 columnas!\nAhora tienes que decidir qu√© hacer con las columnas \"Additional_Info\" y \"Price\", a las que les faltan los valores 300 y 368 respectivamente.\nPrimero echar√°s un vistazo a lo que contiene \"Additional_Info\", y despu√©s visualizar√°s el precio de los billetes de avi√≥n de distintas compa√±√≠as a√©reas.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nInstrucciones\n\nImprime los valores y frecuencias de \"Additional_Info\".\n\n\n# Check the values of the Additional_Info column\nprint(planes['Additional_Info'].value_counts())\n\nAdditional_Info\nNo info                         6399\nIn-flight meal not included     1525\nNo check-in baggage included     258\n1 Long layover                    14\nChange airports                    7\nNo Info                            2\nBusiness class                     1\nRed-eye flight                     1\n2 Long layover                     1\nName: count, dtype: int64\n\n\n\nCrea un boxplot de \"Price\" frente a \"Airline\"\n\n\n# Create a box plot of Price by Airline\nsns.boxplot(data=planes, x='Airline', y='Price',\n            hue='Airline', legend=False)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta\n\n\n¬øC√≥mo debes tratar los valores que faltan en \"Additional_Info\" y \"Price\".?\n\nRespuestas Posibles\n\nElimina la columna \"Additional_Info\" e imputa la media para los valores que faltan de \"Price\".\nElimina los valores de \"No info\" de \"Additiona_Info\" e imputa la mediana de los valores que faltan de \"Price\".\nElimina la columna \"Additional_Info\" e imputa la media por \"Airline\" para los valores que falten de \"Price\".\nElimina la columna \"Additional_Info\" e imputa la mediana por \"Airline\" para los valores que falten de \"Price\".\n\nNo necesitamos la columna \"Additional_Info\", y deber√≠as imputar la mediana de \"Price\" por \"Airline\" para representar los datos con precisi√≥n.\n\n\n\nImputar los precios de los aviones que faltan\n!Ahora solo queda una columna con valores perdidos!\nHas eliminado la columna \"Additional_Info\" de planes, el √∫ltimo paso es imputar los datos que faltan en la columna \"Price\" del conjunto de datos.\nComo recordatorio, t√∫ generaste este diagrama de caja, que suger√≠a que imputar el precio medio bas√°ndose en el \"Airline\" ¬°es un enfoque s√≥lido!\n\n# Eliminamos la columna Additional_Info\nplanes = planes.drop('Additional_Info', axis=1)\nplanes.columns\n\nIndex(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops', 'Price'],\n      dtype='object')\n\n\n\nInstrucciones\n\nAgrupa planes por aerol√≠nea y calcula el precio medio.\n\n\n# Calculate median plane ticket prices by Airplane\nairline_prices = planes.groupby('Airline')['Price'].median()\n\nprint(airline_prices)\n\nAirline\nAir Asia              5192.0\nAir India             9443.0\nGoAir                 5003.5\nIndiGo                5054.0\nJet Airways          11507.0\nMultiple carriers    10197.0\nSpiceJet              3873.0\nVistara               8028.0\nName: Price, dtype: float64\n\n\n\nConvierte los precios medios agrupados en un diccionario.\n\n\n# Convert to a dictionary\nprices_dict = airline_prices.to_dict()\nprint(prices_dict)\n\n{'Air Asia': 5192.0, 'Air India': 9443.0, 'GoAir': 5003.5, 'IndiGo': 5054.0, 'Jet Airways': 11507.0, 'Multiple carriers': 10197.0, 'SpiceJet': 3873.0, 'Vistara': 8028.0}\n\n\n\n\n\n\nImputa condicionalmente los valores perdidos de \"Price\" asignando los valores de la columna \"Airline\" en funci√≥n de prices_dict\nComprueba si faltan valores\n\n\n# Map the dictionary to missing values of Price by Airline\nplanes['Price'] = planes['Price'].fillna(planes['Airline'].map(prices_dict))\n\n# Check for missing values\nprint(planes.isna().sum())\n\nAirline            0\nDate_of_Journey    0\nSource             0\nDestination        0\nRoute              0\nDep_Time           0\nArrival_Time       0\nDuration           0\nTotal_Stops        0\nPrice              0\ndtype: int64\n\n\nConvertiste un DataFrame agrupado a un diccionario y luego lo usaste para llenar condicionalmente los valores faltantes de \"Price\" bas√°ndote en \"Airline\". Ahora vamos a explorar c√≥mo realizar an√°lisis exploratorio en datos categ√≥ricos.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Limpieza e imputaci√≥n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#convertir-y-analizar-datos-categ√≥ricos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#convertir-y-analizar-datos-categ√≥ricos",
    "title": "Limpieza e imputaci√≥n de datos",
    "section": "Convertir y analizar datos categ√≥ricos",
    "text": "Convertir y analizar datos categ√≥ricos\n\nPrevisualizar los datos\n\n\nprint(salaries.select_dtypes('object').head())\n\n\n\nT√≠tulos de los trabajos\n\n\nprint(salaries['Designation'].value_counts())\n\n\n\nprint(salaries['Designation'].nunique())\n\n\n\n\nExtrayendo valores desde las categor√≠as\n\nEl formato actual de los datos limita la capacidad de generar informaci√≥n.\npandas.Series.str.contains()\n\nBusca en una columna una cadena especifica o m√∫ltiples cadenas.\n\n\n\n\nsalaries['Designation'].str.contains('Scientist')\n\n\n\nFiltrar filas que contienen una o m√°s frases\n\nPalabras de interes: Machine Learning o AI\n\n\n\nsalaries['Designation'].str.contains('Machine Learning|AI')\n\n\n\nBuscar m√∫ltiples frases en una cadena de caracteres\n\nPalabras de interes: Cualquiera que inicie con Data\n\n\n\nsalaries['Designation'].str.contains('ÀÜData')\n\n\nAhora que se tiene una idea de c√≥mo funciona este m√©todo, definamos una lista de t√≠tulos de trabajo que queremos encontrar:\n\njob_categories = ['Data Science', 'Data Analytics',\n                   'Data Engineering', 'Machine Learning',\n                   'Managerial', 'Consultant']\n\nLuego necesitamos crear variables que contengan nuestros filtros\n\ndata_science = 'Data Scientist|NLP'\ndata_analyst = 'Analyst|Analytics'\ndata_engineer = 'Data Engineer|ETL|Architect|Infrastructure'\nml_engineer = 'Machine Learning|ML|Bid Data|AI'\nmanager = 'Manager|Head|Director|Lead|Principal|Staff'\nconsultant = 'Consultant|Freelance'\n\nEl siguiente paso es crear una lista con nuestro rango de condiciones para el m√©todo str.contains\n\nconditions = [\n    (salaries['Designation'].str.contains(data_science)),\n    (salaries['Designation'].str.contains(data_analyst)),\n    (salaries['Designation'].str.contains(data_engineer)),\n    (salaries['Designation'].str.contains(ml_engineer)),\n    (salaries['Designation'].str.contains(manager)),\n    (salaries['Designation'].str.contains(consultant))\n]\n\nFinalmente, podemos crear nuestra nueva columna Job_Category usando la funci√≥n de selecci√≥n de Numpy\n\nsalaries['Job_Category'] = np.select(conditions,\n                                     job_categories,\n                                     default='Other')\n\nAl obtener una vista previa de la Designaci√≥n y nuestra nueva columna Job_Category, podemos verificar los primeros cinco valores.\n\nprint(salaries[['Designation', 'Job_Category']].head())\n\n\n\nVisualizaci√≥n de la frecuencia de la categor√≠a job\n\n\nsns.countplot(data=salaries, x='Job_Category')\nplt.show()\n\n\n\nEncontrar el n√∫mero de valores √∫nicos\nTe gustar√≠a practicar algunas de las habilidades de manipulaci√≥n y an√°lisis de datos categ√≥ricos que acabas de ver. Para ayudarte a identificar qu√© datos podr√≠an reformatearse para extraer valor, vas a averiguar qu√© columnas no num√©ricas del conjunto de datos planes tienen un gran n√∫mero de valores √∫nicos.\n\nInstrucciones\n\nFiltra planes para las columnas que sean del tipo datos \"object\".\nRecorre las columnas del conjunto de datos.\nA√±ade el iterador de columna a la sentencia print y, a continucaci√≥n, llama a la funci√≥n para que devuelva el n√∫mero de valores √∫nicos de la columna.\n\n\n# Filter the DataFrame for objects columns\nnon_numeric = planes.select_dtypes('object')\n\n# Loop through columns\nfor column in non_numeric.columns:\n    # Print the number of unique values\n    print(f\"Number of unique values in {column} column: {non_numeric[column].nunique()}\")\n\nNumber of unique values in Airline column: 8\nNumber of unique values in Date_of_Journey column: 44\nNumber of unique values in Source column: 5\nNumber of unique values in Destination column: 6\nNumber of unique values in Route column: 122\nNumber of unique values in Dep_Time column: 218\nNumber of unique values in Arrival_Time column: 1220\nNumber of unique values in Duration column: 362\nNumber of unique values in Total_Stops column: 5\n\n\nCuriosamente, \"Duration\" es actualmente una columna de tipo objeto cuando deber√≠a ser una columna num√©rica, ¬°y tiene 362 valores √∫nicos! Vamos a averiguar m√°s sobre esta columna.\n\n\n\nCategor√≠a de duraci√≥n de vuelos\nComo has visto, hay 362 valores √∫nicos en la columna \"Duration\" de planes. Llamando a planes['Duration'].head(), vemos los siguientes valores.\n\n\n0        19h\n1     5h 25m\n2     4h 45m\n3     2h 25m\n4    15h 30m\nName: Duration, dtype: object\n\n\nParece que no ser√° sencillo convertirlo a n√∫meros. Sin embargo, ¬°podr√≠as clasificar los vuelos por duraci√≥n y examinar la frecuencia de las distintas longitudes de vuelo!\nCrear√°s una columna \"Duration_Category\" en el DataFrame planes. Antes tendr√°s que crear una lista de valores que deseas insertar en el DataFrame, seguida de los valores existentes a partir de los cuales deben crearse.\n\nInstrucciones\n\nCrea una lista de categor√≠as que contengan \"Short-haul\", \"Medium\" y \"Long-haul\".\n\n\n# Create a list of categories\nflight_categories = ['Short-haul', 'Medium', 'Long-haul']\n\n\n\n\n\nCrea short_flights, una cadena para capturar valores de \"0h\", \"1h\", \"2h\", \"3h\", \"4h\" teniendo cuidado de evitar valores como \"10h\".\nCrea medium_flights para capturar cualquier valor entre cinco y nueve horas. ~\nCrea long_flights para capturar cualquier valor comprendido entre 10 y 16 horas, ambos inclusive.\n\n\n# Create a list of categories\nflight_categories = ['Short-haul', 'Medium', 'Long-haul']\n\n# Create short-haul values\nshort_flights = '^0h|^1h|^2h|^3h|^4h'\n\n# Create medium-haul values\nmedium_flights = '^5h|^6h|^7h|^8h|^9h'\n\n# Create long-haul values\nlong_flights = '^10h|^11h|^12h|^13h|^14h|^15h|^16h'\n\nAhora has creado tus categor√≠as y valores, es hora de agregar condicionalmente las categor√≠as en el DataFrame\n\n\n\nA√±adir categor√≠as de duraci√≥n\nAhora que has configurado las categor√≠as y los valores que quieres capturar, ¬°es hora de construir una nueva columna para analizar la frecuencia de los vuelos seg√∫n su duraci√≥n!\nLas variablesflight_categories, short_flights, medium_flights y long_flights que creaste anteriormente est√°n a tu disposici√≥n.\n\nimport numpy as np\n\n\nInstrucciones\n\nCrea conditions, una lista que contenga subconjuntos de planes['Duration'] basados en short_flights, medium_flights y long_flights.\nCrea la columna \"Duration_Category\" llamando a una funci√≥n que acepte tu lista conditions y flight_categories, estableciendo los valores no encontrados en \"Extreme duration\".\nCrea un gr√°fico fque muestre el recuento de cada categor√≠a.\n\n\n# Create conditions for values in flight_categories to be created\nconditions = [\n    (planes['Duration'].str.contains(short_flights)),\n    (planes['Duration'].str.contains(medium_flights)),\n    (planes['Duration'].str.contains(long_flights))\n]\n\n# Apply the conditions list to the flight_categories\nplanes['Duration_Category'] = np.select(conditions, flight_categories,\n                                        default='Extreme duration')\n\n# Plot the counts of each category√ü\nsns.countplot(data=planes, x='Duration_Category',\n              hue='Duration_Category', legend=False)\nplt.show()\n\n\n\n\n\n\n\n\n¬°Est√° claro que la mayor√≠a de los vuelos son de corta distancia.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Limpieza e imputaci√≥n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#trabajar-con-datos-num√©ricos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#trabajar-con-datos-num√©ricos",
    "title": "Limpieza e imputaci√≥n de datos",
    "section": "Trabajar con datos num√©ricos",
    "text": "Trabajar con datos num√©ricos\n\nEl dataset origina de los salarios\n\n\nprint(salaries.info())\n\n\n\nSalario en Rupias\n\n\nprint(salaries['Salary_In_Rupees'].head())\n\n\n\nConvirtiendo cadena de caracteres en n√∫meros\n\nRemover las comas de los valores Salary_In_Rupees\nConvertir la columna a tipo de dato float\nCrear una nueva columna convirtiendo la moneda a d√≥lares\n\n\n\npd.Series.str.replace('Caracter a remover', 'Caracter a reemplazar')\n\n\nsalaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].str.replace(',', '')\nprint(salaries['Salary_In_Rupees'].head())\n\n\n\nsalaries['Salary_In_Rupees'] = salaries['Salary_In_Rupees'].astype(float) \n\n1 Indian Rupee = 0.012 US Dollars\n\nsalaries['Salary_USD'] = salaries['Salary_In_Rupees'] * 0.012\n\n\nPrevisualizando la nueva columna\n\n\nprint(salaries[['Salary_In_Rupees', 'Salary_USD']].head())\n\n\n\nA√±adiendo un resumen esrtad√≠stico al DataFrame\n\n\nsalaries.groupby('Company_Size')['Salary_USD'].mean()\n\n\nCalculo de la desviaci√≥n est√°ndar de los salarios por experiencia:\n\n\nsalaries['std_dev'] = salaries.groupby('Experience') \\ \n                      ['Salary_USD'].transform(lambda x: x.std())\n\n\nprint(salaries[['Experience', 'std_dev']].value_counts())\n\n\nRepitamos el proceso para otros datos estad√≠sticos:\n\nsalaries['median_by_comp_size'] = salaries.groupby('Company_Size') \\\n                                  ['Salary_USD'].transform(lambda x: x.median())\n\n\nprint(salaries[['Company_Size', 'median_by_comp_size']].head())\n\n\n\nDuraci√≥n del vuelo\nTe gustar√≠a analizar la duraci√≥n de los vuelos, pero por desgracia, la columna \"Duration\" de DataFrame planes contiene actualmente valores de cadena.\nTendr√°s que limpiar la columna y convertirla al tipo de datos correcto para el an√°lisis.\n\nimport re\n\ndef duration_to_decimal_str(duration_str: str) -&gt; str:\n    '''\n    Convierte una duraci√≥n de vuelo de formato '2h 30m' a una cadena en formato decimal en horas, como '2.5h'.\n    \n    Par√°metros:\n    -----------\n    duration_str : str\n        Cadena de texto que representa la duraci√≥n de un vuelo, como '2h 30m', '45m', '19h', etc.\n\n    Retorna:\n    --------\n    str\n        Cadena con duraci√≥n expresada en horas decimales, con un solo decimal y el sufijo 'h'. Ej: '2.5h'\n    '''\n    horas = re.search(r'(\\d+)\\s*h', duration_str)\n    minutos = re.search(r'(\\d+)\\s*m', duration_str)\n\n    h = int(horas.group(1)) if horas else 0\n    m = int(minutos.group(1)) if minutos else 0\n\n    decimal_hours = round(h + m / 60, 1)\n    return f'{decimal_hours}h'\n\n\n\nplanes['Duration'] = planes['Duration'].apply(duration_to_decimal_str)\n\n\nInstrucciones\n\nImprime los cinco primeros valores de la columna \"Duration\".\n\n\n# Preview the column\nprint(planes['Duration'].head())\n\n0    19.0h\n1     5.4h\n2     4.8h\n3     2.4h\n4    15.5h\nName: Duration, dtype: object\n\n\n\nRetira \"h\" de la columna\n\n\n# Remove the string character\nplanes['Duration'] = planes['Duration'].str.replace('h', '')\nprint(planes['Duration'].head())\n\n0    19.0\n1     5.4\n2     4.8\n3     2.4\n4    15.5\nName: Duration, dtype: object\n\n\n\nConvierte la columna al tipo de datos float.\n\n\n# Convert to float data type\nplanes['Duration'] = planes['Duration'].astype(float)\nprint(planes['Duration'].head())\n\n0    19.0\n1     5.4\n2     4.8\n3     2.4\n4    15.5\nName: Duration, dtype: float64\n\n\n\nTraza un histograma de los valores de \"Duration\"\n\n\n# Plot a histogram\nsns.histplot(data=planes, x='Duration')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nA√±adir estad√≠sticas descriptivas\nAhora \"Duration\" y \"Price\"contienen valores num√©ricos en el DataFrame planes, y te gustar√≠a calcular para ellos estad√≠sticas de resumen condicionadas a los valores de otras columnas.\n\nInstrucciones\n\nA√±ade una columna a planes que contenga la desviaci√≥n est√°ndar de \"Price\" basada en \"Airline\".\n\n\n# Price standard deviation by Airline\nplanes['airline_price_st_dev'] = planes.groupby('Airline')['Price'].transform(lambda x: x.std())\nprint(planes[['Airline', 'airline_price_st_dev']].value_counts())\n\nAirline            airline_price_st_dev\nJet Airways        4159.846432             3082\nIndiGo             2245.529140             1632\nAir India          3692.609285             1399\nMultiple carriers  3558.323763              959\nSpiceJet           1798.900648              653\nVistara            2888.915498              376\nAir Asia           1979.826234              260\nGoAir              2764.926625              147\nName: count, dtype: int64\n\n\n\nCalcula la mediana de \"Duration\" en \"Airline\", almacen√°ndola como una columna llamada \"airline_median_duration\".\n\n\n# Median Duration by Airline\nplanes['airline_median_duration'] = planes.groupby('Airline')['Duration'].transform(lambda x: x.median())\nprint(planes[['Airline', 'airline_median_duration']].value_counts())\n\nAirline            airline_median_duration\nJet Airways        13.3                       3082\nIndiGo             2.9                        1632\nAir India          15.5                       1399\nMultiple carriers  10.2                        959\nSpiceJet           2.5                         653\nVistara            3.2                         376\nAir Asia           2.8                         260\nGoAir              2.9                         147\nName: count, dtype: int64\n\n\n\nEncuenta la media \"Price\" por \"Destination\", guard√°ndola como una columna llamada \"price_destination_mean\".\n\n\n# Mean Price by Destination\nplanes['price_destination_mean'] = planes.groupby('Destination')['Price'].transform(lambda x: x.mean())\nprint(planes[['Destination', 'price_destination_mean']].value_counts())\n\nDestination  price_destination_mean\nCochin       10473.585927              3631\nBanglore     9093.622872               2291\nDelhi        5248.541082                998\nNew Delhi    11579.306944               720\nHyderabad    5190.274021                562\nKolkata      4907.156863                306\nName: count, dtype: int64\n\n\nParece que Jet Airways tiene la mayor desviaci√≥n est√°ndar en precio, Air India tiene la mayor duraci√≥n median, y Nueva Delhi, en promedio, es el destiono m√°s caro. Ahora veamos c√≥mo manejar los datos at√≠picos.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Limpieza e imputaci√≥n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#gesti√≥n-de-valores-at√≠picos",
    "href": "07_Analisis_exploratorio_de_datos/02_Limpieza_e_imputacion_de_datos.html#gesti√≥n-de-valores-at√≠picos",
    "title": "Limpieza e imputaci√≥n de datos",
    "section": "Gesti√≥n de valores at√≠picos",
    "text": "Gesti√≥n de valores at√≠picos\n\nQu√© es un outlier?\n\nEs una observaci√≥n que est√° muy alejada de otros puntos de datos.\n\nUsando estad√≠stica descriptiva\n\n\nprint(salaries['Salary_USD'].describe())\n\n\n\nUsando el rango intercuartil\n\nRango intercuartil (IQR)\n\nIQR = 75th - 25th percentil\nUpper outliers &gt; 75th percentile + (1.5 * IQR)\nLower Outliers &lt; 25th percentile - (1.5 * IQR)\n\n\n\n\nsns.boxplot(data=salaries, y='Salaary_USD')\nplt.show()\n\n\n\nIdentificando Umbrales\n\n\n# 75th percentil\nseventy_fifth = salaries['Salary_USD'].quantile(0.75)\n\n# 25th percentil\ntwenty_fifth = salaries['Salary_USD'].quantile(0.25)\n\n# Interquartil range\nsalaries_iqr = seventy_fifth - twenty_fifth\n\nprint(salaries_iqr)\n\n\n\n# Upper threshold\nupper = seventy_fifth + (1.5 * salaries_iqr)\n\n# Lower threshold\nlower = twenty_fifth - (1.5 * salaries_iqr)\n\nprint(upper, lower)\n\n\n\nSubdividiendo nuestros datos\n\n\nsalaries[(salaries['Salary_USD'] &lt; lower) | (salaries['Salary_USD'] &gt; upper)] \\\n        [['Experience', 'Employee_Location', 'Salary_USD']]\n\n\n\n¬ø Por qu√© buscar los Outliers?\n\nLos Outliers son valores extremos\n\nPueden no representar con precisi√≥n los datos\n\nPueden sesgar la media y la desviaci√≥n est√°ndar\nPruebas de estad√≠stica y modelos de machine learning requieren datos que tengan una distribuci√≥n normal y no esten sesgados.\n\nQu√© hacer con los Outliers?\n\nPreguntas que nos debemos hacer:\n\nPor qu√© existen los outliers?\nLos valores son precisos?\n\n\nEliminaci√≥n de Outliers\n\n\nno_outliers = salaries[(salaries['Salar_USD'] &gt; lower) & (salaries['Salary_USD'] &lt; upper)]\n\n\nprint(no_outliers['Salary_USD'].describe())\n\n\n\nDistribuci√≥n de Salarios\n\n\n\nQu√© hacer con los valores at√≠picos?\nIdentificar los valores at√≠picos es un paso integral en la realizaci√≥n de an√°lisis exploratorios de datos.\nEn este ejercicio, se te presentar√°n escenarios en los que hay valores at√≠picos, y tendr√°s que decidir qu√© acci√≥n debes tomar.\n\nInstrucciones\n\nColoca cada escenario en el cubo adecuado en funci√≥n del enfoque que deba adaptarse para tratar los valores at√≠picos.\n\n\n\n\n\n\n\nElimina los valores at√≠picos\nDejar los valores at√≠picos en el conjunto de datos\n\n\n\n\nUn sensor de temperatura tiene un registro de 100 grados Celsius, pero el sensor solo funciona correctamente a temperaturas de hasta 80 grados.\nse registran las alturas de distintos animales y uno de ellos es m√°s de 1.5 veces la IQR m√°s el percentil 75.\n\n\nLa velocidad de un coche se registra como 5000 km/h.\nLos pa√≠ses tienen una superficie total media de 667.143 km2, pero un pa√≠s tiene 1.637.687 km2.\n\n\nUn participante en un estudio tiene una edad de menos 35 a√±os.\nUn jugador de baloncesto hace una media de 35 puntos por partido cuando la media en toda la liga es de solo 10 puntos por partido.\n\n\n\n\nPuede ser dif√≠cil decidir qu√© hacer con los valores at√≠picos, pero debes saber c√≥mo gestionarlos, ¬°ya que a menudo se dan en el mundo real!\n\n\n\nIdentificar valores at√≠picos\nHas demostrado que reconoces qu√© hacer cuando se te presentan valores at√≠picos, pero ¬øPuedes identificarlos utilizando visualizaciones?\nIntenta averiguar si hay valores at√≠picos en las columnas \"Price\" o \"Duration\" del dataframe planes.\n\nIntrucciones\n\nTraza la distribuci√≥n de la columna \"Price\" de planes.\n\n\n# Plot a histogram of flight prices\nsns.histplot(data=planes, x='Price')\nplt.show()\n\n\n\n\n\n\n\n\n\nMuestra las estad√≠sticas descriptivas de la duraci√≥n del vuelo.\n\n\n# Display descriptive statistics for flight duration\nprint(planes['Duration'].describe())\n\ncount    8508.000000\nmean       10.726704\nstd         8.472415\nmin         0.100000\n25%         2.800000\n50%         8.700000\n75%        15.500000\nmax        47.700000\nName: Duration, dtype: float64\n\n\n\nPregunta\n\n¬øQu√© columna contiene potencialmente valores at√≠picos?\nRespuestas Posibles\n\n\"Price\"\n\"Duration\"\n\"Price\" y \"Duration\"\nNinguna\n\nLos histogramas, diagramas de caja y estad√≠sticas descriptivas tambi√©n son m√©todos √∫tiles para identificar valores extremos. ¬°Ahora vamos a tratarlos!\n\n\n\nEliminar valores at√≠picos\nAunque eliminar los valores at√≠picos no siempre es el camino a seguir, para tu an√°lisis has decidido que solo incluir√°s los vuelos en los que el \"Price\" no sea un valor at√≠pico.\nPor lo tanto tienes que encontrar el umbral superior y utilizarlo para eliminar los valores que lo superen del Dataframe planes.\n\nInstrucciones\n\nHalla los percentiles 75 y 25, guardando como price_seventy_fifth y price_twenty_fifth respectivamente.\n\n\n# Find the 75th and 25th percentiles\nprice_seventy_fifth = planes['Price'].quantile(0.75)\nprice_twenty_fifth = planes['Price'].quantile(0.25)\n\n\nCalcula el IQR, almacen√°ndolo como prices_iqr.\n\n\n# Calculate iqr\nprices_iqr = price_seventy_fifth - price_twenty_fifth\nprint(prices_iqr)\n\n7014.0\n\n\n\nCalcula los umbrales superior e inferior de los valores at√≠picos.\n\n\n# Calculate the thresholds\nupper = price_seventy_fifth + (1.5 * prices_iqr)\nlower = price_twenty_fifth - (1.5 * prices_iqr)\n\n\nElimina los valores at√≠picos de planes.\n\n\n# Subset the data\nplanes = planes[(planes['Price'] &gt; lower) & (planes['Price'] &lt; upper)]\n\nprint(planes['Price'].describe())\n\ncount     8438.000000\nmean      8877.466046\nstd       4001.838236\nmin       1759.000000\n25%       5224.000000\n50%       8372.000000\n75%      12121.000000\nmax      22270.000000\nName: Price, dtype: float64\n\n\n¬°Habilidades rid√≠culas para eliminar valores at√≠picos! Lograste crear umbrales basados en el IQR y los usaste para filtrar el conjunto de datos planes para eliminar precios extremos. Originalmente, el conjunto de datos ten√≠a un precio m√°ximo de casi 55000, pero la salida de planes['Price'].describe() muestra que el m√°ximo se ha reducido a alrededor de 23000, ¬°reflejando una distribuci√≥n menos sesgada para el an√°lisis!",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Limpieza e imputaci√≥n de datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html",
    "title": "Relaciones en los datos",
    "section": "",
    "text": "Patrones a lo largo del tiempo\nLas variables de los conjuntos de datos tienen relaciones entre s√≠. En este cap√≠tulo, examinar√°s las relaciones entre datos num√©ricos, categ√≥ricos e incluso DateTime, explorando la direcci√≥n y la fuerza de estas relaciones, as√≠ como las formas de visualizarlas.\ndivorce = pd.read_csv(\"divorce.csv\")\ndivorce.head()\ndivorce.dtypes\ndivorce = pd.read_csv(\"divorce.csv\", parse_dates=[\"marriage_date\"])\ndivorce.dtypes\ndivorce['marriage_date'] = pd.to_datetime(divorce['marriage_date'])\ndivorce_dtypes\ndivorce.head(2)\ndivorce['marriage_date'] = pd.to_datetime(divorce[['month', 'day', 'year']])\ndivorce.head(2)\nEs posible extraer s√≥lo el mes, el d√≠a o el a√±o de una columna que contenga una fecha completa, usando los atributos dt.month, dt.day y dt.year.\ndivorce['marriage_month'] = divorce['marriage_date'].dt.month()\ndivorce.head()\nsns.lineplot(data=divorce, x='marriage_month', y='marriage_duration')\nplt.show()\nLos amplios intervalos de confianza sugieren que se necesita m√°s an√°lisis.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#patrones-a-lo-largo-del-tiempo",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#patrones-a-lo-largo-del-tiempo",
    "title": "Relaciones en los datos",
    "section": "",
    "text": "Importando data DateTime\n\nDataTime necesita ser explicitamente declarada en pandas\n\n\n\n\n\n\n\n\nEste tipo de datos abre muchas posibilidades para el an√°lisis, como observar patrones a lo largo de a√±os, meses o incluso d√≠as de la semana.\n\n\n\nConviritiendo los datos a DataTime\n\npd.to_datetime() convierte los argumentos de datos DateTime\n\n\n\n\n\nCreando datos DateTime\n\n\n\n\n\n\n\n\n\nVisualizando patrones a lo largo del tiempo\n\n\n\n\n\nImportar datos DateTime\n¬°Ahora trabajar√°s con todo el conjunto de datos del divorcio! Los datos desciben los matrimonios mexicanos disueltos entre 2000 y 2015. Contiene las fechs de matrimonio y divorcio, el nivel educativo, la fecha de nacimiento, los ingresos de cada miembro de la pareja y la duraci√≥n del matrimonio, as√≠ como el n√∫mero de hijos que ten√≠a la pareja en el momento del divorcio.\nLos nombres de ls columnas y los tipos de datos son los siguientes:\n\n¬°Parece que hay mucha informaci√≥n de fecha en estos datos que todav√≠a no son de tipo DateTime! Tu tarea es arreglarlo para que puedas explorar patrones a lo largo del tiempo.\n\nimport pandas as pd\n\nruta = './data/divorce.csv'\ndivorce = pd.read_csv(ruta)\ndivorce.head()\n\n\n\n\n\n\n\n\ndivorce_date\ndob_man\neducation_man\nincome_man\ndob_woman\neducation_woman\nincome_woman\nmarriage_date\nmarriage_duration\nnum_kids\n\n\n\n\n0\n2006-09-06\n1975-12-18\nSecondary\n2000.0\n1983-08-01\nSecondary\n1800.0\n2000-06-26\n5.0\n1.0\n\n\n1\n2008-01-02\n1976-11-17\nProfessional\n6000.0\n1977-03-13\nProfessional\n6000.0\n2001-09-02\n7.0\nNaN\n\n\n2\n2011-01-02\n1969-04-06\nPreparatory\n5000.0\n1970-02-16\nProfessional\n5000.0\n2000-02-02\n2.0\n2.0\n\n\n3\n2011-01-02\n1979-11-13\nSecondary\n12000.0\n1981-05-13\nSecondary\n12000.0\n2006-05-13\n2.0\nNaN\n\n\n4\n2011-01-02\n1982-09-20\nProfessional\n6000.0\n1988-01-30\nProfessional\n10000.0\n2007-08-06\n3.0\nNaN\n\n\n\n\n\n\n\n\nInstrucciones\n\nImporta divorce.csv, guardando como DataFrame, divorce: indica en la funci√≥n de importaci√≥n que las columnas divorce_date, dob_man, dob_woman, y marriage_date deben importarse como valores DateTime.\n\n\n# Import divorce.csv, parseing the appropriate columns as dateds in the import\ndivorce = pd.read_csv('./data/divorce.csv', parse_dates=['divorce_date', 'dob_man', 'dob_woman', 'marriage_date'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date        datetime64[ns]\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\nBuen trabajo parseando esas fechas al mismo tiempo que importabas los datos en pandas. ¬°Ahora, intenta actualizar los tipos de datos DateTime en una DataFrame que ya ha sido importado!\n\n\n\nActualizar tipo de datos a DateTime\nAhora se te ha cargado el DataFrame divorce, pero una columna se almacea como una cadena que deber√≠a ser un dato DateTime. ¬øCu√°l es? Una vez que hayas identificado la columna, la actualizar√°s para que puedas explorarla m√°s de cerca en el siguiente ejercicio.\n\nruta = './data/divorce.csv'\ndivorce = pd.read_csv(ruta, parse_dates=['divorce_date', 'dob_man', 'dob_woman'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date                object\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\n\nInstrucciones\n\nPregunta\n\n¬øCu√°l de las columnas del DataFrame divorce no se ha actualizado a un tipo de datos DateTime, pero deber√≠a hacerse?\nRespuestas posibles\n\ndivorce_date\nmarriage_date\neducation_woman\nnum_kids\n\n\nCovierte la columna marriage_date del DataFrame divorce en valores de DateTime.\n\n\n# Convert the marriage_date column to DateTime values\ndivorce['marriage_date'] = pd.to_datetime(divorce['marriage_date'])\nprint(divorce.dtypes)\n\ndivorce_date         datetime64[ns]\ndob_man              datetime64[ns]\neducation_man                object\nincome_man                  float64\ndob_woman            datetime64[ns]\neducation_woman              object\nincome_woman                float64\nmarriage_date        datetime64[ns]\nmarriage_duration           float64\nnum_kids                    float64\ndtype: object\n\n\nAhora, est√°s listo para ver c√≥mo la fecha de matrimonio de una pareja se relaciona con otros datos.\n\n\n\nVisualizar las relaciones a lo largo del tiempo\nAhora que tus datos de fechas se guardan como datos DateTime, ¬°puedes explorar patrones a lo largo del tiempo! ¬øTiene relaci√≥n el a√±o en que se cas√≥ una pareja con el n√∫mero de hijos que tiene en el momento del divorcio? ¬°Tu tarea es averiguarlo!\n\nInstrucciones\n\nDefine una columna llamada marriage_year, que solo contiene la parte del a√±o de la columna marriage_date.\n\n\n# Define the marriage_year column\ndivorce['marriage_year'] = divorce['marriage_date'].dt.year\n\n\nCrea un gr√°fico de l√≠neas que muestre el n√∫mero medio de hijos que tuvo una pareja durante su matrimonio, ordenado por el a√±o en que la pareja se cas√≥.\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Create a lineplot showing the average  number of kids by year\nsns.lineplot(data=divorce, x='marriage_year', y='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\n¬°Bien hecho! Haz descubierto un patr√≥n aqu√≠, parece que las parejas que se casaron en a√±os posteriores tambi√©n tuvieron menos hijos durante su matrimonio.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#correlaci√≥n",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#correlaci√≥n",
    "title": "Relaciones en los datos",
    "section": "Correlaci√≥n",
    "text": "Correlaci√≥n\n\nCorrelaci√≥n\n\nDescribe la direcci√≥n de la relaci√≥n de entre dos variables as√≠ como su fuerza.\nConfigurar numeric_only=True previene errores con columnas no num√©ricas.\nEl m√©todo .cor() calcula el coeficiente de correlaci√≥n de Pearson.\n\n\n\ndivorce.corr(numeric_only=True)\n\n\n\n\n\n\n\n\nincome_man\nincome_woman\nmarriage_duration\nnum_kids\nmarriage_year\n\n\n\n\nincome_man\n1.000000\n0.318047\n0.085321\n0.040848\n0.019170\n\n\nincome_woman\n0.318047\n1.000000\n0.078677\n-0.018015\n0.026433\n\n\nmarriage_duration\n0.085321\n0.078677\n1.000000\n0.447358\n-0.812469\n\n\nnum_kids\n0.040848\n-0.018015\n0.447358\n1.000000\n-0.461495\n\n\nmarriage_year\n0.019170\n0.026433\n-0.812469\n-0.461495\n1.000000\n\n\n\n\n\n\n\n\nMapas de calor de correlaci√≥n\n\n\nsns.heatmap(divorce.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nCorrelaci√≥n en contexto\n\n\ndivorce['divorce_date'].min()\n\nTimestamp('2000-01-08 00:00:00')\n\n\n\ndivorce['divorce_date'].max()\n\nTimestamp('2015-11-03 00:00:00')\n\n\n\nVisualizaci√≥n de las relaciones\n\nEs importante complementar nuestros c√°lculos de correlaci√≥n con gr√°ficos de dispersi√≥n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuerte relaci√≥n, pero no lineal\nEl coeficiente de correlaci√≥n de Pearson: -6.48e-18\n\n\nRelaci√≥n cuadr√°tica; no lineal\nCoeficiente de correlaci√≥n de Pearson: .971211\n\n\n\n\n\nScatter plots\n\n\nsns.scatterplot(data=divorce, x='income_man', y='income_woman')\nplt.show()\n\n\n\n\n\n\n\n\n\nPairplots\n\nEs √∫til para obtener una descripci√≥n general r√°pida de las relaciones dentro del conjunto de datos.\nTanta informaci√≥n en un elemento visual puede ser dif√≠cil de interpretar con grandes conjuntos de datos.\n\n\n\nsns.pairplot(data=divorce)\nplt.show()\n\n\n\n\n\n\n\n\nEs posible limitar el n√∫mero de relaciones graficadas estableciendo el argumento vars igual a las variables de inter√©s.\n\nsns.pairplot(data=divorce, vars=['income_man', 'income_woman', 'marriage_duration'])\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretar un mapa de calor\n¬øCu√°l de las siguientes afirmaciones es correcta respecto a las relaciones entre variables en el DataFrame divorce?\n\ndivorce['marriage_moth'] = divorce['marriage_date'].dt.month\ndivorce.head()\n\n\n\n\n\n\n\n\ndivorce_date\ndob_man\neducation_man\nincome_man\ndob_woman\neducation_woman\nincome_woman\nmarriage_date\nmarriage_duration\nnum_kids\nmarriage_year\nmarriage_moth\n\n\n\n\n0\n2006-09-06\n1975-12-18\nSecondary\n2000.0\n1983-08-01\nSecondary\n1800.0\n2000-06-26\n5.0\n1.0\n2000\n6\n\n\n1\n2008-01-02\n1976-11-17\nProfessional\n6000.0\n1977-03-13\nProfessional\n6000.0\n2001-09-02\n7.0\nNaN\n2001\n9\n\n\n2\n2011-01-02\n1969-04-06\nPreparatory\n5000.0\n1970-02-16\nProfessional\n5000.0\n2000-02-02\n2.0\n2.0\n2000\n2\n\n\n3\n2011-01-02\n1979-11-13\nSecondary\n12000.0\n1981-05-13\nSecondary\n12000.0\n2006-05-13\n2.0\nNaN\n2006\n5\n\n\n4\n2011-01-02\n1982-09-20\nProfessional\n6000.0\n1988-01-30\nProfessional\n10000.0\n2007-08-06\n3.0\nNaN\n2007\n8\n\n\n\n\n\n\n\n\nInstrucciones\nRespuestas Posibles\n\nmarriage_duration est√° fuertemente correlacionada de forma positiva con marriage_month.\nLa correlaci√≥n entre num_kids y income_man es m√°s fuerte que la correlaci√≥n entre num_kids y marriage_duration.\nUn marriage_year m√°s tard√≠o provoca un menor n√∫mero de hijos, representado por num_kids.\nUn marriage_year m√°s tard√≠o est√° correlacionado con tener menos hijos.\n\n\n\n\nVisualizar las relaciones entre variables\nEn el √∫ltimo ejercicio, habr√°s observado que un marriage_duration m√°s largo est√° correlacionado con tener m√°s hijos , representado por la columna num_kids. El coeficiente de correlaci√≥n entre las variables marriage_duration y num_kids es 0.45.\nEn este ejercicio, crear√°s un gr√°fico de dispersi√≥n para visualizar la relaci√≥n entre estas variables.\n\nInstrucciones\n\nCree un diagrama de dispersi√≥n que muestre marriage_duration en el eje x y num_kids en el eje y.\n\n\n# Create the scatterplot\nsns.scatterplot(data=divorce, x='marriage_duration', y='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\nHay una ligera relaci√≥n positiva en el gr√°fico de dispersi√≥n. En el conjunto de datos, las parejas sin hijos no tienen valor en la columna num_kids. Si est√°s seguro que todos o la mayor√≠a de los valores faltantes en num_kids est√°n relacionados con parejas sin hijos, podr√≠as considerar actualizar estos valores a 0, lo que podr√≠a aumentar la correlaci√≥n.\n\n\n\nVisualizar las relaciones entre m√∫ltiples variables\nSeaborn‚Äôs .pairplot() es excelente para comprender las relaciones entre varias o todas las vatiables de un conjunto de datos, agregando gr√°ficos de dispersi√≥n por pares en un solo visual.\nTu tarea consiste en utilizar un pairplot par comparar la relaci√≥n entre ‚Äòmarriage_duration‚Äô y ‚Äòincome_woman‚Äô.\n\nInstrucciones\n\nCrea un diagrama de pares para visualizar las relaciones entre income_woman y marriage_duration en el DataFrame divorce.\n\n\n# Create a pairplot for income_woman and marriage_duration\nsns.pairplot(data=divorce, vars=['income_woman', 'marriage_duration'])\nplt.show()\n\n\n\n\n\n\n\n\nAl igual que la matriz de correlaci√≥n , puedes ver que la relaci√≥n entre income_woman y marriage_duration no es fuerte. Tambi√©n puedes tener una idea de las distribuciones de ambas variables en los gr√°ficos superior izquierdo e inferior derecho.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#relaciones-y-distribuciones-de-los-factores",
    "href": "07_Analisis_exploratorio_de_datos/03_Relaciones_en_los_datos.html#relaciones-y-distribuciones-de-los-factores",
    "title": "Relaciones en los datos",
    "section": "Relaciones y distribuciones de los factores",
    "text": "Relaciones y distribuciones de los factores\n\nNivel de educaci√≥n: male partner\n\n\ndivorce['education_man'].value_counts()\n\neducation_man\nProfessional    1313\nPreparatory      501\nSecondary        288\nPrimary          100\nOther              3\nName: count, dtype: int64\n\n\n\nExplorando las relaciones categ√≥ricas\n\n\nsns.histplot(data=divorce, x='marriage_duration', binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.histplot(data=divorce, x='marriage_duration', hue='education_man', binwidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\nKernel Desnsity Estimate (KDE) plots\n\n\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man')\nplt.show()\n\n\n\n\n\n\n\n\nLos gr√°ficos KDE nos permiten visualizar las distribuciones. Los KDE son m√°s interpretables, especialmente cuando se muestran varias distribuciones.\nLa distribuci√≥n con KDE parece sugerir que algunas parejas tuvieron duraciones menores a cero.\nPara solucionar esto, podempos utilizar el argumento de la palabra clave cut.\n\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man', cut=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nGr√°ficos KDE acumulativos\n\n\nimport seaborn as sns\nsns.kdeplot(data=divorce, x='marriage_duration', hue='education_man', cut=0, cumulative=True)\nplt.show()\n\n\n\n\n\n\n\n\nEste gr√°fico describe la probabilidad de que la duraci√≥n del matrimonio sea menor o igual al valor del eje x para cada nivel de educaci√≥n de la pareja masculina.\n\nRelaci√≥n entre la edad del matrimonio y la educaci√≥n\n\nHay una relaci√≥n entre la edad al momento del matrimonio y el nivel de educaci√≥n?\n\n\n\ndivorce['man_age_marriage'] = divorce['marriage_year'] - divorce['dob_man'].dt.year\ndivorce['woman_age_marriage'] = divorce['marriage_year'] - divorce['dob_woman'].dt.year\n\n\nScatter plot con las variables categ√≥ricas\n\n\nsns.catplot(data=divorce, x='woman_age_marriage', y='man_age_marriage')\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.catplot(data=divorce, x='woman_age_marriage', y='man_age_marriage', hue='education_man')\nplt.show()\n\n\n\n\n\n\n\n\n\nDatos categ√≥ricos en gr√°ficos de dispersi√≥n\nEn el video se exploro c√≥mo se relacionan el nivel educativo de los hombres y la edad al casarse con otras variables de nuestro conjunto de datos, el DataFrame divorce. Ahora ver√°s c√≥mo se relacionan la formaci√≥n de las mujeres y la edad al casarse con otras variables.\nTu tarea consiste en crear un diagrama de dispersi√≥n de la edad y los ingresos de cada mujer, incorporando la variable categ√≥rica del nivel educativo para obtener un contexto adicional.\n\nInstrucciones\n\nCrea un gr√°fico de dispersi√≥n que muestre woman_age_marriage en el eje de abcisas y income_woman en el eje de las ordenadas, cada punto de datos debe colorearse en funci√≥n del nivel educativo de la mujer, representado por education_woman.\n\n\n# Create a scatter plot\nsns.scatterplot(data=divorce, x='woman_age_marriage', y='income_woman', hue='education_woman')\nplt.show()\n\n\n\n\n\n\n\n\nParece que hay una correlaci√≥n positiva entre la educaci√≥n profesional y los salarios m√°s altos, como cabr√≠a esperar. La relaci√≥n entre la edad de las mujeres al casarse y el nivel educativo es un poco menos clara.\n\n\n\nExplorando con gr√°ficos KDE\nLos gr√°ficos de Estimaci√≥n de Densidad del N√∫cleo (KDE) son una gran alternativa a los histogramas cuando quieres mostrar varias distribuciones en el mismo gr√°fico.\nSupongamos que te interesa la relaci√≥n entre la duraci√≥n del matrimonio y el n√∫mero de hijos que tiene una pareja. Como los valores de la columna num_kids s√≥lo van de uno a cinco, puedes graficar el KDE de cada valor en la misma gr√°fica.\nRecuerda que la columna num_kids de divorce solo muestra los valores N/A de las parejas sin hijos, por lo que solo ver√°s las distribuciones de las parejas divorciadas con al menos un hijo.\n\nInstrucciones\n\nCree un gr√°fico KDE que muestre marriage_duration en el eje x y una l√≠nea de color diferente para cada posible n√∫mero de hijos que pueda tener una pareja, representada por num_kids.\n\n\n# Create the KDE plot\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids')\nplt.show()\n\n\n\n\n\n\n\n\n\nObserva que actualmente el gr√°fico muestra duraciones del matrimonio inferiores a cero; actualiza el grafico KDE para que la duraci√≥n del matrimonio no pueda suavizarse m√°s all√° de los puntos de datos extremos.\n\n\n# Update the KDE plot so that marriage durantion can't be smoothed too far\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids', cut=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nActualiza el c√≥digo del gr√°fico KDE del paso anterior para que muestre una funci√≥n de distribuci√≥n acumulativo para cada n√∫mero de hijos que tiene una pareja.\n\n\n# Update the KDE plot to show a cumulative distribution function\nsns.kdeplot(data=divorce, x='marriage_duration', hue='num_kids', cut=0, cumulative=True)\nplt.show()\n\n\n\n\n\n\n\n\nParece que hay una correlaci√≥n positiva entre matrimonios m√°s largos y m√°s hijos, pero por supuesto, esto no indica causalidad. Tambi√©n puedes ver que hay muchos menos datos sobre parejas con m√°s de dos hijos; esto nos ayuda a entender cuan confiables son nuestros hallazgos.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>Relaciones en los datos</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html",
    "title": "Convertir el an√°lisis exploratorio en acci√≥n",
    "section": "",
    "text": "Consideraciones para datos categ√≥ricos\nEl an√°lisis exploratorio de datos es un paso crucial en el flujo de trabajo de la ciencia de datos, ¬°por no esl el final! Ahora es el momento de aprender t√©cnicas y consideraciones que puedes utilizar para avanzar con √©xito en tus proyectos una vez que hayas terminado de explorar.\nprint(planes('Destination').value_counts())\nplanes['Destination'].value_counts(normalize=True)\nEs nuestra muestra representativa de la poblaci√≥n? (Vuelos internos de India)\npd.crosstab(planes['Source'], planes['Destination'])\npd.crosstab(planes['Source'], planes['Destination'],\n           values=planes['Price'], aggfunc='median')\nLos resultados muestran valores de la mediana para todas las rutas posibles en el conjunto de datos.",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Convertir el an√°lisis exploratorio en acci√≥n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#consideraciones-para-datos-categ√≥ricos",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#consideraciones-para-datos-categ√≥ricos",
    "title": "Convertir el an√°lisis exploratorio en acci√≥n",
    "section": "",
    "text": "Por qu√© ejecutar EDA?\n\nDetectar patrones y relaciones.\nGenerar preguntas o hip√≥tesis.\nPreparar datos para modelos de machine learning.\n\nRepresentatividad de los datos\n\nLa muestra debe representar la poblaci√≥n.\nPor ejemplo:\n\nEducaci√≥n versus ingresos en USA\n\nNo se pueden usar datos de Francia\n\n\n\nClases Categ√≥ricas\n\nClases = etiquetas\nEjemplo, actitudes de las personas hacia el matrimonio.\n\nEstado civil\n\nSoltero\nCasado\nDivorciado\n\n\n\nDesbalance de Clases\n\n\n\nFrecuencia de Clases\n\n\n\n\nFrecuencia relativa de clases\n\n40% de los vuelos internos de la India van hacia Delhi.\n\n\n\n\n\n\nTabulaci√≥n Cruzada\n\nEs otro m√©todo para observar la frecuencia de clase, que permite examinar la frecuencia de combinaciones de clases\n\n\n\n\n\n\nExtendiendo la tabulaci√≥n cruzada\n\n\n\n\nSource\nDestination\nMedian Price (IDR)\n\n\n\n\nBanglore\nDelhi\n4232.21\n\n\nBanglore\nNew Delhi\n12114.56\n\n\nChennai\nKolkata\n3859.76\n\n\nDelhi\nCochin\n9987.63\n\n\nKolkata\nBanglore\n9654.21\n\n\nMumbai\nHyderabad\n3431.97\n\n\n\n\nAgregaci√≥n de valores con pd.crosstab()\n\n\n\n\n\nComparando la muestra con la poblaci√≥n\n\n\n\n\nSource\nDesitnation\nMedian Price (IDR)\nMedian Price (dataset)\n\n\n\n\nBanglore\nDelhi\n4232.21\n4823.0\n\n\nBanglore\nNew Delhi\n12114.56\n10976.50\n\n\nChennai\nKolkata\n3859.76\n3850.0\n\n\nDelhi\nCochin\n9987.63\n10260.0\n\n\nKolkata\nBanglore\n9654.21\n9345.0\n\n\nMumbai\nHyderabad\n3431.97\n3342.0\n\n\n\n\nComprobaci√≥n del desequilibrio de clases\nLa Encuesta Kaggle 2022 recoge la informaci√≥n sobre la formaci√≥n de los cient√≠ficos de datos, sus tecnolog√≠as y t√©cnicas preferidas. Se considera una visi√≥n precisa de lo que est√° ocurriendo en la ciencia de datos, basada en el volumen y el perfil de los que responden.\nUna vez examinados los t√≠tulos de los puestos y categorizados para alinearlos con nuestro salaries DataFrame`, puedes ver la siguiente proporci√≥n de categor√≠as laborales en la encuesta Kaggle:\n\n\n\nCategor√≠a laboral\nFrecuencia relativa\n\n\n\n\nCiencia de datos\n0,281236\n\n\nAn√°lisis de datos\n0,224231\n\n\nOtros\n0,214609\n\n\nDirecci√≥n\n0,121300\n\n\nMachine Learning\n0,083248\n\n\nIngenier√≠a de datos\n0,075375\n\n\n\nPensando en los resultados de la encuesta Kaggle como poblaci√≥n, tu tarea consiste en averiguar si el DataFrame salaries es representativo comparando la frecuencia relativa de las categor√≠as laborales.\n\nimport pandas as pd\nruta = './data/salaries.csv'\nsalaries = pd.read_csv(ruta)\nsalaries.head()\n\n\n\n\n\n\n\n\nWorking_Year\nDesignation\nExperience\nEmployment_Status\nSalary_In_Rupees\nEmployee_Location\nCompany_Location\nCompany_Size\nRemote_Working_Ratio\nSalary_USD\nJob_Category\n\n\n\n\n0\n2020\nMachine Learning Scientist\nSE\nFT\n20688070.0\nJP\nJP\nS\n0.0\n248256.840\nMachine Learning\n\n\n1\n2020\nBig Data Engineer\nSE\nFT\n8674985.0\nGB\nGB\nM\n50.0\n104099.820\nData Engineering\n\n\n2\n2020\nProduct Data Analyst\nMI\nFT\n1591390.0\nHN\nHN\nS\n0.0\n19096.680\nData Analytics\n\n\n3\n2020\nMachine Learning Engineer\nSE\nFT\n11935425.0\nUS\nUS\nL\n50.0\n143225.100\nMachine Learning\n\n\n4\n2020\nData Analyst\nEN\nFT\n5729004.0\nUS\nUS\nL\n100.0\n68748.048\nData Analytics\n\n\n\n\n\n\n\n\nInstrucciones\n\nImprime la frecuencia relativa de la columna Job_Category de salaries DataFrame\n\n\n\n\n\n\n\nNote\n\n\n\nPara exportar el dataset en formato CSV dentro de DataCamp y luego copiarlo:\nprint(salaries.to_csv(index=False))\n\n\n\n# Print the relative frequency of Job_Category\nprint(salaries['Job_Category'].value_counts(normalize=True))\n\nJob_Category\nData Science        0.277641\nData Engineering    0.272727\nData Analytics      0.226044\nMachine Learning    0.120393\nOther               0.068796\nManagerial          0.034398\nName: proportion, dtype: float64\n\n\nParece que Data Science es la clase m√°s popular y tiene una representaci√≥n similar. A√∫n as√≠, las otras categor√≠as tienen frecuencias relativas bastante diferentes, lo cual pordr√≠a no ser sorprendente dado que el p√∫blico objetivo son cient√≠fico de datos. Dada la diferencia en las frecuencias relativas, ¬øpuedes confiar en que el DataFrame salaries representa con precisi√≥n los roles gerenciales?\n\n\n\nTabulaci√≥n cruzada\nLa tabulaci√≥n cruzada puede ayudar a identificar c√≥mo se combinan las observaciones.\nUtilizando el conjunto de datos salaries, que se ha importado como un DataFrame pandas, realizar√°s una tabulaci√≥n cruzada de m√∫ltiples variables, incluyendo el uso de la agregaci√≥n, para ver la relaci√≥n entre ‚ÄòCompany_Size‚Äô y otras variables.\n\nInstrucciones\n\nRealiza una tabulaci√≥n cruzada, estableciendo Company_Size como √≠ndice, y las columnas a las clases en Experience.\n\n\n# Cross-tabulate Company_Size and Experience\nprint(pd.crosstab(salaries['Company_Size'], salaries['Experience']))\n\nExperience    EN  EX  MI   SE\nCompany_Size                 \nL             24   7  49   44\nM             25   9  58  136\nS             18   1  21   15\n\n\n\nCruza ‚ÄòJob_Category‚Äô y las clases de ‚ÄòCompany_Size‚Äô como nombres de columna.\n\n\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size']))\n\nCompany_Size       L   M   S\nJob_Category                \nData Analytics    23  61   8\nData Engineering  28  72  11\nData Science      38  59  16\nMachine Learning  17  19  13\nManagerial         5   8   1\nOther             13   9   6\n\n\n\nActualiza pd.crosstab() para que devuelva los valores medios de Salary_USD.\n\n\n# Cross-tabulate Job_Category and Company_Size\nprint(pd.crosstab(salaries['Job_Category'], salaries['Company_Size'], values= salaries['Salary_USD'], aggfunc='mean'))\n\nCompany_Size                  L              M             S\nJob_Category                                                \nData Analytics    112851.749217   95912.685246  53741.877000\nData Engineering  118939.035000  121287.060500  86927.136000\nData Science       96489.520105  116044.455864  62241.749250\nMachine Learning  140779.491529  100794.236842  78812.586462\nManagerial        190551.448800  150713.628000  31484.700000\nOther              92873.911385   89750.578667  69871.248000\n\n\n√âsta es una funci√≥n √∫til para examinar la combinaci√≥n de frecuencias, as√≠ como para encontrar estad√≠sticas agregadas. ¬°Parece que el salario medio m√°s alto es para roles de datos gerenciales en grandes empresas!",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Convertir el an√°lisis exploratorio en acci√≥n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-nuevas-caracter√≠sticas",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-nuevas-caracter√≠sticas",
    "title": "Convertir el an√°lisis exploratorio en acci√≥n",
    "section": "Generar nuevas Caracter√≠sticas",
    "text": "Generar nuevas Caracter√≠sticas\n\nCorrelaci√≥n\n\n\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\nViendo el tipo de datos\n\n\nprint(planes.dtypes)\n\n\n\nTotal Stops\n\n\nprint(planes['Total_Stops'].value_counts())\n\n\nSe observa que es necesario eliminar algunos caracteres.\n\nLimpiando Total Stops\n\n\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stops', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace(' stop', '')\nplanes['Total_Stops'] = planes['Total_Stops'].str.replace('non-stop', '0')\nplanes['Total_Stops'] = planes['Total_Stops'].astype(int)\n\n\nCorrelaci√≥n\n\n\nsns.heatmap(planes.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\nFechas\n\n\nprint(planes.dtypes)\n\n\n\nExtrayendo el mes y el d√≠a de la semana\n\n\nplanes['month'] = planes['Date_of_Journey'].dt.month\nplanes['weekday'] = planes['Date_of_Journey'].dt.weekday\nprint(planes[['month', 'weekday', 'Date_of_Journey']].head())\n\n\n\nTiempos de salidas y llegadas\n\n\nplanes['Dep_Hour'] = planes['Dep_Time'].dt.hour\nplanes['Arrival_Hour'] = planes['Arrival_Time'].dt.hour\n\n\nCorrelaci√≥n\n\n\nNo hay correlaciones, pero no lo sabr√≠amos si no se hubieran generado nuevas caracter√≠sticas.\n\nCreando caracter√≠sticas\n\n\nprint(planes['Price'].describe())\n\n\n\n\n\nRango\nTipo de tiquete\n\n\n\n\n&lt;= 5228\nEconomy\n\n\n&gt; 5528 &lt;= 8355\nPremium Economy\n\n\n&gt; 8355 &lt;= 12373\nBusiness Class\n\n\n&gt; 12373\nFirst Class\n\n\n\n\nEstad√≠stica descriptiva\n\n\ntwenty_fifth = planes['Price'].quantile(0.25)\nmedian = planes['Price'].median()\nseventy_fifth = planes['Price'].quantile(0.75)\nmaximum = planes['Price'].max()\n\n\nEtiquetas y bins\n\n\nlabels = ['Economy', 'Premium Economy', 'Business Class', 'First Class']\nbins = [0, twenty_fifth, median, seventy_fifth, maximum]\n\n\npd.cut()\n\n\n\nplanes['Price_Category'] = pd.cut(planes['Price'], labels=labels, bins=bins)\n\n\nCategor√≠a de precios\n\n\nprint(planes[['Price', 'Price_Category']].head())\n\n\n\nCategor√≠a de precio por aerol√≠nea\n\n\nsns.countplot(data=planes, x='Airline', hue='Price_Category')\nplt.show()\n\n\n\nExtraer caracter√≠sticas para la correlaci√≥n\nEn este ejercicio trabajar√°s con una versi√≥n del conjunto de datos salaries que contiene una nueva columna llamada ‚Äú`date_of_response‚Äù.\nEl conjunto de datos se ha le√≠do comjo un DataFrame de pandas, con ‚Äúdate_of_response‚Äù como tipo de datos datetime.\nTu tarea consiste en extraer los atributos fecha-hora de esta columna y, a continuaci√≥n, crear un mapa de calor para visualizar los coeficientes de correlaci√≥n entre las variables.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nPara realizar el ejercicio fue necesario bajar el DataFrame de Datacamp teniendo en cuenta la nueva columna, y cambiando el tipo de formato de la columna date_of_response usando los comandos:\n\nprint(salaries.to_csv(index=false))\n\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nruta = './data/salaries_2.csv'\nsalaries = pd.read_csv(ruta)\n\n# Cambia el tipo de datos de date_of_response\nsalaries['date_of_response'] = pd.to_datetime(salaries['date_of_response'])\nsalaries.head()\n\n\n\n\n\n\n\n\nDesignation\ndate_of_response\nExperience\nEmployment_Status\nSalary_In_Rupees\nEmployee_Location\nCompany_Location\nCompany_Size\nRemote_Working_Ratio\nSalary_USD\nJob_Category\n\n\n\n\n0\nMachine Learning Scientist\n2020-01-07\nSE\nFT\n20688070.0\nJP\nJP\nS\n0.0\n248256.840\nMachine Learning\n\n\n1\nBig Data Engineer\n2020-09-19\nSE\nFT\n8674985.0\nGB\nGB\nM\n50.0\n104099.820\nData Engineering\n\n\n2\nProduct Data Analyst\n2020-11-21\nMI\nFT\n1591390.0\nHN\nHN\nS\n0.0\n19096.680\nData Analytics\n\n\n3\nMachine Learning Engineer\n2020-11-29\nSE\nFT\n11935425.0\nUS\nUS\nL\n50.0\n143225.100\nMachine Learning\n\n\n4\nData Analyst\n2020-09-07\nEN\nFT\n5729004.0\nUS\nUS\nL\n100.0\n68748.048\nData Analytics\n\n\n\n\n\n\n\n\nInstrucciones\n\nExtrae el mes de ‚Äúdate_of_response‚Äù, almacen√°ndolo como una columna llamada ‚Äúmonth‚Äù.\nCrea la columna ‚Äúweekday‚Äù, que contiene el d√≠a de la semana en que los participantes completaron la encuesta.\nTraza un mapa de calor, incluyendo las puntuaciones del coeficiente de correlaci√≥n de Pearson.\n\n\n# Get the month of the response\nsalaries['month'] = salaries['date_of_response'].dt.month\n\n# Extract the weekday of the response\nsalaries['weekday'] = salaries['date_of_response'].dt.weekday\n\n# Create a heatmap\nsns.heatmap(salaries.corr(numeric_only=True), annot=True)\nplt.show()\n\n\n\n\n\n\n\n\n¬°Fant√°stica creaci√≥n de caracter√≠sticas! Parece que no hay relaciones significativas entre nuestras variables num√©ricas, as√≠ que veamos si convertir los datos num√©ricos en clases ofrece informaci√≥n adicional.\n\n\n\nC√°lculo de los percentiles salariales\nTu tarea consiste en convertir la columna ‚ÄúSalary_USD‚Äù en categor√≠as basadas en sus percentiles . Primero tienes que encontrar los percentiles y almacenarlos como variables.\n\nInstrucciones\n\nHalla el percentil 25 de ‚ÄúSalary_USD‚Äù\nGuarda la mediana de ‚ÄúSalary_USD‚Äù como salaries_median.\nObt√©n el percentil 75 de los salaries\n\n\n# Find the 25th percentile \ntwenty_fifth = salaries['Salary_USD'].quantile(0.25)\n\n# Save the median\nsalaries_median = salaries['Salary_USD'].median()\n\n# Gather the 75th percentile\nseventy_fifth = salaries['Salary_USD'].quantile(0.75)\n\nprint(twenty_fifth, salaries_median, seventy_fifth)\n\n60880.691999999995 97488.552 143225.1\n\n\n¬°Parece que el rango intercuartil est√° entre 60881 y 143225 d√≥lares! ¬°Ahora usemos estas variables para agregar una columna categ√≥rica de salario en el DataFrame\n\n\n\nCategorizar los salarios\n¬°Ahora es el momento de crear una nueva categor√≠a! Utilizar√°s las variables twenty_fifth, salaries_median y seventy_fifth, que creaste en el ejercicio anterior, para dividir los salarios en diferentes etiquetas.\nEl resultado ser√° una nueva columna llamada ‚Äúsalary_level‚Äù, que incorporar√°s a una visualizaci√≥n para analizar el salario de los encuestados y en empresas de distintos tama√±os.\n\nInstrucciones\n\nCrea salaries_labels, una lista que contenga ‚Äúentry‚Äù, ‚Äúmid‚Äù, ‚Äúsenior‚Äù y ‚Äúexec‚Äù.\n\n\n# Create salary labels\nsalary_labels = ['entry', 'mid', 'senior', 'exec']\n\n\nTermina salary_ranges, a√±adiendo el percentil 25, la mediana, el percentil 75 y el valor m√°s grande de ‚ÄúSalary_USD‚Äù\n\n\n# Create the salary ranges list\nsalary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries['Salary_USD'].max()]\n\n\nDivide ‚ÄúSalary_USD‚Äù en funci√≥n de las etiquetas y rangos que hayas creado.\n\n\n# Create salary_level\nsalaries['salary_level'] = pd.cut(salaries['Salary_USD'], bins=salary_ranges, labels=salary_labels)\n\n\nUtiliza sns.countplot() para visualizar el reconteo de ‚ÄúCompany_Size‚Äù, factrorizando las etiquetas de nivel salarial.\n\n\n# Plot the count of salary levels at companies of different sizes\nsns.countplot(data=salaries, x='Company_Size', hue='salary_level')\nplt.show()\n\n\n\n\n\n\n\n\nAl usar pd.cut() para dividir los datos num√©ricos en categor√≠as, se puede ver que una gran proporci√≥n de trabajadores en empresas peque√±as reciben salarios de nivel de ‚Äúentrada‚Äù, mientras que m√°s personal en empresas medianas son recompensados con salarios de nivel ‚Äúsenior‚Äù. ¬°Ahora vamos a ver c√≥mo generar hip√≥tesis a medida que se llega al final de la fase de EDA!",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Convertir el an√°lisis exploratorio en acci√≥n</span>"
    ]
  },
  {
    "objectID": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-hip√≥tesis",
    "href": "07_Analisis_exploratorio_de_datos/04_Convertir_analisis_exploratorio_en_accion.html#generar-hip√≥tesis",
    "title": "Convertir el an√°lisis exploratorio en acci√≥n",
    "section": "Generar hip√≥tesis",
    "text": "Generar hip√≥tesis\nGenerar hip√≥tesis es una tarea fundamental para los cient√≠ficos de datos.\nAl realizar EDA, la pregunta que debemos hacernos es ¬øC√≥mo sabemos que lo que estamos observando es verdadero?\nPor ejemplo:\n\nSi recopilamos nuevos datos sobre vuelos de un per√≠odo de tiempo diferente ¬øobservar√≠amos los mismos resultados?\nDetectar relaciones, diferencias y patrones:\n\nUsamos Prueba de hip√≥tesis\n\nLa prueba de hip√≥tesis requiere previo a la recolecci√≥n de datos:\n\nGenerar una hip√≥tesis o pregunta.\nUna decisi√≥n en la se pueda usar una prueba estad√≠stica\n\nData snooping\n\nLos an√°lisis de datos excesivos, la generaci√≥n de m√∫ltiples hip√≥tesis y la ejecuci√≥n de m√∫ltiples pruebas estad√≠sticas\n\nGeneraci√≥n de Hip√≥tesis\n\nSe realiza usando an√°lisis exploratorio de datos\n\nPr√≥ximos pasos\n\nDise√±ar nuestro experimento.\nEnvuelve pasos como:\n\nElegir una muestra\nCalcular cu√°ntos puntos de datos necesitamos\nDecidir que prueba estad√≠stica ejecutar.\n\n\n\n\nComparar salarios\n¬°El an√°lisis exploratorio de datos es un paso crucial en la generaci√≥n de hip√≥tesis!\nSe te ha ocurrido una idea que te gustar√≠a investigar: ¬ølos profesionales de los datos cobran m√°s en Estados Unidos que en Gran Breta√±a?\nTendr√°s que subconjuntar los datos en ‚ÄúEmployee_Location‚Äù y elaborar un gr√°fico que muestre el salario medio entre los dos grupos.\n\nInstrucciones\n\nFiltra salaries donde ‚ÄúEmployee_Location‚Äù es ‚ÄúUS‚Äù o ‚ÄúGB‚Äù, guardando como usa_and_gb.\nUtiliza usa_and_gb para crear un gr√°fico de barras que visualice ‚ÄúSalary_USD‚Äù frete a ‚ÄúEmployee_Location‚Äù.\n\n\n# Filter for employees in the US or GB\nusa_and_gb = salaries[salaries['Employee_Location'].isin(['US', 'GB'])]\n\n# Create a barplot of salaries by location\nsns.barplot(data=usa_and_gb, x='Employee_Location', y='Salary_USD')\nplt.show()\n\n\n\n\n\n\n\n\nAl subconfigurar los datos, pudiste comparar directamente los salarios entre EE.UU. y Gran Breta√±a. La visualizaci√≥n sugiere que has generado una hip√≥tesis que vale la pena investigar formalmente para determinar si existe una diferencia real o no.\n\n\n\nElegir una hip√≥tesis\nHas visto c√≥mo las visualizaciones pueden utilizarse para generar hip√≥tesis, ¬°lo que las convierte en una parte crucial del an√°lisis exploratorio de datos!\nEn este ejercicio, generar√°s un diagrama de barras para inspeccionar c√≥mo difieren los salarios seg√∫n el tama√±o de la empresa y la situaci√≥n laboral.\nComo referencia, hay cuatro valores:\n\n\n\nValor\nSignificado\n\n\n\n\nCT\nContratista\n\n\nFL\nAut√≥nomo\n\n\nPT\nA tiempo parcial\n\n\nFT\nA tiempo completo\n\n\n\n\nInstrucciones\n\nElabora un diagrama de barras comparando ‚ÄúSalary_USD‚Äù por ‚ÄúCompany_Size‚Äù, factorizando ‚ÄúEmployment_Status‚Äù.\n\n\n# Create a bar plot  of salary versus company size, factoring in employment status\nsns.barplot(data=salaries, x='Company_Size', y='Salary_USD', hue='Employment_Status')\nplt.show()\n\n\n\n\n\n\n\n\n\nPregunta ¬ø Cu√°l es una hip√≥tesis razonable que se puede generar a partir de esta trama?\n\nRespuestas Posibles\n\nPor t√©rmino medio, las peque√±as empresas pagan menos a los empleados a tiempo parcial que las grandes empresas.\nLos aut√≥nomos ganan m√°s en las empresas medianas que en las peque√±as o grandes.\nPor t√©rmino medio, las grandes empresas pagan m√°s a los contratistas que las medianas.\nNo se puede generar ninguna hip√≥tesis a partir de este gr√°fico.\n\nLos contratistas parecen se mejor pagados por las grandes empresas en promedio seg√∫n los datos, ¬°as√≠ que esta es una hip√≥tesis razonable!",
    "crumbs": [
      "An√°lisis Exploratorio de Datos",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Convertir el an√°lisis exploratorio en acci√≥n</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/index.html",
    "href": "08_Muestreo_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nüìä Nivel: Intermedio\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nEl muestreo en Python es la piedra angular de la estad√≠stica de inferencia y las pruebas de hip√≥tesis. Es una poderosa habilidad utilizada en el an√°lisis de encuestas y el dise√±o experimental para sacar conclusiones sin encuestar a toda una poblaci√≥n. En este curso de Muestreo en Python, descubrir√°s cu√°ndo utilizar el muestreo y c√≥mo realizar tipos comunes de muestreo, desde el muestreo aleatorio simple hasta m√©todos m√°s complejos como el muestreo estratificado y por cl√∫steres. Utilizando conjuntos de datos del mundo real, como valoraciones de caf√©, canciones de Spotify y bajas de empleados, aprender√°s a estimar estad√≠sticas de poblaci√≥n y a cuantificar la incertidumbre en tus estimaciones generando distribuciones de muestreo y distribuciones bootstrap.",
    "crumbs": [
      "Muestreo en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/index.html#m√≥dulos-del-curso",
    "href": "08_Muestreo_en_python/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nIntroducci√≥n al muestreo\nM√©todos de muestreo\nDistribuciones muestrales\nDistribuciones Bootstrap",
    "crumbs": [
      "Muestreo en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html",
    "title": "Introducci√≥n al Muestreo",
    "section": "",
    "text": "Muestreo y estimaciones puntuales\nAprende qu√© es el muestreo y por qu√© es tan poderoso. Tambi√©n aprender√°s sobre los problemas causados por el muestreo de conveniencia y las diferencias entre la verdadera aleatoriedad y la pseudoaleatoriedad.\nLa t√©cnica de trabajar con un subconjunto de toda la poblaci√≥n se le llama muestreo.\nLa muestra es el subconjunto de datos con el que estamos trabajando.\npts_vs_flavor_pop = coffee_ratings[[\"total_points\", \"flavor\"]]\npts_vs_flavor_samp = pts_vs_flavor_pop.sample(n=10)\nEl m√©todo .sample() de pandas devuelve un subconjunto aleatorio de filas. Establecer n en 10 significa que devuelve 10 filas aleatorias. En la muestra aparecen 10 muestras √∫nicas.\ncup_points_samp = coffe_ratings['total_cup_points'].sample(n=10)\nimport numpy as np\nnp.mean(pts_vs_flavor_pop['total_cup_points'])\nUna estimaci√≥n puntual o estad√≠stica de muestra, es un c√°lculo basado en el conjunto de datos de muestra.\nnp.mean(cup_points_samp)\npts_vs_flavor_pop['flavor'].mean()\npts_vs_flavor_samp['flavor'].mean()",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Introducci√≥n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-y-estimaciones-puntuales",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-y-estimaciones-puntuales",
    "title": "Introducci√≥n al Muestreo",
    "section": "",
    "text": "Poblaci√≥n vs Muestreo La poblaci√≥n es el conjunto completo de datos que nos interesan.\n\nNo se refiere a personas.\nT√≠picamente, no sabremos c√≥mo es toda la poblaci√≥n.\n\n\n\n\nCoffee rating dataset\n\n\nCada fila representa 1 caf√©.\nHay 1338 filas\nAl caf√© se le asigna una puntuaci√≥n de cero a cien, que se almacena en la columna total_cup_points.\nOtras columnas contienen informaci√≥n contextual como la variedad y el pa√≠s de origen.\nPuntuaciones entre 0 y 10 para atributos del caf√© como el aroma y el cuerpo.\nNo contiene todos los caf√©s del mundo, por lo que no sabemos exactamente cu√°l es la poblaci√≥n de caf√©s.\nHay suficientes para considerarla como la poblaci√≥n de inter√©s.\n\nPoints vs.¬†Flavor: Poblaci√≥n\n\n\n\n\nPoints vs.¬†Flavor: 10 filas de muestra\n\n\n\n\n\nMuestreo en Python para Series\n\nUse .sample() en pandas para DataFrames y Series.\n\n\n\n\n\nPar√°metros de Poblaci√≥n & Puntos Estimados\nUn par√°metro de poblaci√≥n es un c√°lculo realizado sobre el conjunto de datos de poblaci√≥n.\n\n\n\n\n\n\n\nPuntos estimados con pandas\nTrabajar con pandas puede ser m√°s f√°cil que trabajar con Numpy. Estos c√°lculos de media se pueden realizar utilizando el m√©todo de pandas .mean()\n\n\n\n\n\n\nMotivos del muestreo\nEl muestreo es una t√©cnica importante en tu arsenal estad√≠sico. Sin embargo, no siempre es adecuado: hay que saber cu√°ndo utilizarlo y cu√°ndo trabajar con todo el conjunto de datos.\n¬øCu√°l de los siguientes no es un buen escenario para utilizar el muestreo?\nRespuestas posibles\n\nTe han agregado un terabyte de datos sobre registros de errores del dispositivo de tu empresa.\nDeseas conocer los h√°bitos de viaje de todos los ciudadanos adultos paquistan√≠es.\nHas terminado de recoger los datos de un peque√±o estudio sobre las medidas de las alas de 10 mariposas.\nHas estado trabajando para predecir la rotaci√≥n de clientes en un proyecto de big data para tu empresa de marketing.\n\nDiez mariposas es un conjunto de datos peque√±o, por lo que el muestreo no es √∫til aqu√≠.\n\n\nMuestreo simple con pandas\nA lo largo de este cap√≠tulo , explorar√°s los datos de canciones de Spotify. Cada fila de este conjunto de datos de poblaci√≥n representa una canci√≥n, y hay m√°s de 40000 filas. Las columnas incluyen el nombre de la canci√≥n, los artistas que la interpretaron, al a√±o de lanzamiento y atributos de la canci√≥n como su duraci√≥n, tempo y bailabilidad. Empezar√°s por fijarte en las duraciones.\nTu primera tarea es tomar una muestra del conjunto de datos de Spotify y comparar la duraci√≥n media de la poblaci√≥n con la de la muestra.\n\nimport pandas as pd\nruta = './data/spotify_2000_2020.feather'\nspotify_population = pd.read_feather(ruta)\nspotify_population.head()\n\n\n\n\n\n\n\n\nacousticness\nartists\ndanceability\nduration_ms\nduration_minutes\nenergy\nexplicit\nid\ninstrumentalness\nkey\nliveness\nloudness\nmode\nname\npopularity\nrelease_date\nspeechiness\ntempo\nvalence\nyear\n\n\n\n\n0\n0.97200\n['David Bauer']\n0.567\n313293.0\n5.221550\n0.227\n0.0\n0w0D8H1ubRerCXHWYJkinO\n0.601000\n10.0\n0.110\n-13.441\n1.0\nShout to the Lord\n47.0\n2000\n0.0290\n136.123\n0.0396\n2000.0\n\n\n1\n0.32100\n['Etta James']\n0.821\n360240.0\n6.004000\n0.418\n0.0\n4JVeqfE2tpi7Pv63LJZtPh\n0.000372\n9.0\n0.222\n-9.841\n0.0\nMiss You\n51.0\n2000-12-12\n0.0407\n117.382\n0.8030\n2000.0\n\n\n2\n0.00659\n['Quasimoto']\n0.706\n202507.0\n3.375117\n0.602\n1.0\n5pxtdhLAi0RTh1gNqhGMNA\n0.000138\n11.0\n0.400\n-8.306\n0.0\nReal Eyes\n44.0\n2000-06-13\n0.3420\n89.692\n0.4790\n2000.0\n\n\n3\n0.00390\n['Millencolin']\n0.368\n173360.0\n2.889333\n0.977\n0.0\n3jRsoe4Vkxa4BMYqGHX8L0\n0.000000\n11.0\n0.350\n-2.757\n0.0\nPenguins & Polarbears\n52.0\n2000-02-22\n0.1270\n165.889\n0.5480\n2000.0\n\n\n4\n0.12200\n['Steve Chou']\n0.501\n344200.0\n5.736667\n0.511\n0.0\n4mronxcllhfyhBRqyZi8kU\n0.000000\n7.0\n0.279\n-9.836\n0.0\nÈªÉÊòè\n53.0\n2000-12-25\n0.0291\n78.045\n0.1130\n2000.0\n\n\n\n\n\n\n\n\nInstrucciones\n\nMuestra 1000 filas de spotify_population, asign√°ndolas a spotify_sample.\n\n\n# Sample 1000 rows from spotify_population\nspotify_sample = spotify_population.sample(n=1000)\n\n# print sample\nprint(spotify_sample)\n\n       acousticness                         artists  danceability  \\\n37262      0.296000                  ['Lil Loaded']         0.871   \n24370      0.007680                     ['STARSET']         0.274   \n20911      0.101000                ['Travis Tritt']         0.647   \n40408      0.001220             ['Nine Inch Nails']         0.611   \n16947      0.232000                      ['Pesado']         0.814   \n...             ...                             ...           ...   \n11496      0.000043                 ['Lamb of God']         0.418   \n16862      0.685000               ['Grateful Dead']         0.560   \n16061      0.954000              ['Casting Crowns']         0.342   \n1394       0.477000  ['Daft Punk', 'Paul Williams']         0.290   \n13864      0.096600                  ['Toby Keith']         0.670   \n\n       duration_ms  duration_minutes  energy  explicit  \\\n37262     131286.0          2.188100   0.702       1.0   \n24370     288036.0          4.800600   0.652       0.0   \n20911     284173.0          4.736217   0.874       0.0   \n40408     259183.0          4.319717   0.793       0.0   \n16947     196453.0          3.274217   0.708       0.0   \n...            ...               ...     ...       ...   \n11496     324667.0          5.411117   0.968       0.0   \n16862     502533.0          8.375550   0.451       0.0   \n16061     281427.0          4.690450   0.151       0.0   \n1394      498960.0          8.316000   0.412       0.0   \n13864     212467.0          3.541117   0.837       0.0   \n\n                           id  instrumentalness   key  liveness  loudness  \\\n37262  3WCXvxgQ7U3mznWsQjiEMu          0.000000   5.0    0.0912    -8.025   \n24370  3Xfg7AegXaDLoD5GOUMf2e          0.000064   5.0    0.1080    -6.196   \n20911  58rdbCe3SBJuJeWEJa8Htm          0.000018   9.0    0.2770    -5.075   \n40408  0Z4pLlygCvkTHmeQtYAbNH          0.285000   6.0    0.2510    -6.646   \n16947  0zQQZYD7Nb80dyIYebSqNN          0.000000   0.0    0.1250    -7.807   \n...                       ...               ...   ...       ...       ...   \n11496  7lVrIjVb0ctSCo00X7cDOk          0.278000   7.0    0.3700    -3.120   \n16862  6tLJfms92i27IibnbaMbsz          0.013500   9.0    0.4320   -12.947   \n16061  2PuvIyN4e2w2i4GIjWCqsB          0.000000  10.0    0.1570   -12.397   \n1394   7oaEjLP2dTJLJsITbAxTOz          0.083900   6.0    0.0790   -12.659   \n13864  3Q74BN3z8lQIkiBC80zd07          0.000008   0.0    0.1060    -4.723   \n\n       mode                                               name  popularity  \\\n37262   1.0                                         6locc 6a6y        68.0   \n24370   0.0                                          My Demons        72.0   \n20911   0.0                        Modern Day Bonnie and Clyde        60.0   \n40408   1.0                                         Discipline        50.0   \n16947   1.0                                      Mitad y mitad        46.0   \n...     ...                                                ...         ...   \n11496   1.0                                      In Your Words        42.0   \n16862   1.0  Althea - Live at Nassau Coliseum, May 15-16, 1980        36.0   \n16061   1.0                                    Broken Together        49.0   \n1394    0.0                        Touch (feat. Paul Williams)        58.0   \n13864   1.0                                  Drinks After Work        47.0   \n\n      release_date  speechiness    tempo  valence    year  \n37262   2019-12-06       0.2530  125.089   0.6750  2019.0  \n24370         2014       0.0625  173.008   0.1000  2014.0  \n20911   2000-10-01       0.0337   89.727   0.9180  2000.0  \n40408   2008-06-12       0.0275  122.010   0.8240  2008.0  \n16947   2002-02-07       0.0396  142.039   0.9510  2002.0  \n...            ...          ...      ...      ...     ...  \n11496   2009-02-24       0.1950  112.409   0.0701  2009.0  \n16862   2002-10-22       0.0588  155.838   0.5380  2002.0  \n16061   2014-01-24       0.0363   88.358   0.1920  2014.0  \n1394    2013-05-17       0.0458   90.539   0.1200  2013.0  \n13864   2013-10-28       0.0278  102.507   0.8050  2013.0  \n\n[1000 rows x 20 columns]\n\n\n\n\n\n\nCalcula la duraci√≥n media en minutos de spotify_population utilizando pandas.\nCalcula la duraci√≥n media en minutos de spotify_sample utilizando pandas.\n\n\n# Calculate the mean duration in mins from spotify_population\nmean_dur_pop = spotify_population['duration_minutes'].mean()\n\n# Calculate the mean duration in mins from spotify_sample\nmean_dur_sample = spotify_sample['duration_minutes'].mean()\n\n# print the means\nprint(mean_dur_pop)\nprint(mean_dur_sample)\n\n3.8521519140900073\n3.8613368333333336\n\n\nSe observa que la duraci√≥n media de las canciones en la muestra es similar, pero no id√©ntica a la duraci√≥n media de las canciones en toda la poblacici√≥n.\n\n\n\nMuestreos y c√°lculos sencillos con Numpy\nTambi√©n puedes utilizar numpy para calcular par√°metros o estad√≠sticas partir de una lista o de la serie pandas.\n\n\nInstrucciones\n\n\n\n\nCrea una serie pandas, loudness_pop, subdividiendo la columna loudness de spotify_population.\nMuestra loudness_pop para obtener 100 valores aleatorios, asign√°ndolos a loudness_samp.\n\n\n# Create a pandas Series from de loudness column of spotify_population\nloudness_pop = spotify_population['loudness']\n\n# Sample 100 values of loudness_pop\nloudness_samp = loudness_pop.sample(n=100)\n\nprint(loudness_samp)\n\n40093    -8.959\n10719    -7.193\n39941    -4.478\n3432     -6.891\n21895    -5.980\n          ...  \n23388    -3.214\n7639    -22.704\n6622     -3.148\n16329   -14.084\n39885    -4.988\nName: loudness, Length: 100, dtype: float64\n\n\n\n\n\n\nCalcula la media de loudness_pop utilizando numpy.\nCalcula la media de loudness_samp utilizando numpy.\n\n\nimport numpy as np\n\n# Calculate the mean of loudness_pop\nmean_loudness_pop = np.mean(loudness_pop)\n\n# Calculate the mean of loudness_samp\nmean_loudness_samp = np.mean(loudness_samp)\n\nprint(mean_loudness_pop)\nprint(mean_loudness_samp)\n\n-7.366856851353947\n-6.975039999999999\n\n\nNuevamente, observe que el valor calculado (la media) es cercano pero no id√©ntico en cada caso.",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Introducci√≥n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-de-conveniencia",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#muestreo-de-conveniencia",
    "title": "Introducci√≥n al Muestreo",
    "section": "Muestreo de conveniencia",
    "text": "Muestreo de conveniencia\n\n¬øSon generalizables las conclusiones de la muestra?\n\n\n¬øSon generalizables estos resultados?",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Introducci√≥n al Muestreo</span>"
    ]
  },
  {
    "objectID": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#generaci√≥n-de-n√∫meros-pseudoaleatorios",
    "href": "08_Muestreo_en_python/01_Introduccion_al_muestreo.html#generaci√≥n-de-n√∫meros-pseudoaleatorios",
    "title": "Introducci√≥n al Muestreo",
    "section": "Generaci√≥n de n√∫meros pseudoaleatorios",
    "text": "Generaci√≥n de n√∫meros pseudoaleatorios\n\nGenerar n√∫meros aleatorios\n\n\nComprender los valores de iniciaclizaci√≥n aleatorios",
    "crumbs": [
      "Muestreo en Python",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Introducci√≥n al Muestreo</span>"
    ]
  },
  {
    "objectID": "09_Pruebas_de_hipotesis_en_python/index.html",
    "href": "09_Pruebas_de_hipotesis_en_python/index.html",
    "title": "Bienvenida",
    "section": "",
    "text": "Descripci√≥n\nüìä Nivel: Intermedio\nüïí Duraci√≥n estimada: 4 horas\nüé• Incluye c√≥digo, visualizaciones y ejercicios\nLas pruebas de hip√≥tesis te permiten responder a preguntas sobre tus conjuntos de datos de forma estad√≠sticamente rigurosa. En este curso, desarrollar√°s tus competencias anal√≠ticas en Python aprendiendo c√≥mo y cu√°ndo utilizar pruebas comunes como las pruebas t, las pruebas de proporci√≥n y las pruebas œá¬≤. Trabajando con datos del mundo real, incluidos datos de cadena de suministro y comentarios de usuarios de Stack Overflow sobre env√≠os de suministros m√©dicos, comprender√°s en profundidad c√≥mo funcionan estas pruebas y los supuestos clave que las sustentan. Tambi√©n descubrir√°s c√≥mo pueden utilizarse pruebas no param√©tricas para superar las limitaciones de las pruebas de hip√≥tesis tradicionales.",
    "crumbs": [
      "Pruebas de Hip√≥tesis en Python",
      "Bienvenida"
    ]
  },
  {
    "objectID": "09_Pruebas_de_hipotesis_en_python/index.html#m√≥dulos-del-curso",
    "href": "09_Pruebas_de_hipotesis_en_python/index.html#m√≥dulos-del-curso",
    "title": "Bienvenida",
    "section": "M√≥dulos del curso",
    "text": "M√≥dulos del curso\n\nFundamentos de las pruebas de hip√≥tesis\nPruebas de dos muestras y ANOVA\nPruebas de proporci√≥n\nPruebas no param√©tricas",
    "crumbs": [
      "Pruebas de Hip√≥tesis en Python",
      "Bienvenida"
    ]
  }
]